{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.read_csv('feat_cup.csv', delimiter=',')\n",
    "df_objects = pd.read_csv('objects_cup.csv', delimiter=',')\n",
    "df_excel = pd.read_excel('feat_dict_cup.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holder_id</th>\n",
       "      <th>card_uk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000037dc4be61f378896fdcf92fbdc2149dddce77974f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323344</th>\n",
       "      <td>a30fa54e4c4e4c45301fbc2305ea9e0abd733329b27596...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323343</th>\n",
       "      <td>a30f758600fd3ac2a8f68635319c6a36406235c9f7b246...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323342</th>\n",
       "      <td>a30f33a0969b2ad87e96f4d8b45da0f48c3fbdc2eb783e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323341</th>\n",
       "      <td>a30f2f297e1f2252357a8da5dbb6c9f060bfa7648fb1e2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300697</th>\n",
       "      <td>97b8f6fcd392c1333ad4d9eaf553bbb08caa86a9406c3c...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126697</th>\n",
       "      <td>3fc77308c2aa1c7373fe161ba6f81f826d5b23b76bdb8a...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>01073424ca6704a4ed626b930e63bc05a12f028e320b0c...</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500192</th>\n",
       "      <td>fb87393a13e055485cd0b5eb90bdc5f8c4f602bb2799c2...</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89856</th>\n",
       "      <td>2d539a4c8b322285979f67ead95bc7adfc97c9909a523e...</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509235 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                holder_id  card_uk\n",
       "0       0000037dc4be61f378896fdcf92fbdc2149dddce77974f...        1\n",
       "323344  a30fa54e4c4e4c45301fbc2305ea9e0abd733329b27596...        1\n",
       "323343  a30f758600fd3ac2a8f68635319c6a36406235c9f7b246...        1\n",
       "323342  a30f33a0969b2ad87e96f4d8b45da0f48c3fbdc2eb783e...        1\n",
       "323341  a30f2f297e1f2252357a8da5dbb6c9f060bfa7648fb1e2...        1\n",
       "...                                                   ...      ...\n",
       "300697  97b8f6fcd392c1333ad4d9eaf553bbb08caa86a9406c3c...       22\n",
       "126697  3fc77308c2aa1c7373fe161ba6f81f826d5b23b76bdb8a...       34\n",
       "2146    01073424ca6704a4ed626b930e63bc05a12f028e320b0c...       89\n",
       "500192  fb87393a13e055485cd0b5eb90bdc5f8c4f602bb2799c2...      321\n",
       "89856   2d539a4c8b322285979f67ead95bc7adfc97c9909a523e...     1005\n",
       "\n",
       "[509235 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_objects.groupby('holder_id')['card_uk'].count().reset_index().sort_values('card_uk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holder_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>101214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.263995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.104375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>966.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           holder_id\n",
       "count  101214.000000\n",
       "mean        1.263995\n",
       "std         3.104375\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max       966.000000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_objects[df_objects['owner_id'] != df_objects['holder_id']].groupby('owner_id')['holder_id'].count().reset_index().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_objects['cardapp_date'] = pd.to_datetime(df_objects['cardapp_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_objects['month'] = df_objects['cardapp_date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>owner_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>47503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>47474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>54283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>46178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>42180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>46799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>52236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>55771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>59730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>54101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>53235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>57264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  owner_id\n",
       "0     1.0     47503\n",
       "1     2.0     47474\n",
       "2     3.0     54283\n",
       "3     4.0     46178\n",
       "4     5.0     42180\n",
       "5     6.0     46799\n",
       "6     7.0     52236\n",
       "7     8.0     55771\n",
       "8     9.0     59730\n",
       "9    10.0     54101\n",
       "10   11.0     53235\n",
       "11   12.0     57264"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_objects.groupby('month')['owner_id'].count().reset_index().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = df_objects[df_objects['owner_id'] != df_objects['holder_id']].drop_duplicates(subset =  ['owner_id','holder_id']).\\\n",
    "                                    drop_duplicates('holder_id').groupby('owner_id')['holder_id'].count().reset_index().\\\n",
    "    sort_values('holder_id', ascending = False).reset_index().rename(columns = {'owner_id':'client_id', 'holder_id':'col_holders'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = df_feat.merge(test_1, how='left', on='client_id')\n",
    "df_feat['is_owner'] = df_feat.col_holders.apply(lambda x: 1 if x>0 else 0)\n",
    "df_feat.drop('col_holders', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всё в норме, пропусков нет, длина исходного массива совпадает с получившимся\n",
      "Претенденты на заполнение other ['country', 'clientoutflowstatus', 'srvpackage', 'addrref']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14328\\383242814.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  addrref_small['checker'] = 'OTHER'\n"
     ]
    }
   ],
   "source": [
    "categorial_features = df_feat.select_dtypes(include=['object']).columns.to_list()\n",
    "\n",
    "df_feat = df_feat.drop_duplicates(subset='client_id', keep='last')\n",
    "        \n",
    "feat_eda = df_feat[categorial_features].drop(columns = (['client_id','dt']))\n",
    "\n",
    "for i in feat_eda.columns:\n",
    "    test_city = feat_eda[i].value_counts(normalize = True).reset_index().rename(columns = ({'index': 'city'}))\n",
    "    city_list = test_city['city'].to_list()\n",
    "    p_city_list = test_city[i].to_list()\n",
    "    test_weight_city = pd.Series(np.random.choice(city_list, replace = True, p = p_city_list, size = feat_eda[i].isna().sum()))\\\n",
    "    .value_counts()\n",
    "    target_weight = np.random.choice(city_list, replace = True, p = p_city_list, size = feat_eda[i].isna().sum()).tolist()\n",
    "    new_values = pd.Series(target_weight, index=feat_eda.index[feat_eda[i].isna()])\n",
    "    feat_eda[i].fillna(new_values, inplace=True)\n",
    "if (len(feat_eda) == len(df_feat)) & (feat_eda.isna().sum().sum() == 0):\n",
    "    print('Всё в норме, пропусков нет, длина исходного массива совпадает с получившимся')\n",
    "else:\n",
    "    print('Что-то пошло не так')\n",
    "\n",
    "coder_other = []\n",
    "for i in feat_eda.columns:\n",
    "    if len(feat_eda[i].value_counts()) > 6:\n",
    "        coder_other.append(i)\n",
    "print(f'Претенденты на заполнение other {coder_other}')\n",
    "\n",
    "feat_eda['country_coder'] = feat_eda['country'].apply(lambda x: 'RUS' if x == 'RUS' else 'OTHER')\n",
    "feat_eda['clientoutflowstatus_coder'] = feat_eda['clientoutflowstatus'].apply(lambda x: 'ACTIVE' if x == 'ACTIVE' else 'OTHER')\n",
    "addrref_check = feat_eda['addrref'].value_counts(normalize = True).reset_index()\n",
    "addrref_small = addrref_check[addrref_check['addrref'] < 0.03]\n",
    "addrref_small['checker'] = 'OTHER'\n",
    "end_addrref = addrref_check.merge(addrref_small, on = ['index','addrref'], how = 'left')\n",
    "end_addrref['checker'] = end_addrref['checker'].fillna(pd.Series(end_addrref['index'].values[:5]))\n",
    "feat_eda = feat_eda.merge(end_addrref[['index','checker']], left_on = 'addrref', right_on = 'index').drop(columns = 'index')\\\n",
    ".rename(columns = {'checker':'addrref_coder'})\n",
    "new_df_with_coders = feat_eda.drop(columns = (['country','addrref']))\n",
    "new_df_with_coders = new_df_with_coders.drop(columns = ['clientoutflowstatus'])\n",
    "new_df_with_coders = pd.get_dummies(new_df_with_coders)\n",
    "df_feat_new_with_encoders = df_feat.drop(columns = categorial_features)\\\n",
    "            .merge(new_df_with_coders, left_index = True, right_index = True)\n",
    "correlations = df_feat_new_with_encoders.corr().unstack().reset_index().rename(columns = {0:'correlations'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_nan = df_feat_new_with_encoders.isna().sum().reset_index().rename(columns = {0:'count_nan'})\n",
    "stats_nan['all'] = len(df_feat_new_with_encoders)\n",
    "stats_nan['nan_percent'] = stats_nan['count_nan'] / stats_nan['all']\n",
    "stats_nan = stats_nan.sort_values('nan_percent', ascending = False)\n",
    "stats_filter_columns = stats_nan[stats_nan['nan_percent'] <= np.percentile(stats_nan['nan_percent'], 50)]\n",
    "values_stats_nan = stats_filter_columns['index'].values\n",
    "df_feat_new_with_encoders_without_high_nan = df_feat_new_with_encoders[values_stats_nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop_with_high_cor = correlations[(correlations['correlations'] < 1) & (correlations['correlations'] > 0.7)]\\\n",
    "                                                .drop_duplicates('level_0')['level_0'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_new_with_encoders_without_high_nan = df_feat_new_with_encoders_without_high_nan.drop(columns=[col for col in columns_to_drop_with_high_cor if col in df_feat_new_with_encoders_without_high_nan.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    186799\n",
       "1     42234\n",
       "Name: is_owner, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_new_with_encoders_without_high_nan['is_owner'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_feat_new_with_encoders_without_high_nan.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['transaction_category_pharmacy_percent_amt_2m',\n",
       "       'transaction_category_pharmacy_percent_cnt_2m',\n",
       "       'transaction_category_pharmacy_sum_cnt_m2',\n",
       "       'by_category__amount__SUM__eoperation_type_name__perevod_po_nomeru_telefona',\n",
       "       'transaction_category_fastfood_percent_amt_2m',\n",
       "       'transaction_category_fastfood_percent_cnt_2m',\n",
       "       'transaction_category_other_retail_purchase_percent_amt_2m',\n",
       "       'transaction_category_other_retail_purchase_sum_amt_m2',\n",
       "       'transaction_category_other_retail_purchase_sum_cnt_m2',\n",
       "       'transaction_category_other_retail_purchase_percent_cnt_2m',\n",
       "       'transaction_category_cash_percent_amt_2m',\n",
       "       'transaction_category_cash_percent_cnt_2m',\n",
       "       'transaction_category_cash_sum_cnt_m2',\n",
       "       'hdb_bki_other_active_cc_outstanding',\n",
       "       'transaction_category_supermarket_percent_amt_2m',\n",
       "       'transaction_category_supermarket_percent_cnt_2m',\n",
       "       'hdb_bki_active_cc_max_outstand', 'hdb_bki_total_pil_max_limit',\n",
       "       'hdb_bki_total_pil_last_days', 'hdb_bki_total_cc_last_days',\n",
       "       'avg_percents_inc', 'avg_invest_inc', 'avg_zp_inc', 'total_inc',\n",
       "       'hdb_other_active_mean_psk', 'hdb_other_active_min_psk',\n",
       "       'hdb_bki_active_auto_cnt', 'hdb_bki_total_auto_cnt',\n",
       "       'hdb_bki_active_pil_cnt', 'hdb_bki_total_currency',\n",
       "       'hdb_bki_last_product_days', 'avg_credit_turn_rur',\n",
       "       'diff_cur_cr_db_turn', 'days_to_last_transaction', 'hdb_bki_total_cnt',\n",
       "       'sal_rur_amt_curr_v2', 'cred_dda_rur_amt_curr_v2', 'accountsalary_flag',\n",
       "       'life_time_days', 'age', 'clientsegment_AFFLUENT', 'gender_Мужской',\n",
       "       'gender_Женский', 'clientsegment_MASS', 'clientsegment_MAFFLUENT',\n",
       "       'srvpackage_ЭкономUltra', 'srvpackage_длякредитовидепозитов',\n",
       "       'hdb_relend_client_credits_count_grade_b', 'srvpackage_Эконом',\n",
       "       'hdb_relend_client_credits_count_grade_a', 'country_coder_OTHER',\n",
       "       'hdb_relend_client_credits_count_grade_c',\n",
       "       'hdb_relend_client_credits_count_grade_d', 'srvpackage_Премиум',\n",
       "       'country_coder_RUS', 'clientoutflowstatus_coder_ACTIVE',\n",
       "       'clientoutflowstatus_coder_OTHER', 'addrref_coder_OTHER',\n",
       "       'addrref_coder_Краснодарский край',\n",
       "       'addrref_coder_Новосибирская область',\n",
       "       'addrref_coder_Свердловская область', 'addrref_coder_г. Москва',\n",
       "       'srvpackage_Технический', 'srvpackage_Он-Лайф',\n",
       "       'srvpackage_ОптимумUltra', 'srvpackage_Оптимум', 'is_owner',\n",
       "       'stratsegfactor_Зарплата из кредитной анкеты',\n",
       "       'stratsegfactor_Инвестиционные продукты',\n",
       "       'stratsegfactor_Остатки на счетах', 'stratsegfactor_Пакет услуг',\n",
       "       'stratsegfactor_Предиктивный доход',\n",
       "       'stratsegfactor_Реальная зарплата клиента', 'srvpackage_X5Банк',\n",
       "       'srvpackage_Альфа-Подписка', 'srvpackage_АльфаPriority',\n",
       "       'srvpackage_Класс', 'srvpackage_Комфорт', 'srvpackage_КомфортUltra',\n",
       "       'srvpackage_КомфортUltrafree', 'srvpackage_Комфортfree',\n",
       "       'srvpackage_Корпоративный', 'srvpackage_Максимум+',\n",
       "       'srvpackage_Максимум+free', 'srvpackage_МаксимумUltra',\n",
       "       'srvpackage_МаксимумUltrafree', 'addrref_coder_г. Санкт - Петербург'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill0 = [i for i in a if i.startswith('transaction')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill0.append('by_category__amount__SUM__eoperation_type_name__perevod_po_nomeru_telefona')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill0.extend([i for i in a if i.startswith('hdb')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill0.extend([i for i in a if i.startswith('avg')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill0.append('sal_rur_amt_curr_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill0.append('accountsalary_flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_new_with_encoders_without_high_nan[fill0] = \\\n",
    "                                df_feat_new_with_encoders_without_high_nan[fill0].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "final = imputer.fit_transform(df_feat_new_with_encoders_without_high_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame(final, columns=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    186799\n",
       "1.0     42234\n",
       "Name: is_owner, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi.is_owner.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fi.drop('is_owner', axis=1)\n",
    "Y = fi['is_owner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_7/embedding_262/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14328\\1531624186.py\", line 57, in <cell line: 57>\n      model.fit(X_train_resampled, y_train_resampled, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_7/embedding_262/embedding_lookup'\nindices[0,41] = -1 is not in [0, 416)\n\t [[{{node model_7/embedding_262/embedding_lookup}}]] [Op:__inference_train_function_56517]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 57>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Обучение модели\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model_7/embedding_262/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14328\\1531624186.py\", line 57, in <cell line: 57>\n      model.fit(X_train_resampled, y_train_resampled, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_7/embedding_262/embedding_lookup'\nindices[0,41] = -1 is not in [0, 416)\n\t [[{{node model_7/embedding_262/embedding_lookup}}]] [Op:__inference_train_function_56517]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "\n",
    "X = fi.drop('is_owner', axis=1)\n",
    "Y = fi['is_owner']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train_scaled = scaler.fit_transform(X_train).astype(np.float32)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "\n",
    "\n",
    "X_train_resampled, y_train_resampled = SMOTE().fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "X_train_resampled = X_train_resampled.astype(np.int32)\n",
    "\n",
    "input_layer = Input(shape=(X_train_resampled.shape[1],))\n",
    "\n",
    "embedding_layer = Embedding(int(X_train_resampled.max()+1), embedding_dim)(input_layer)\n",
    "flatten_layer = Flatten()(embedding_layer)\n",
    "\n",
    "\n",
    "\n",
    "hidden_layer1 = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(flatten_layer)\n",
    "dropout1 = Dropout(0.5)(hidden_layer1)\n",
    "hidden_layer2 = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(dropout1)\n",
    "dropout2 = Dropout(0.5)(hidden_layer2)\n",
    "hidden_layer3 = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(dropout2)\n",
    "\n",
    "output_layer = Dense(1, activation='sigmoid')(hidden_layer3)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled, epochs=10, batch_size=16, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Без оверсемплинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8312141940434765"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboostNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading catboost-1.1.1-cp310-none-win_amd64.whl (73.9 MB)\n",
      "     ---------------------------------------- 73.9/73.9 MB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (1.22.4)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (1.8.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (3.5.2)\n",
      "Requirement already satisfied: graphviz in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: plotly in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (5.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.24.0->catboost) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (4.33.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (9.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (3.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (1.4.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from plotly->catboost) (8.0.1)\n",
      "Installing collected packages: catboost\n",
      "Successfully installed catboost-1.1.1\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.088378\n",
      "0:\tlearn: 0.6182600\ttotal: 253ms\tremaining: 4m 12s\n",
      "1:\tlearn: 0.5643611\ttotal: 356ms\tremaining: 2m 57s\n",
      "2:\tlearn: 0.5208892\ttotal: 490ms\tremaining: 2m 42s\n",
      "3:\tlearn: 0.4860710\ttotal: 592ms\tremaining: 2m 27s\n",
      "4:\tlearn: 0.4544138\ttotal: 703ms\tremaining: 2m 19s\n",
      "5:\tlearn: 0.4310502\ttotal: 831ms\tremaining: 2m 17s\n",
      "6:\tlearn: 0.4139478\ttotal: 941ms\tremaining: 2m 13s\n",
      "7:\tlearn: 0.3994849\ttotal: 1.06s\tremaining: 2m 11s\n",
      "8:\tlearn: 0.3888307\ttotal: 1.16s\tremaining: 2m 7s\n",
      "9:\tlearn: 0.3786900\ttotal: 1.3s\tremaining: 2m 8s\n",
      "10:\tlearn: 0.3712136\ttotal: 1.41s\tremaining: 2m 7s\n",
      "11:\tlearn: 0.3653611\ttotal: 1.52s\tremaining: 2m 5s\n",
      "12:\tlearn: 0.3602452\ttotal: 1.64s\tremaining: 2m 4s\n",
      "13:\tlearn: 0.3557175\ttotal: 1.79s\tremaining: 2m 6s\n",
      "14:\tlearn: 0.3511171\ttotal: 1.93s\tremaining: 2m 6s\n",
      "15:\tlearn: 0.3481943\ttotal: 2.04s\tremaining: 2m 5s\n",
      "16:\tlearn: 0.3453331\ttotal: 2.18s\tremaining: 2m 6s\n",
      "17:\tlearn: 0.3433354\ttotal: 2.36s\tremaining: 2m 9s\n",
      "18:\tlearn: 0.3413195\ttotal: 2.54s\tremaining: 2m 11s\n",
      "19:\tlearn: 0.3397749\ttotal: 2.65s\tremaining: 2m 9s\n",
      "20:\tlearn: 0.3373860\ttotal: 2.77s\tremaining: 2m 8s\n",
      "21:\tlearn: 0.3360906\ttotal: 2.92s\tremaining: 2m 9s\n",
      "22:\tlearn: 0.3346304\ttotal: 3.06s\tremaining: 2m 10s\n",
      "23:\tlearn: 0.3334748\ttotal: 3.16s\tremaining: 2m 8s\n",
      "24:\tlearn: 0.3322812\ttotal: 3.27s\tremaining: 2m 7s\n",
      "25:\tlearn: 0.3314367\ttotal: 3.42s\tremaining: 2m 8s\n",
      "26:\tlearn: 0.3301682\ttotal: 3.58s\tremaining: 2m 9s\n",
      "27:\tlearn: 0.3294921\ttotal: 3.77s\tremaining: 2m 10s\n",
      "28:\tlearn: 0.3288883\ttotal: 3.94s\tremaining: 2m 12s\n",
      "29:\tlearn: 0.3284546\ttotal: 4.05s\tremaining: 2m 10s\n",
      "30:\tlearn: 0.3278836\ttotal: 4.14s\tremaining: 2m 9s\n",
      "31:\tlearn: 0.3275251\ttotal: 4.25s\tremaining: 2m 8s\n",
      "32:\tlearn: 0.3269262\ttotal: 4.35s\tremaining: 2m 7s\n",
      "33:\tlearn: 0.3264275\ttotal: 4.46s\tremaining: 2m 6s\n",
      "34:\tlearn: 0.3256968\ttotal: 4.58s\tremaining: 2m 6s\n",
      "35:\tlearn: 0.3254653\ttotal: 4.69s\tremaining: 2m 5s\n",
      "36:\tlearn: 0.3251183\ttotal: 4.8s\tremaining: 2m 5s\n",
      "37:\tlearn: 0.3247393\ttotal: 4.92s\tremaining: 2m 4s\n",
      "38:\tlearn: 0.3242103\ttotal: 5.04s\tremaining: 2m 4s\n",
      "39:\tlearn: 0.3239163\ttotal: 5.17s\tremaining: 2m 4s\n",
      "40:\tlearn: 0.3233968\ttotal: 5.32s\tremaining: 2m 4s\n",
      "41:\tlearn: 0.3230667\ttotal: 5.45s\tremaining: 2m 4s\n",
      "42:\tlearn: 0.3226465\ttotal: 5.54s\tremaining: 2m 3s\n",
      "43:\tlearn: 0.3223776\ttotal: 5.65s\tremaining: 2m 2s\n",
      "44:\tlearn: 0.3221069\ttotal: 5.77s\tremaining: 2m 2s\n",
      "45:\tlearn: 0.3218150\ttotal: 5.9s\tremaining: 2m 2s\n",
      "46:\tlearn: 0.3216197\ttotal: 6.04s\tremaining: 2m 2s\n",
      "47:\tlearn: 0.3214636\ttotal: 6.14s\tremaining: 2m 1s\n",
      "48:\tlearn: 0.3211869\ttotal: 6.25s\tremaining: 2m 1s\n",
      "49:\tlearn: 0.3208201\ttotal: 6.37s\tremaining: 2m 1s\n",
      "50:\tlearn: 0.3204385\ttotal: 6.49s\tremaining: 2m\n",
      "51:\tlearn: 0.3201779\ttotal: 6.64s\tremaining: 2m 1s\n",
      "52:\tlearn: 0.3199399\ttotal: 6.76s\tremaining: 2m\n",
      "53:\tlearn: 0.3197803\ttotal: 6.85s\tremaining: 2m\n",
      "54:\tlearn: 0.3196371\ttotal: 6.95s\tremaining: 1m 59s\n",
      "55:\tlearn: 0.3193730\ttotal: 7.07s\tremaining: 1m 59s\n",
      "56:\tlearn: 0.3192428\ttotal: 7.2s\tremaining: 1m 59s\n",
      "57:\tlearn: 0.3190744\ttotal: 7.32s\tremaining: 1m 58s\n",
      "58:\tlearn: 0.3189582\ttotal: 7.49s\tremaining: 1m 59s\n",
      "59:\tlearn: 0.3188058\ttotal: 7.62s\tremaining: 1m 59s\n",
      "60:\tlearn: 0.3185716\ttotal: 7.73s\tremaining: 1m 59s\n",
      "61:\tlearn: 0.3183782\ttotal: 7.84s\tremaining: 1m 58s\n",
      "62:\tlearn: 0.3182128\ttotal: 7.97s\tremaining: 1m 58s\n",
      "63:\tlearn: 0.3180755\ttotal: 8.08s\tremaining: 1m 58s\n",
      "64:\tlearn: 0.3179231\ttotal: 8.23s\tremaining: 1m 58s\n",
      "65:\tlearn: 0.3177584\ttotal: 8.37s\tremaining: 1m 58s\n",
      "66:\tlearn: 0.3176447\ttotal: 8.48s\tremaining: 1m 58s\n",
      "67:\tlearn: 0.3174659\ttotal: 8.59s\tremaining: 1m 57s\n",
      "68:\tlearn: 0.3172813\ttotal: 8.7s\tremaining: 1m 57s\n",
      "69:\tlearn: 0.3171468\ttotal: 8.85s\tremaining: 1m 57s\n",
      "70:\tlearn: 0.3170505\ttotal: 8.98s\tremaining: 1m 57s\n",
      "71:\tlearn: 0.3169687\ttotal: 9.14s\tremaining: 1m 57s\n",
      "72:\tlearn: 0.3168543\ttotal: 9.23s\tremaining: 1m 57s\n",
      "73:\tlearn: 0.3167486\ttotal: 9.35s\tremaining: 1m 56s\n",
      "74:\tlearn: 0.3166596\ttotal: 9.48s\tremaining: 1m 56s\n",
      "75:\tlearn: 0.3165409\ttotal: 9.6s\tremaining: 1m 56s\n",
      "76:\tlearn: 0.3163969\ttotal: 9.82s\tremaining: 1m 57s\n",
      "77:\tlearn: 0.3162743\ttotal: 9.93s\tremaining: 1m 57s\n",
      "78:\tlearn: 0.3161626\ttotal: 10s\tremaining: 1m 56s\n",
      "79:\tlearn: 0.3160568\ttotal: 10.2s\tremaining: 1m 57s\n",
      "80:\tlearn: 0.3159474\ttotal: 10.4s\tremaining: 1m 57s\n",
      "81:\tlearn: 0.3158736\ttotal: 10.5s\tremaining: 1m 57s\n",
      "82:\tlearn: 0.3157953\ttotal: 10.6s\tremaining: 1m 57s\n",
      "83:\tlearn: 0.3155528\ttotal: 10.7s\tremaining: 1m 57s\n",
      "84:\tlearn: 0.3154574\ttotal: 10.8s\tremaining: 1m 56s\n",
      "85:\tlearn: 0.3153605\ttotal: 11s\tremaining: 1m 56s\n",
      "86:\tlearn: 0.3152284\ttotal: 11.1s\tremaining: 1m 56s\n",
      "87:\tlearn: 0.3151301\ttotal: 11.2s\tremaining: 1m 56s\n",
      "88:\tlearn: 0.3150704\ttotal: 11.4s\tremaining: 1m 56s\n",
      "89:\tlearn: 0.3149799\ttotal: 11.5s\tremaining: 1m 56s\n",
      "90:\tlearn: 0.3147058\ttotal: 11.6s\tremaining: 1m 56s\n",
      "91:\tlearn: 0.3146026\ttotal: 11.8s\tremaining: 1m 56s\n",
      "92:\tlearn: 0.3145164\ttotal: 12s\tremaining: 1m 56s\n",
      "93:\tlearn: 0.3144190\ttotal: 12.1s\tremaining: 1m 56s\n",
      "94:\tlearn: 0.3143049\ttotal: 12.2s\tremaining: 1m 55s\n",
      "95:\tlearn: 0.3141639\ttotal: 12.3s\tremaining: 1m 55s\n",
      "96:\tlearn: 0.3140700\ttotal: 12.4s\tremaining: 1m 55s\n",
      "97:\tlearn: 0.3139166\ttotal: 12.5s\tremaining: 1m 55s\n",
      "98:\tlearn: 0.3138239\ttotal: 12.6s\tremaining: 1m 55s\n",
      "99:\tlearn: 0.3137292\ttotal: 12.8s\tremaining: 1m 54s\n",
      "100:\tlearn: 0.3136528\ttotal: 12.9s\tremaining: 1m 54s\n",
      "101:\tlearn: 0.3135691\ttotal: 13s\tremaining: 1m 54s\n",
      "102:\tlearn: 0.3134288\ttotal: 13.1s\tremaining: 1m 54s\n",
      "103:\tlearn: 0.3133444\ttotal: 13.3s\tremaining: 1m 54s\n",
      "104:\tlearn: 0.3132484\ttotal: 13.4s\tremaining: 1m 54s\n",
      "105:\tlearn: 0.3131707\ttotal: 13.6s\tremaining: 1m 54s\n",
      "106:\tlearn: 0.3130985\ttotal: 13.7s\tremaining: 1m 54s\n",
      "107:\tlearn: 0.3129378\ttotal: 13.8s\tremaining: 1m 53s\n",
      "108:\tlearn: 0.3128789\ttotal: 13.9s\tremaining: 1m 53s\n",
      "109:\tlearn: 0.3127995\ttotal: 14.1s\tremaining: 1m 53s\n",
      "110:\tlearn: 0.3127213\ttotal: 14.2s\tremaining: 1m 53s\n",
      "111:\tlearn: 0.3126529\ttotal: 14.3s\tremaining: 1m 53s\n",
      "112:\tlearn: 0.3126105\ttotal: 14.5s\tremaining: 1m 53s\n",
      "113:\tlearn: 0.3125513\ttotal: 14.6s\tremaining: 1m 53s\n",
      "114:\tlearn: 0.3124648\ttotal: 14.7s\tremaining: 1m 53s\n",
      "115:\tlearn: 0.3123552\ttotal: 14.8s\tremaining: 1m 52s\n",
      "116:\tlearn: 0.3122936\ttotal: 15s\tremaining: 1m 52s\n",
      "117:\tlearn: 0.3121634\ttotal: 15.1s\tremaining: 1m 53s\n",
      "118:\tlearn: 0.3120836\ttotal: 15.3s\tremaining: 1m 53s\n",
      "119:\tlearn: 0.3119661\ttotal: 15.4s\tremaining: 1m 53s\n",
      "120:\tlearn: 0.3118819\ttotal: 15.6s\tremaining: 1m 53s\n",
      "121:\tlearn: 0.3117559\ttotal: 15.8s\tremaining: 1m 53s\n",
      "122:\tlearn: 0.3116719\ttotal: 15.9s\tremaining: 1m 53s\n",
      "123:\tlearn: 0.3115348\ttotal: 16s\tremaining: 1m 53s\n",
      "124:\tlearn: 0.3114664\ttotal: 16.1s\tremaining: 1m 52s\n",
      "125:\tlearn: 0.3113837\ttotal: 16.2s\tremaining: 1m 52s\n",
      "126:\tlearn: 0.3113040\ttotal: 16.3s\tremaining: 1m 52s\n",
      "127:\tlearn: 0.3112346\ttotal: 16.4s\tremaining: 1m 52s\n",
      "128:\tlearn: 0.3111725\ttotal: 16.6s\tremaining: 1m 51s\n",
      "129:\tlearn: 0.3110602\ttotal: 16.7s\tremaining: 1m 52s\n",
      "130:\tlearn: 0.3109796\ttotal: 16.9s\tremaining: 1m 52s\n",
      "131:\tlearn: 0.3108683\ttotal: 17s\tremaining: 1m 52s\n",
      "132:\tlearn: 0.3107840\ttotal: 17.1s\tremaining: 1m 51s\n",
      "133:\tlearn: 0.3107138\ttotal: 17.3s\tremaining: 1m 51s\n",
      "134:\tlearn: 0.3106230\ttotal: 17.4s\tremaining: 1m 51s\n",
      "135:\tlearn: 0.3105131\ttotal: 17.5s\tremaining: 1m 51s\n",
      "136:\tlearn: 0.3104020\ttotal: 17.7s\tremaining: 1m 51s\n",
      "137:\tlearn: 0.3103351\ttotal: 17.8s\tremaining: 1m 51s\n",
      "138:\tlearn: 0.3102398\ttotal: 18s\tremaining: 1m 51s\n",
      "139:\tlearn: 0.3101411\ttotal: 18.1s\tremaining: 1m 51s\n",
      "140:\tlearn: 0.3100956\ttotal: 18.2s\tremaining: 1m 50s\n",
      "141:\tlearn: 0.3099700\ttotal: 18.3s\tremaining: 1m 50s\n",
      "142:\tlearn: 0.3098847\ttotal: 18.4s\tremaining: 1m 50s\n",
      "143:\tlearn: 0.3097998\ttotal: 18.5s\tremaining: 1m 50s\n",
      "144:\tlearn: 0.3096949\ttotal: 18.6s\tremaining: 1m 49s\n",
      "145:\tlearn: 0.3096362\ttotal: 18.8s\tremaining: 1m 49s\n",
      "146:\tlearn: 0.3095648\ttotal: 18.9s\tremaining: 1m 49s\n",
      "147:\tlearn: 0.3094761\ttotal: 19s\tremaining: 1m 49s\n",
      "148:\tlearn: 0.3094118\ttotal: 19.1s\tremaining: 1m 49s\n",
      "149:\tlearn: 0.3093256\ttotal: 19.2s\tremaining: 1m 48s\n",
      "150:\tlearn: 0.3091174\ttotal: 19.3s\tremaining: 1m 48s\n",
      "151:\tlearn: 0.3090186\ttotal: 19.4s\tremaining: 1m 48s\n",
      "152:\tlearn: 0.3089316\ttotal: 19.6s\tremaining: 1m 48s\n",
      "153:\tlearn: 0.3088433\ttotal: 19.7s\tremaining: 1m 48s\n",
      "154:\tlearn: 0.3087637\ttotal: 19.8s\tremaining: 1m 48s\n",
      "155:\tlearn: 0.3086314\ttotal: 19.9s\tremaining: 1m 47s\n",
      "156:\tlearn: 0.3085122\ttotal: 20.1s\tremaining: 1m 47s\n",
      "157:\tlearn: 0.3084300\ttotal: 20.2s\tremaining: 1m 47s\n",
      "158:\tlearn: 0.3083176\ttotal: 20.3s\tremaining: 1m 47s\n",
      "159:\tlearn: 0.3082426\ttotal: 20.4s\tremaining: 1m 46s\n",
      "160:\tlearn: 0.3081381\ttotal: 20.5s\tremaining: 1m 46s\n",
      "161:\tlearn: 0.3080786\ttotal: 20.6s\tremaining: 1m 46s\n",
      "162:\tlearn: 0.3080129\ttotal: 20.7s\tremaining: 1m 46s\n",
      "163:\tlearn: 0.3079373\ttotal: 20.8s\tremaining: 1m 45s\n",
      "164:\tlearn: 0.3078626\ttotal: 20.9s\tremaining: 1m 45s\n",
      "165:\tlearn: 0.3077941\ttotal: 21s\tremaining: 1m 45s\n",
      "166:\tlearn: 0.3077013\ttotal: 21.1s\tremaining: 1m 45s\n",
      "167:\tlearn: 0.3075885\ttotal: 21.2s\tremaining: 1m 44s\n",
      "168:\tlearn: 0.3075175\ttotal: 21.3s\tremaining: 1m 44s\n",
      "169:\tlearn: 0.3074687\ttotal: 21.4s\tremaining: 1m 44s\n",
      "170:\tlearn: 0.3073806\ttotal: 21.5s\tremaining: 1m 44s\n",
      "171:\tlearn: 0.3072694\ttotal: 21.6s\tremaining: 1m 44s\n",
      "172:\tlearn: 0.3071806\ttotal: 21.7s\tremaining: 1m 43s\n",
      "173:\tlearn: 0.3071006\ttotal: 21.9s\tremaining: 1m 43s\n",
      "174:\tlearn: 0.3070067\ttotal: 22s\tremaining: 1m 43s\n",
      "175:\tlearn: 0.3069176\ttotal: 22.1s\tremaining: 1m 43s\n",
      "176:\tlearn: 0.3068470\ttotal: 22.2s\tremaining: 1m 43s\n",
      "177:\tlearn: 0.3067759\ttotal: 22.3s\tremaining: 1m 42s\n",
      "178:\tlearn: 0.3066976\ttotal: 22.4s\tremaining: 1m 42s\n",
      "179:\tlearn: 0.3066323\ttotal: 22.5s\tremaining: 1m 42s\n",
      "180:\tlearn: 0.3065401\ttotal: 22.6s\tremaining: 1m 42s\n",
      "181:\tlearn: 0.3064475\ttotal: 22.7s\tremaining: 1m 42s\n",
      "182:\tlearn: 0.3063661\ttotal: 22.8s\tremaining: 1m 41s\n",
      "183:\tlearn: 0.3062920\ttotal: 22.9s\tremaining: 1m 41s\n",
      "184:\tlearn: 0.3062267\ttotal: 23s\tremaining: 1m 41s\n",
      "185:\tlearn: 0.3061477\ttotal: 23.1s\tremaining: 1m 41s\n",
      "186:\tlearn: 0.3060698\ttotal: 23.2s\tremaining: 1m 40s\n",
      "187:\tlearn: 0.3059781\ttotal: 23.3s\tremaining: 1m 40s\n",
      "188:\tlearn: 0.3059230\ttotal: 23.4s\tremaining: 1m 40s\n",
      "189:\tlearn: 0.3058279\ttotal: 23.6s\tremaining: 1m 40s\n",
      "190:\tlearn: 0.3057559\ttotal: 23.8s\tremaining: 1m 40s\n",
      "191:\tlearn: 0.3056999\ttotal: 23.9s\tremaining: 1m 40s\n",
      "192:\tlearn: 0.3056237\ttotal: 24s\tremaining: 1m 40s\n",
      "193:\tlearn: 0.3055431\ttotal: 24.1s\tremaining: 1m 40s\n",
      "194:\tlearn: 0.3054981\ttotal: 24.2s\tremaining: 1m 39s\n",
      "195:\tlearn: 0.3054541\ttotal: 24.2s\tremaining: 1m 39s\n",
      "196:\tlearn: 0.3053104\ttotal: 24.3s\tremaining: 1m 39s\n",
      "197:\tlearn: 0.3052310\ttotal: 24.4s\tremaining: 1m 39s\n",
      "198:\tlearn: 0.3050596\ttotal: 24.6s\tremaining: 1m 38s\n",
      "199:\tlearn: 0.3049799\ttotal: 24.7s\tremaining: 1m 38s\n",
      "200:\tlearn: 0.3049222\ttotal: 24.8s\tremaining: 1m 38s\n",
      "201:\tlearn: 0.3048653\ttotal: 24.9s\tremaining: 1m 38s\n",
      "202:\tlearn: 0.3048027\ttotal: 25s\tremaining: 1m 38s\n",
      "203:\tlearn: 0.3047250\ttotal: 25.1s\tremaining: 1m 37s\n",
      "204:\tlearn: 0.3046627\ttotal: 25.2s\tremaining: 1m 37s\n",
      "205:\tlearn: 0.3045706\ttotal: 25.3s\tremaining: 1m 37s\n",
      "206:\tlearn: 0.3044738\ttotal: 25.4s\tremaining: 1m 37s\n",
      "207:\tlearn: 0.3044005\ttotal: 25.5s\tremaining: 1m 36s\n",
      "208:\tlearn: 0.3043224\ttotal: 25.6s\tremaining: 1m 36s\n",
      "209:\tlearn: 0.3042595\ttotal: 25.7s\tremaining: 1m 36s\n",
      "210:\tlearn: 0.3042138\ttotal: 25.7s\tremaining: 1m 36s\n",
      "211:\tlearn: 0.3041326\ttotal: 25.8s\tremaining: 1m 36s\n",
      "212:\tlearn: 0.3040549\ttotal: 25.9s\tremaining: 1m 35s\n",
      "213:\tlearn: 0.3039739\ttotal: 26s\tremaining: 1m 35s\n",
      "214:\tlearn: 0.3038988\ttotal: 26.1s\tremaining: 1m 35s\n",
      "215:\tlearn: 0.3038394\ttotal: 26.2s\tremaining: 1m 35s\n",
      "216:\tlearn: 0.3037730\ttotal: 26.4s\tremaining: 1m 35s\n",
      "217:\tlearn: 0.3036299\ttotal: 26.5s\tremaining: 1m 35s\n",
      "218:\tlearn: 0.3035637\ttotal: 26.6s\tremaining: 1m 34s\n",
      "219:\tlearn: 0.3034820\ttotal: 26.7s\tremaining: 1m 34s\n",
      "220:\tlearn: 0.3034063\ttotal: 26.8s\tremaining: 1m 34s\n",
      "221:\tlearn: 0.3033440\ttotal: 26.9s\tremaining: 1m 34s\n",
      "222:\tlearn: 0.3032640\ttotal: 27.1s\tremaining: 1m 34s\n",
      "223:\tlearn: 0.3031705\ttotal: 27.2s\tremaining: 1m 34s\n",
      "224:\tlearn: 0.3031047\ttotal: 27.3s\tremaining: 1m 34s\n",
      "225:\tlearn: 0.3030296\ttotal: 27.4s\tremaining: 1m 33s\n",
      "226:\tlearn: 0.3029622\ttotal: 27.6s\tremaining: 1m 33s\n",
      "227:\tlearn: 0.3028935\ttotal: 27.7s\tremaining: 1m 33s\n",
      "228:\tlearn: 0.3028206\ttotal: 27.8s\tremaining: 1m 33s\n",
      "229:\tlearn: 0.3027563\ttotal: 27.9s\tremaining: 1m 33s\n",
      "230:\tlearn: 0.3026853\ttotal: 28.1s\tremaining: 1m 33s\n",
      "231:\tlearn: 0.3026158\ttotal: 28.2s\tremaining: 1m 33s\n",
      "232:\tlearn: 0.3025493\ttotal: 28.3s\tremaining: 1m 33s\n",
      "233:\tlearn: 0.3024949\ttotal: 28.4s\tremaining: 1m 32s\n",
      "234:\tlearn: 0.3024372\ttotal: 28.5s\tremaining: 1m 32s\n",
      "235:\tlearn: 0.3023723\ttotal: 28.7s\tremaining: 1m 32s\n",
      "236:\tlearn: 0.3023097\ttotal: 28.9s\tremaining: 1m 32s\n",
      "237:\tlearn: 0.3022433\ttotal: 29s\tremaining: 1m 32s\n",
      "238:\tlearn: 0.3021906\ttotal: 29.1s\tremaining: 1m 32s\n",
      "239:\tlearn: 0.3021324\ttotal: 29.2s\tremaining: 1m 32s\n",
      "240:\tlearn: 0.3020667\ttotal: 29.3s\tremaining: 1m 32s\n",
      "241:\tlearn: 0.3020209\ttotal: 29.4s\tremaining: 1m 32s\n",
      "242:\tlearn: 0.3019677\ttotal: 29.5s\tremaining: 1m 31s\n",
      "243:\tlearn: 0.3019296\ttotal: 29.6s\tremaining: 1m 31s\n",
      "244:\tlearn: 0.3018840\ttotal: 29.7s\tremaining: 1m 31s\n",
      "245:\tlearn: 0.3018111\ttotal: 29.9s\tremaining: 1m 31s\n",
      "246:\tlearn: 0.3017537\ttotal: 30s\tremaining: 1m 31s\n",
      "247:\tlearn: 0.3016860\ttotal: 30.1s\tremaining: 1m 31s\n",
      "248:\tlearn: 0.3016316\ttotal: 30.3s\tremaining: 1m 31s\n",
      "249:\tlearn: 0.3015757\ttotal: 30.4s\tremaining: 1m 31s\n",
      "250:\tlearn: 0.3015098\ttotal: 30.6s\tremaining: 1m 31s\n",
      "251:\tlearn: 0.3014452\ttotal: 30.7s\tremaining: 1m 31s\n",
      "252:\tlearn: 0.3013545\ttotal: 30.8s\tremaining: 1m 31s\n",
      "253:\tlearn: 0.3013026\ttotal: 31s\tremaining: 1m 30s\n",
      "254:\tlearn: 0.3012591\ttotal: 31.1s\tremaining: 1m 30s\n",
      "255:\tlearn: 0.3011955\ttotal: 31.2s\tremaining: 1m 30s\n",
      "256:\tlearn: 0.3011305\ttotal: 31.3s\tremaining: 1m 30s\n",
      "257:\tlearn: 0.3010643\ttotal: 31.5s\tremaining: 1m 30s\n",
      "258:\tlearn: 0.3009841\ttotal: 31.6s\tremaining: 1m 30s\n",
      "259:\tlearn: 0.3009174\ttotal: 31.7s\tremaining: 1m 30s\n",
      "260:\tlearn: 0.3008668\ttotal: 31.8s\tremaining: 1m 30s\n",
      "261:\tlearn: 0.3008088\ttotal: 31.9s\tremaining: 1m 29s\n",
      "262:\tlearn: 0.3007562\ttotal: 32s\tremaining: 1m 29s\n",
      "263:\tlearn: 0.3006440\ttotal: 32.2s\tremaining: 1m 29s\n",
      "264:\tlearn: 0.3005857\ttotal: 32.3s\tremaining: 1m 29s\n",
      "265:\tlearn: 0.3005362\ttotal: 32.4s\tremaining: 1m 29s\n",
      "266:\tlearn: 0.3004785\ttotal: 32.5s\tremaining: 1m 29s\n",
      "267:\tlearn: 0.3004260\ttotal: 32.6s\tremaining: 1m 29s\n",
      "268:\tlearn: 0.3003779\ttotal: 32.7s\tremaining: 1m 28s\n",
      "269:\tlearn: 0.3003248\ttotal: 32.9s\tremaining: 1m 28s\n",
      "270:\tlearn: 0.3002812\ttotal: 33s\tremaining: 1m 28s\n",
      "271:\tlearn: 0.3002062\ttotal: 33.1s\tremaining: 1m 28s\n",
      "272:\tlearn: 0.3001920\ttotal: 33.2s\tremaining: 1m 28s\n",
      "273:\tlearn: 0.3001524\ttotal: 33.3s\tremaining: 1m 28s\n",
      "274:\tlearn: 0.3000828\ttotal: 33.5s\tremaining: 1m 28s\n",
      "275:\tlearn: 0.3000060\ttotal: 33.6s\tremaining: 1m 28s\n",
      "276:\tlearn: 0.2999504\ttotal: 33.7s\tremaining: 1m 28s\n",
      "277:\tlearn: 0.2998760\ttotal: 33.9s\tremaining: 1m 27s\n",
      "278:\tlearn: 0.2998038\ttotal: 34s\tremaining: 1m 27s\n",
      "279:\tlearn: 0.2997447\ttotal: 34.1s\tremaining: 1m 27s\n",
      "280:\tlearn: 0.2996900\ttotal: 34.2s\tremaining: 1m 27s\n",
      "281:\tlearn: 0.2996383\ttotal: 34.4s\tremaining: 1m 27s\n",
      "282:\tlearn: 0.2995574\ttotal: 34.5s\tremaining: 1m 27s\n",
      "283:\tlearn: 0.2995009\ttotal: 34.6s\tremaining: 1m 27s\n",
      "284:\tlearn: 0.2994334\ttotal: 34.7s\tremaining: 1m 27s\n",
      "285:\tlearn: 0.2993779\ttotal: 34.8s\tremaining: 1m 27s\n",
      "286:\tlearn: 0.2993035\ttotal: 35s\tremaining: 1m 27s\n",
      "287:\tlearn: 0.2992380\ttotal: 35.2s\tremaining: 1m 26s\n",
      "288:\tlearn: 0.2991845\ttotal: 35.3s\tremaining: 1m 26s\n",
      "289:\tlearn: 0.2991293\ttotal: 35.5s\tremaining: 1m 26s\n",
      "290:\tlearn: 0.2990775\ttotal: 35.6s\tremaining: 1m 26s\n",
      "291:\tlearn: 0.2990216\ttotal: 35.7s\tremaining: 1m 26s\n",
      "292:\tlearn: 0.2989791\ttotal: 35.8s\tremaining: 1m 26s\n",
      "293:\tlearn: 0.2989411\ttotal: 35.9s\tremaining: 1m 26s\n",
      "294:\tlearn: 0.2988900\ttotal: 36.1s\tremaining: 1m 26s\n",
      "295:\tlearn: 0.2988319\ttotal: 36.2s\tremaining: 1m 26s\n",
      "296:\tlearn: 0.2987895\ttotal: 36.3s\tremaining: 1m 25s\n",
      "297:\tlearn: 0.2987506\ttotal: 36.4s\tremaining: 1m 25s\n",
      "298:\tlearn: 0.2986807\ttotal: 36.5s\tremaining: 1m 25s\n",
      "299:\tlearn: 0.2986256\ttotal: 36.7s\tremaining: 1m 25s\n",
      "300:\tlearn: 0.2985611\ttotal: 36.8s\tremaining: 1m 25s\n",
      "301:\tlearn: 0.2985096\ttotal: 36.9s\tremaining: 1m 25s\n",
      "302:\tlearn: 0.2984352\ttotal: 37.1s\tremaining: 1m 25s\n",
      "303:\tlearn: 0.2983790\ttotal: 37.2s\tremaining: 1m 25s\n",
      "304:\tlearn: 0.2983025\ttotal: 37.4s\tremaining: 1m 25s\n",
      "305:\tlearn: 0.2982510\ttotal: 37.5s\tremaining: 1m 25s\n",
      "306:\tlearn: 0.2981923\ttotal: 37.6s\tremaining: 1m 24s\n",
      "307:\tlearn: 0.2981354\ttotal: 37.7s\tremaining: 1m 24s\n",
      "308:\tlearn: 0.2980784\ttotal: 37.8s\tremaining: 1m 24s\n",
      "309:\tlearn: 0.2980675\ttotal: 38.1s\tremaining: 1m 24s\n",
      "310:\tlearn: 0.2979978\ttotal: 38.2s\tremaining: 1m 24s\n",
      "311:\tlearn: 0.2979361\ttotal: 38.3s\tremaining: 1m 24s\n",
      "312:\tlearn: 0.2978847\ttotal: 38.4s\tremaining: 1m 24s\n",
      "313:\tlearn: 0.2978327\ttotal: 38.5s\tremaining: 1m 24s\n",
      "314:\tlearn: 0.2977677\ttotal: 38.6s\tremaining: 1m 24s\n",
      "315:\tlearn: 0.2977064\ttotal: 38.7s\tremaining: 1m 23s\n",
      "316:\tlearn: 0.2976352\ttotal: 38.8s\tremaining: 1m 23s\n",
      "317:\tlearn: 0.2975980\ttotal: 38.9s\tremaining: 1m 23s\n",
      "318:\tlearn: 0.2975324\ttotal: 39.1s\tremaining: 1m 23s\n",
      "319:\tlearn: 0.2974594\ttotal: 39.2s\tremaining: 1m 23s\n",
      "320:\tlearn: 0.2973909\ttotal: 39.3s\tremaining: 1m 23s\n",
      "321:\tlearn: 0.2973375\ttotal: 39.4s\tremaining: 1m 23s\n",
      "322:\tlearn: 0.2972783\ttotal: 39.6s\tremaining: 1m 23s\n",
      "323:\tlearn: 0.2972241\ttotal: 39.8s\tremaining: 1m 22s\n",
      "324:\tlearn: 0.2971641\ttotal: 39.9s\tremaining: 1m 22s\n",
      "325:\tlearn: 0.2971113\ttotal: 40s\tremaining: 1m 22s\n",
      "326:\tlearn: 0.2970557\ttotal: 40.1s\tremaining: 1m 22s\n",
      "327:\tlearn: 0.2970024\ttotal: 40.2s\tremaining: 1m 22s\n",
      "328:\tlearn: 0.2969420\ttotal: 40.3s\tremaining: 1m 22s\n",
      "329:\tlearn: 0.2968835\ttotal: 40.4s\tremaining: 1m 22s\n",
      "330:\tlearn: 0.2968523\ttotal: 40.5s\tremaining: 1m 21s\n",
      "331:\tlearn: 0.2967841\ttotal: 40.6s\tremaining: 1m 21s\n",
      "332:\tlearn: 0.2967260\ttotal: 40.8s\tremaining: 1m 21s\n",
      "333:\tlearn: 0.2966994\ttotal: 40.9s\tremaining: 1m 21s\n",
      "334:\tlearn: 0.2966356\ttotal: 41s\tremaining: 1m 21s\n",
      "335:\tlearn: 0.2965810\ttotal: 41.1s\tremaining: 1m 21s\n",
      "336:\tlearn: 0.2965410\ttotal: 41.2s\tremaining: 1m 20s\n",
      "337:\tlearn: 0.2964920\ttotal: 41.3s\tremaining: 1m 20s\n",
      "338:\tlearn: 0.2964392\ttotal: 41.4s\tremaining: 1m 20s\n",
      "339:\tlearn: 0.2963897\ttotal: 41.5s\tremaining: 1m 20s\n",
      "340:\tlearn: 0.2963333\ttotal: 41.6s\tremaining: 1m 20s\n",
      "341:\tlearn: 0.2962760\ttotal: 41.7s\tremaining: 1m 20s\n",
      "342:\tlearn: 0.2962183\ttotal: 41.8s\tremaining: 1m 20s\n",
      "343:\tlearn: 0.2961575\ttotal: 41.9s\tremaining: 1m 19s\n",
      "344:\tlearn: 0.2960886\ttotal: 42s\tremaining: 1m 19s\n",
      "345:\tlearn: 0.2960543\ttotal: 42.1s\tremaining: 1m 19s\n",
      "346:\tlearn: 0.2959994\ttotal: 42.2s\tremaining: 1m 19s\n",
      "347:\tlearn: 0.2959485\ttotal: 42.3s\tremaining: 1m 19s\n",
      "348:\tlearn: 0.2959087\ttotal: 42.4s\tremaining: 1m 19s\n",
      "349:\tlearn: 0.2958662\ttotal: 42.5s\tremaining: 1m 18s\n",
      "350:\tlearn: 0.2958124\ttotal: 42.6s\tremaining: 1m 18s\n",
      "351:\tlearn: 0.2957454\ttotal: 42.7s\tremaining: 1m 18s\n",
      "352:\tlearn: 0.2956746\ttotal: 42.8s\tremaining: 1m 18s\n",
      "353:\tlearn: 0.2956281\ttotal: 42.9s\tremaining: 1m 18s\n",
      "354:\tlearn: 0.2955484\ttotal: 43s\tremaining: 1m 18s\n",
      "355:\tlearn: 0.2955026\ttotal: 43.1s\tremaining: 1m 17s\n",
      "356:\tlearn: 0.2954586\ttotal: 43.1s\tremaining: 1m 17s\n",
      "357:\tlearn: 0.2954169\ttotal: 43.3s\tremaining: 1m 17s\n",
      "358:\tlearn: 0.2953724\ttotal: 43.4s\tremaining: 1m 17s\n",
      "359:\tlearn: 0.2953156\ttotal: 43.4s\tremaining: 1m 17s\n",
      "360:\tlearn: 0.2952479\ttotal: 43.5s\tremaining: 1m 17s\n",
      "361:\tlearn: 0.2952076\ttotal: 43.7s\tremaining: 1m 16s\n",
      "362:\tlearn: 0.2951709\ttotal: 43.7s\tremaining: 1m 16s\n",
      "363:\tlearn: 0.2951199\ttotal: 43.9s\tremaining: 1m 16s\n",
      "364:\tlearn: 0.2950608\ttotal: 43.9s\tremaining: 1m 16s\n",
      "365:\tlearn: 0.2950243\ttotal: 44s\tremaining: 1m 16s\n",
      "366:\tlearn: 0.2949720\ttotal: 44.1s\tremaining: 1m 16s\n",
      "367:\tlearn: 0.2949141\ttotal: 44.2s\tremaining: 1m 15s\n",
      "368:\tlearn: 0.2948631\ttotal: 44.3s\tremaining: 1m 15s\n",
      "369:\tlearn: 0.2948061\ttotal: 44.5s\tremaining: 1m 15s\n",
      "370:\tlearn: 0.2947516\ttotal: 44.5s\tremaining: 1m 15s\n",
      "371:\tlearn: 0.2947040\ttotal: 44.6s\tremaining: 1m 15s\n",
      "372:\tlearn: 0.2946600\ttotal: 44.7s\tremaining: 1m 15s\n",
      "373:\tlearn: 0.2946074\ttotal: 44.8s\tremaining: 1m 15s\n",
      "374:\tlearn: 0.2945588\ttotal: 44.9s\tremaining: 1m 14s\n",
      "375:\tlearn: 0.2945119\ttotal: 45s\tremaining: 1m 14s\n",
      "376:\tlearn: 0.2944828\ttotal: 45.1s\tremaining: 1m 14s\n",
      "377:\tlearn: 0.2944357\ttotal: 45.2s\tremaining: 1m 14s\n",
      "378:\tlearn: 0.2943835\ttotal: 45.3s\tremaining: 1m 14s\n",
      "379:\tlearn: 0.2943357\ttotal: 45.4s\tremaining: 1m 14s\n",
      "380:\tlearn: 0.2942805\ttotal: 45.5s\tremaining: 1m 13s\n",
      "381:\tlearn: 0.2942343\ttotal: 45.6s\tremaining: 1m 13s\n",
      "382:\tlearn: 0.2941914\ttotal: 45.7s\tremaining: 1m 13s\n",
      "383:\tlearn: 0.2941452\ttotal: 45.8s\tremaining: 1m 13s\n",
      "384:\tlearn: 0.2940902\ttotal: 45.9s\tremaining: 1m 13s\n",
      "385:\tlearn: 0.2940246\ttotal: 46s\tremaining: 1m 13s\n",
      "386:\tlearn: 0.2939777\ttotal: 46.1s\tremaining: 1m 13s\n",
      "387:\tlearn: 0.2939289\ttotal: 46.2s\tremaining: 1m 12s\n",
      "388:\tlearn: 0.2938745\ttotal: 46.3s\tremaining: 1m 12s\n",
      "389:\tlearn: 0.2938397\ttotal: 46.4s\tremaining: 1m 12s\n",
      "390:\tlearn: 0.2937895\ttotal: 46.5s\tremaining: 1m 12s\n",
      "391:\tlearn: 0.2937436\ttotal: 46.7s\tremaining: 1m 12s\n",
      "392:\tlearn: 0.2937037\ttotal: 46.8s\tremaining: 1m 12s\n",
      "393:\tlearn: 0.2936551\ttotal: 46.9s\tremaining: 1m 12s\n",
      "394:\tlearn: 0.2936274\ttotal: 46.9s\tremaining: 1m 11s\n",
      "395:\tlearn: 0.2935671\ttotal: 47s\tremaining: 1m 11s\n",
      "396:\tlearn: 0.2935016\ttotal: 47.2s\tremaining: 1m 11s\n",
      "397:\tlearn: 0.2934626\ttotal: 47.3s\tremaining: 1m 11s\n",
      "398:\tlearn: 0.2934183\ttotal: 47.3s\tremaining: 1m 11s\n",
      "399:\tlearn: 0.2933658\ttotal: 47.5s\tremaining: 1m 11s\n",
      "400:\tlearn: 0.2933176\ttotal: 47.6s\tremaining: 1m 11s\n",
      "401:\tlearn: 0.2932842\ttotal: 47.7s\tremaining: 1m 10s\n",
      "402:\tlearn: 0.2932418\ttotal: 47.8s\tremaining: 1m 10s\n",
      "403:\tlearn: 0.2931880\ttotal: 47.9s\tremaining: 1m 10s\n",
      "404:\tlearn: 0.2931419\ttotal: 48s\tremaining: 1m 10s\n",
      "405:\tlearn: 0.2931016\ttotal: 48.1s\tremaining: 1m 10s\n",
      "406:\tlearn: 0.2930028\ttotal: 48.2s\tremaining: 1m 10s\n",
      "407:\tlearn: 0.2929237\ttotal: 48.3s\tremaining: 1m 10s\n",
      "408:\tlearn: 0.2928616\ttotal: 48.4s\tremaining: 1m 9s\n",
      "409:\tlearn: 0.2928387\ttotal: 48.5s\tremaining: 1m 9s\n",
      "410:\tlearn: 0.2927809\ttotal: 48.6s\tremaining: 1m 9s\n",
      "411:\tlearn: 0.2927202\ttotal: 48.7s\tremaining: 1m 9s\n",
      "412:\tlearn: 0.2926742\ttotal: 48.8s\tremaining: 1m 9s\n",
      "413:\tlearn: 0.2926251\ttotal: 48.9s\tremaining: 1m 9s\n",
      "414:\tlearn: 0.2925769\ttotal: 49s\tremaining: 1m 9s\n",
      "415:\tlearn: 0.2925158\ttotal: 49.1s\tremaining: 1m 8s\n",
      "416:\tlearn: 0.2924619\ttotal: 49.2s\tremaining: 1m 8s\n",
      "417:\tlearn: 0.2924215\ttotal: 49.3s\tremaining: 1m 8s\n",
      "418:\tlearn: 0.2923723\ttotal: 49.4s\tremaining: 1m 8s\n",
      "419:\tlearn: 0.2923101\ttotal: 49.5s\tremaining: 1m 8s\n",
      "420:\tlearn: 0.2922505\ttotal: 49.6s\tremaining: 1m 8s\n",
      "421:\tlearn: 0.2921955\ttotal: 49.7s\tremaining: 1m 8s\n",
      "422:\tlearn: 0.2921542\ttotal: 49.8s\tremaining: 1m 7s\n",
      "423:\tlearn: 0.2920897\ttotal: 49.9s\tremaining: 1m 7s\n",
      "424:\tlearn: 0.2920619\ttotal: 50s\tremaining: 1m 7s\n",
      "425:\tlearn: 0.2920004\ttotal: 50.1s\tremaining: 1m 7s\n",
      "426:\tlearn: 0.2919342\ttotal: 50.2s\tremaining: 1m 7s\n",
      "427:\tlearn: 0.2918960\ttotal: 50.3s\tremaining: 1m 7s\n",
      "428:\tlearn: 0.2918467\ttotal: 50.4s\tremaining: 1m 7s\n",
      "429:\tlearn: 0.2918073\ttotal: 50.5s\tremaining: 1m 6s\n",
      "430:\tlearn: 0.2917602\ttotal: 50.6s\tremaining: 1m 6s\n",
      "431:\tlearn: 0.2917079\ttotal: 50.7s\tremaining: 1m 6s\n",
      "432:\tlearn: 0.2916692\ttotal: 50.8s\tremaining: 1m 6s\n",
      "433:\tlearn: 0.2916147\ttotal: 50.9s\tremaining: 1m 6s\n",
      "434:\tlearn: 0.2915556\ttotal: 51s\tremaining: 1m 6s\n",
      "435:\tlearn: 0.2914975\ttotal: 51.1s\tremaining: 1m 6s\n",
      "436:\tlearn: 0.2914362\ttotal: 51.2s\tremaining: 1m 5s\n",
      "437:\tlearn: 0.2913919\ttotal: 51.3s\tremaining: 1m 5s\n",
      "438:\tlearn: 0.2913450\ttotal: 51.4s\tremaining: 1m 5s\n",
      "439:\tlearn: 0.2912709\ttotal: 51.5s\tremaining: 1m 5s\n",
      "440:\tlearn: 0.2912376\ttotal: 51.6s\tremaining: 1m 5s\n",
      "441:\tlearn: 0.2911811\ttotal: 51.7s\tremaining: 1m 5s\n",
      "442:\tlearn: 0.2911258\ttotal: 51.8s\tremaining: 1m 5s\n",
      "443:\tlearn: 0.2910748\ttotal: 51.9s\tremaining: 1m 5s\n",
      "444:\tlearn: 0.2910196\ttotal: 52s\tremaining: 1m 4s\n",
      "445:\tlearn: 0.2909711\ttotal: 52.1s\tremaining: 1m 4s\n",
      "446:\tlearn: 0.2909162\ttotal: 52.2s\tremaining: 1m 4s\n",
      "447:\tlearn: 0.2909037\ttotal: 52.3s\tremaining: 1m 4s\n",
      "448:\tlearn: 0.2908589\ttotal: 52.4s\tremaining: 1m 4s\n",
      "449:\tlearn: 0.2908314\ttotal: 52.5s\tremaining: 1m 4s\n",
      "450:\tlearn: 0.2907836\ttotal: 52.6s\tremaining: 1m 4s\n",
      "451:\tlearn: 0.2907446\ttotal: 52.8s\tremaining: 1m 3s\n",
      "452:\tlearn: 0.2906900\ttotal: 52.9s\tremaining: 1m 3s\n",
      "453:\tlearn: 0.2906403\ttotal: 53s\tremaining: 1m 3s\n",
      "454:\tlearn: 0.2905982\ttotal: 53.1s\tremaining: 1m 3s\n",
      "455:\tlearn: 0.2905400\ttotal: 53.2s\tremaining: 1m 3s\n",
      "456:\tlearn: 0.2904931\ttotal: 53.3s\tremaining: 1m 3s\n",
      "457:\tlearn: 0.2904426\ttotal: 53.4s\tremaining: 1m 3s\n",
      "458:\tlearn: 0.2903834\ttotal: 53.5s\tremaining: 1m 3s\n",
      "459:\tlearn: 0.2903426\ttotal: 53.6s\tremaining: 1m 2s\n",
      "460:\tlearn: 0.2902961\ttotal: 53.7s\tremaining: 1m 2s\n",
      "461:\tlearn: 0.2902463\ttotal: 53.8s\tremaining: 1m 2s\n",
      "462:\tlearn: 0.2902055\ttotal: 53.9s\tremaining: 1m 2s\n",
      "463:\tlearn: 0.2901568\ttotal: 54s\tremaining: 1m 2s\n",
      "464:\tlearn: 0.2900969\ttotal: 54.1s\tremaining: 1m 2s\n",
      "465:\tlearn: 0.2900362\ttotal: 54.2s\tremaining: 1m 2s\n",
      "466:\tlearn: 0.2899759\ttotal: 54.3s\tremaining: 1m 2s\n",
      "467:\tlearn: 0.2899248\ttotal: 54.5s\tremaining: 1m 1s\n",
      "468:\tlearn: 0.2898726\ttotal: 54.6s\tremaining: 1m 1s\n",
      "469:\tlearn: 0.2898250\ttotal: 54.7s\tremaining: 1m 1s\n",
      "470:\tlearn: 0.2897974\ttotal: 54.8s\tremaining: 1m 1s\n",
      "471:\tlearn: 0.2897519\ttotal: 54.8s\tremaining: 1m 1s\n",
      "472:\tlearn: 0.2897084\ttotal: 54.9s\tremaining: 1m 1s\n",
      "473:\tlearn: 0.2896441\ttotal: 55s\tremaining: 1m 1s\n",
      "474:\tlearn: 0.2895939\ttotal: 55.1s\tremaining: 1m\n",
      "475:\tlearn: 0.2895451\ttotal: 55.2s\tremaining: 1m\n",
      "476:\tlearn: 0.2895054\ttotal: 55.3s\tremaining: 1m\n",
      "477:\tlearn: 0.2894631\ttotal: 55.4s\tremaining: 1m\n",
      "478:\tlearn: 0.2894326\ttotal: 55.5s\tremaining: 1m\n",
      "479:\tlearn: 0.2893784\ttotal: 55.6s\tremaining: 1m\n",
      "480:\tlearn: 0.2893211\ttotal: 55.7s\tremaining: 1m\n",
      "481:\tlearn: 0.2892957\ttotal: 55.8s\tremaining: 60s\n",
      "482:\tlearn: 0.2892570\ttotal: 55.9s\tremaining: 59.8s\n",
      "483:\tlearn: 0.2892143\ttotal: 56s\tremaining: 59.7s\n",
      "484:\tlearn: 0.2891603\ttotal: 56.1s\tremaining: 59.5s\n",
      "485:\tlearn: 0.2891035\ttotal: 56.1s\tremaining: 59.4s\n",
      "486:\tlearn: 0.2890389\ttotal: 56.2s\tremaining: 59.3s\n",
      "487:\tlearn: 0.2890239\ttotal: 56.3s\tremaining: 59.1s\n",
      "488:\tlearn: 0.2889714\ttotal: 56.4s\tremaining: 59s\n",
      "489:\tlearn: 0.2889078\ttotal: 56.5s\tremaining: 58.8s\n",
      "490:\tlearn: 0.2888738\ttotal: 56.7s\tremaining: 58.7s\n",
      "491:\tlearn: 0.2888204\ttotal: 56.8s\tremaining: 58.6s\n",
      "492:\tlearn: 0.2887807\ttotal: 56.9s\tremaining: 58.5s\n",
      "493:\tlearn: 0.2887394\ttotal: 57s\tremaining: 58.4s\n",
      "494:\tlearn: 0.2886933\ttotal: 57.1s\tremaining: 58.3s\n",
      "495:\tlearn: 0.2886474\ttotal: 57.2s\tremaining: 58.1s\n",
      "496:\tlearn: 0.2886085\ttotal: 57.3s\tremaining: 58s\n",
      "497:\tlearn: 0.2885610\ttotal: 57.4s\tremaining: 57.9s\n",
      "498:\tlearn: 0.2885194\ttotal: 57.5s\tremaining: 57.8s\n",
      "499:\tlearn: 0.2884850\ttotal: 57.6s\tremaining: 57.6s\n",
      "500:\tlearn: 0.2884383\ttotal: 57.7s\tremaining: 57.5s\n",
      "501:\tlearn: 0.2884334\ttotal: 57.8s\tremaining: 57.4s\n",
      "502:\tlearn: 0.2883840\ttotal: 57.9s\tremaining: 57.2s\n",
      "503:\tlearn: 0.2883244\ttotal: 58s\tremaining: 57.1s\n",
      "504:\tlearn: 0.2882873\ttotal: 58.1s\tremaining: 57s\n",
      "505:\tlearn: 0.2882357\ttotal: 58.2s\tremaining: 56.9s\n",
      "506:\tlearn: 0.2882109\ttotal: 58.3s\tremaining: 56.7s\n",
      "507:\tlearn: 0.2881836\ttotal: 58.4s\tremaining: 56.6s\n",
      "508:\tlearn: 0.2881275\ttotal: 58.5s\tremaining: 56.5s\n",
      "509:\tlearn: 0.2880775\ttotal: 58.7s\tremaining: 56.4s\n",
      "510:\tlearn: 0.2880261\ttotal: 58.7s\tremaining: 56.2s\n",
      "511:\tlearn: 0.2879769\ttotal: 58.9s\tremaining: 56.1s\n",
      "512:\tlearn: 0.2879416\ttotal: 58.9s\tremaining: 56s\n",
      "513:\tlearn: 0.2879199\ttotal: 59.1s\tremaining: 55.9s\n",
      "514:\tlearn: 0.2878937\ttotal: 59.2s\tremaining: 55.8s\n",
      "515:\tlearn: 0.2878380\ttotal: 59.4s\tremaining: 55.7s\n",
      "516:\tlearn: 0.2877916\ttotal: 59.6s\tremaining: 55.7s\n",
      "517:\tlearn: 0.2877537\ttotal: 59.7s\tremaining: 55.6s\n",
      "518:\tlearn: 0.2877016\ttotal: 59.8s\tremaining: 55.5s\n",
      "519:\tlearn: 0.2876395\ttotal: 60s\tremaining: 55.3s\n",
      "520:\tlearn: 0.2875942\ttotal: 1m\tremaining: 55.2s\n",
      "521:\tlearn: 0.2875523\ttotal: 1m\tremaining: 55.1s\n",
      "522:\tlearn: 0.2875179\ttotal: 1m\tremaining: 55s\n",
      "523:\tlearn: 0.2874808\ttotal: 1m\tremaining: 54.9s\n",
      "524:\tlearn: 0.2874222\ttotal: 1m\tremaining: 54.8s\n",
      "525:\tlearn: 0.2873789\ttotal: 1m\tremaining: 54.7s\n",
      "526:\tlearn: 0.2873415\ttotal: 1m\tremaining: 54.6s\n",
      "527:\tlearn: 0.2873066\ttotal: 1m\tremaining: 54.5s\n",
      "528:\tlearn: 0.2872559\ttotal: 1m 1s\tremaining: 54.4s\n",
      "529:\tlearn: 0.2872039\ttotal: 1m 1s\tremaining: 54.3s\n",
      "530:\tlearn: 0.2871515\ttotal: 1m 1s\tremaining: 54.2s\n",
      "531:\tlearn: 0.2871019\ttotal: 1m 1s\tremaining: 54.1s\n",
      "532:\tlearn: 0.2870554\ttotal: 1m 1s\tremaining: 54s\n",
      "533:\tlearn: 0.2870193\ttotal: 1m 1s\tremaining: 53.9s\n",
      "534:\tlearn: 0.2869717\ttotal: 1m 1s\tremaining: 53.8s\n",
      "535:\tlearn: 0.2869007\ttotal: 1m 1s\tremaining: 53.7s\n",
      "536:\tlearn: 0.2868607\ttotal: 1m 2s\tremaining: 53.5s\n",
      "537:\tlearn: 0.2868176\ttotal: 1m 2s\tremaining: 53.4s\n",
      "538:\tlearn: 0.2867775\ttotal: 1m 2s\tremaining: 53.3s\n",
      "539:\tlearn: 0.2867524\ttotal: 1m 2s\tremaining: 53.2s\n",
      "540:\tlearn: 0.2867180\ttotal: 1m 2s\tremaining: 53.1s\n",
      "541:\tlearn: 0.2866822\ttotal: 1m 2s\tremaining: 53s\n",
      "542:\tlearn: 0.2866384\ttotal: 1m 2s\tremaining: 52.9s\n",
      "543:\tlearn: 0.2865995\ttotal: 1m 2s\tremaining: 52.8s\n",
      "544:\tlearn: 0.2865930\ttotal: 1m 3s\tremaining: 52.7s\n",
      "545:\tlearn: 0.2865480\ttotal: 1m 3s\tremaining: 52.6s\n",
      "546:\tlearn: 0.2864860\ttotal: 1m 3s\tremaining: 52.5s\n",
      "547:\tlearn: 0.2864541\ttotal: 1m 3s\tremaining: 52.4s\n",
      "548:\tlearn: 0.2864165\ttotal: 1m 3s\tremaining: 52.3s\n",
      "549:\tlearn: 0.2863803\ttotal: 1m 3s\tremaining: 52.2s\n",
      "550:\tlearn: 0.2863234\ttotal: 1m 3s\tremaining: 52s\n",
      "551:\tlearn: 0.2862953\ttotal: 1m 3s\tremaining: 51.9s\n",
      "552:\tlearn: 0.2862607\ttotal: 1m 4s\tremaining: 51.8s\n",
      "553:\tlearn: 0.2862192\ttotal: 1m 4s\tremaining: 51.7s\n",
      "554:\tlearn: 0.2861801\ttotal: 1m 4s\tremaining: 51.6s\n",
      "555:\tlearn: 0.2861339\ttotal: 1m 4s\tremaining: 51.6s\n",
      "556:\tlearn: 0.2860828\ttotal: 1m 4s\tremaining: 51.5s\n",
      "557:\tlearn: 0.2860110\ttotal: 1m 4s\tremaining: 51.4s\n",
      "558:\tlearn: 0.2859563\ttotal: 1m 5s\tremaining: 51.3s\n",
      "559:\tlearn: 0.2859027\ttotal: 1m 5s\tremaining: 51.2s\n",
      "560:\tlearn: 0.2858661\ttotal: 1m 5s\tremaining: 51.1s\n",
      "561:\tlearn: 0.2858129\ttotal: 1m 5s\tremaining: 50.9s\n",
      "562:\tlearn: 0.2857901\ttotal: 1m 5s\tremaining: 50.9s\n",
      "563:\tlearn: 0.2857290\ttotal: 1m 5s\tremaining: 50.7s\n",
      "564:\tlearn: 0.2856830\ttotal: 1m 5s\tremaining: 50.6s\n",
      "565:\tlearn: 0.2856352\ttotal: 1m 5s\tremaining: 50.6s\n",
      "566:\tlearn: 0.2855834\ttotal: 1m 6s\tremaining: 50.5s\n",
      "567:\tlearn: 0.2855384\ttotal: 1m 6s\tremaining: 50.4s\n",
      "568:\tlearn: 0.2854944\ttotal: 1m 6s\tremaining: 50.3s\n",
      "569:\tlearn: 0.2854502\ttotal: 1m 6s\tremaining: 50.1s\n",
      "570:\tlearn: 0.2853984\ttotal: 1m 6s\tremaining: 50s\n",
      "571:\tlearn: 0.2853569\ttotal: 1m 6s\tremaining: 49.9s\n",
      "572:\tlearn: 0.2853190\ttotal: 1m 6s\tremaining: 49.8s\n",
      "573:\tlearn: 0.2852874\ttotal: 1m 6s\tremaining: 49.7s\n",
      "574:\tlearn: 0.2852490\ttotal: 1m 7s\tremaining: 49.6s\n",
      "575:\tlearn: 0.2852181\ttotal: 1m 7s\tremaining: 49.5s\n",
      "576:\tlearn: 0.2852151\ttotal: 1m 7s\tremaining: 49.3s\n",
      "577:\tlearn: 0.2851574\ttotal: 1m 7s\tremaining: 49.2s\n",
      "578:\tlearn: 0.2850958\ttotal: 1m 7s\tremaining: 49.1s\n",
      "579:\tlearn: 0.2850485\ttotal: 1m 7s\tremaining: 49s\n",
      "580:\tlearn: 0.2849938\ttotal: 1m 7s\tremaining: 48.9s\n",
      "581:\tlearn: 0.2849597\ttotal: 1m 7s\tremaining: 48.8s\n",
      "582:\tlearn: 0.2849112\ttotal: 1m 8s\tremaining: 48.7s\n",
      "583:\tlearn: 0.2848669\ttotal: 1m 8s\tremaining: 48.5s\n",
      "584:\tlearn: 0.2848102\ttotal: 1m 8s\tremaining: 48.4s\n",
      "585:\tlearn: 0.2847728\ttotal: 1m 8s\tremaining: 48.3s\n",
      "586:\tlearn: 0.2847357\ttotal: 1m 8s\tremaining: 48.2s\n",
      "587:\tlearn: 0.2846863\ttotal: 1m 8s\tremaining: 48.1s\n",
      "588:\tlearn: 0.2846755\ttotal: 1m 8s\tremaining: 48s\n",
      "589:\tlearn: 0.2846160\ttotal: 1m 8s\tremaining: 47.9s\n",
      "590:\tlearn: 0.2845760\ttotal: 1m 8s\tremaining: 47.7s\n",
      "591:\tlearn: 0.2845166\ttotal: 1m 9s\tremaining: 47.6s\n",
      "592:\tlearn: 0.2844829\ttotal: 1m 9s\tremaining: 47.5s\n",
      "593:\tlearn: 0.2844318\ttotal: 1m 9s\tremaining: 47.4s\n",
      "594:\tlearn: 0.2844007\ttotal: 1m 9s\tremaining: 47.3s\n",
      "595:\tlearn: 0.2843655\ttotal: 1m 9s\tremaining: 47.2s\n",
      "596:\tlearn: 0.2843114\ttotal: 1m 9s\tremaining: 47.1s\n",
      "597:\tlearn: 0.2842854\ttotal: 1m 9s\tremaining: 47s\n",
      "598:\tlearn: 0.2842355\ttotal: 1m 10s\tremaining: 46.9s\n",
      "599:\tlearn: 0.2841987\ttotal: 1m 10s\tremaining: 46.8s\n",
      "600:\tlearn: 0.2841575\ttotal: 1m 10s\tremaining: 46.6s\n",
      "601:\tlearn: 0.2841114\ttotal: 1m 10s\tremaining: 46.5s\n",
      "602:\tlearn: 0.2840776\ttotal: 1m 10s\tremaining: 46.4s\n",
      "603:\tlearn: 0.2840278\ttotal: 1m 10s\tremaining: 46.3s\n",
      "604:\tlearn: 0.2839699\ttotal: 1m 10s\tremaining: 46.2s\n",
      "605:\tlearn: 0.2839051\ttotal: 1m 10s\tremaining: 46.1s\n",
      "606:\tlearn: 0.2838611\ttotal: 1m 11s\tremaining: 46s\n",
      "607:\tlearn: 0.2838281\ttotal: 1m 11s\tremaining: 45.9s\n",
      "608:\tlearn: 0.2837926\ttotal: 1m 11s\tremaining: 45.8s\n",
      "609:\tlearn: 0.2837536\ttotal: 1m 11s\tremaining: 45.7s\n",
      "610:\tlearn: 0.2837129\ttotal: 1m 11s\tremaining: 45.6s\n",
      "611:\tlearn: 0.2836672\ttotal: 1m 11s\tremaining: 45.5s\n",
      "612:\tlearn: 0.2836158\ttotal: 1m 11s\tremaining: 45.4s\n",
      "613:\tlearn: 0.2835897\ttotal: 1m 12s\tremaining: 45.3s\n",
      "614:\tlearn: 0.2835458\ttotal: 1m 12s\tremaining: 45.2s\n",
      "615:\tlearn: 0.2834900\ttotal: 1m 12s\tremaining: 45.1s\n",
      "616:\tlearn: 0.2834404\ttotal: 1m 12s\tremaining: 45s\n",
      "617:\tlearn: 0.2833875\ttotal: 1m 12s\tremaining: 44.9s\n",
      "618:\tlearn: 0.2833279\ttotal: 1m 12s\tremaining: 44.8s\n",
      "619:\tlearn: 0.2832707\ttotal: 1m 12s\tremaining: 44.7s\n",
      "620:\tlearn: 0.2832221\ttotal: 1m 13s\tremaining: 44.6s\n",
      "621:\tlearn: 0.2831996\ttotal: 1m 13s\tremaining: 44.5s\n",
      "622:\tlearn: 0.2831613\ttotal: 1m 13s\tremaining: 44.4s\n",
      "623:\tlearn: 0.2831186\ttotal: 1m 13s\tremaining: 44.3s\n",
      "624:\tlearn: 0.2830804\ttotal: 1m 13s\tremaining: 44.2s\n",
      "625:\tlearn: 0.2830251\ttotal: 1m 13s\tremaining: 44.1s\n",
      "626:\tlearn: 0.2829834\ttotal: 1m 13s\tremaining: 44s\n",
      "627:\tlearn: 0.2829292\ttotal: 1m 14s\tremaining: 43.9s\n",
      "628:\tlearn: 0.2828741\ttotal: 1m 14s\tremaining: 43.8s\n",
      "629:\tlearn: 0.2828222\ttotal: 1m 14s\tremaining: 43.6s\n",
      "630:\tlearn: 0.2827788\ttotal: 1m 14s\tremaining: 43.5s\n",
      "631:\tlearn: 0.2827371\ttotal: 1m 14s\tremaining: 43.4s\n",
      "632:\tlearn: 0.2826849\ttotal: 1m 14s\tremaining: 43.3s\n",
      "633:\tlearn: 0.2826396\ttotal: 1m 14s\tremaining: 43.2s\n",
      "634:\tlearn: 0.2826038\ttotal: 1m 14s\tremaining: 43.1s\n",
      "635:\tlearn: 0.2825660\ttotal: 1m 15s\tremaining: 43s\n",
      "636:\tlearn: 0.2825082\ttotal: 1m 15s\tremaining: 42.8s\n",
      "637:\tlearn: 0.2824552\ttotal: 1m 15s\tremaining: 42.7s\n",
      "638:\tlearn: 0.2823987\ttotal: 1m 15s\tremaining: 42.6s\n",
      "639:\tlearn: 0.2823543\ttotal: 1m 15s\tremaining: 42.5s\n",
      "640:\tlearn: 0.2823073\ttotal: 1m 15s\tremaining: 42.4s\n",
      "641:\tlearn: 0.2822791\ttotal: 1m 15s\tremaining: 42.3s\n",
      "642:\tlearn: 0.2822351\ttotal: 1m 15s\tremaining: 42.2s\n",
      "643:\tlearn: 0.2821854\ttotal: 1m 16s\tremaining: 42s\n",
      "644:\tlearn: 0.2821345\ttotal: 1m 16s\tremaining: 41.9s\n",
      "645:\tlearn: 0.2820943\ttotal: 1m 16s\tremaining: 41.8s\n",
      "646:\tlearn: 0.2820615\ttotal: 1m 16s\tremaining: 41.7s\n",
      "647:\tlearn: 0.2820262\ttotal: 1m 16s\tremaining: 41.6s\n",
      "648:\tlearn: 0.2819946\ttotal: 1m 16s\tremaining: 41.5s\n",
      "649:\tlearn: 0.2819535\ttotal: 1m 16s\tremaining: 41.4s\n",
      "650:\tlearn: 0.2819051\ttotal: 1m 17s\tremaining: 41.3s\n",
      "651:\tlearn: 0.2818855\ttotal: 1m 17s\tremaining: 41.2s\n",
      "652:\tlearn: 0.2818571\ttotal: 1m 17s\tremaining: 41s\n",
      "653:\tlearn: 0.2817998\ttotal: 1m 17s\tremaining: 40.9s\n",
      "654:\tlearn: 0.2817620\ttotal: 1m 17s\tremaining: 40.8s\n",
      "655:\tlearn: 0.2817338\ttotal: 1m 17s\tremaining: 40.7s\n",
      "656:\tlearn: 0.2816821\ttotal: 1m 17s\tremaining: 40.6s\n",
      "657:\tlearn: 0.2816469\ttotal: 1m 17s\tremaining: 40.5s\n",
      "658:\tlearn: 0.2816155\ttotal: 1m 17s\tremaining: 40.3s\n",
      "659:\tlearn: 0.2815723\ttotal: 1m 18s\tremaining: 40.2s\n",
      "660:\tlearn: 0.2815305\ttotal: 1m 18s\tremaining: 40.1s\n",
      "661:\tlearn: 0.2814860\ttotal: 1m 18s\tremaining: 40s\n",
      "662:\tlearn: 0.2814326\ttotal: 1m 18s\tremaining: 39.9s\n",
      "663:\tlearn: 0.2813943\ttotal: 1m 18s\tremaining: 39.8s\n",
      "664:\tlearn: 0.2813584\ttotal: 1m 18s\tremaining: 39.6s\n",
      "665:\tlearn: 0.2813105\ttotal: 1m 18s\tremaining: 39.5s\n",
      "666:\tlearn: 0.2812751\ttotal: 1m 18s\tremaining: 39.4s\n",
      "667:\tlearn: 0.2812645\ttotal: 1m 18s\tremaining: 39.3s\n",
      "668:\tlearn: 0.2812255\ttotal: 1m 19s\tremaining: 39.1s\n",
      "669:\tlearn: 0.2811965\ttotal: 1m 19s\tremaining: 39s\n",
      "670:\tlearn: 0.2811425\ttotal: 1m 19s\tremaining: 38.9s\n",
      "671:\tlearn: 0.2811014\ttotal: 1m 19s\tremaining: 38.8s\n",
      "672:\tlearn: 0.2810422\ttotal: 1m 19s\tremaining: 38.7s\n",
      "673:\tlearn: 0.2810063\ttotal: 1m 19s\tremaining: 38.5s\n",
      "674:\tlearn: 0.2809544\ttotal: 1m 19s\tremaining: 38.4s\n",
      "675:\tlearn: 0.2809256\ttotal: 1m 19s\tremaining: 38.3s\n",
      "676:\tlearn: 0.2808718\ttotal: 1m 20s\tremaining: 38.2s\n",
      "677:\tlearn: 0.2808416\ttotal: 1m 20s\tremaining: 38.1s\n",
      "678:\tlearn: 0.2807873\ttotal: 1m 20s\tremaining: 38s\n",
      "679:\tlearn: 0.2807667\ttotal: 1m 20s\tremaining: 37.8s\n",
      "680:\tlearn: 0.2807318\ttotal: 1m 20s\tremaining: 37.7s\n",
      "681:\tlearn: 0.2806813\ttotal: 1m 20s\tremaining: 37.6s\n",
      "682:\tlearn: 0.2806266\ttotal: 1m 20s\tremaining: 37.5s\n",
      "683:\tlearn: 0.2805839\ttotal: 1m 20s\tremaining: 37.3s\n",
      "684:\tlearn: 0.2805763\ttotal: 1m 20s\tremaining: 37.2s\n",
      "685:\tlearn: 0.2805511\ttotal: 1m 21s\tremaining: 37.1s\n",
      "686:\tlearn: 0.2804935\ttotal: 1m 21s\tremaining: 37s\n",
      "687:\tlearn: 0.2804523\ttotal: 1m 21s\tremaining: 36.8s\n",
      "688:\tlearn: 0.2804066\ttotal: 1m 21s\tremaining: 36.7s\n",
      "689:\tlearn: 0.2803618\ttotal: 1m 21s\tremaining: 36.6s\n",
      "690:\tlearn: 0.2803187\ttotal: 1m 21s\tremaining: 36.6s\n",
      "691:\tlearn: 0.2802726\ttotal: 1m 21s\tremaining: 36.4s\n",
      "692:\tlearn: 0.2802459\ttotal: 1m 22s\tremaining: 36.3s\n",
      "693:\tlearn: 0.2801867\ttotal: 1m 22s\tremaining: 36.2s\n",
      "694:\tlearn: 0.2801553\ttotal: 1m 22s\tremaining: 36.1s\n",
      "695:\tlearn: 0.2801152\ttotal: 1m 22s\tremaining: 36s\n",
      "696:\tlearn: 0.2800766\ttotal: 1m 22s\tremaining: 35.9s\n",
      "697:\tlearn: 0.2800389\ttotal: 1m 22s\tremaining: 35.8s\n",
      "698:\tlearn: 0.2799894\ttotal: 1m 22s\tremaining: 35.7s\n",
      "699:\tlearn: 0.2799324\ttotal: 1m 23s\tremaining: 35.6s\n",
      "700:\tlearn: 0.2798821\ttotal: 1m 23s\tremaining: 35.5s\n",
      "701:\tlearn: 0.2798427\ttotal: 1m 23s\tremaining: 35.3s\n",
      "702:\tlearn: 0.2797942\ttotal: 1m 23s\tremaining: 35.2s\n",
      "703:\tlearn: 0.2797666\ttotal: 1m 23s\tremaining: 35.1s\n",
      "704:\tlearn: 0.2797481\ttotal: 1m 23s\tremaining: 35s\n",
      "705:\tlearn: 0.2797123\ttotal: 1m 23s\tremaining: 34.9s\n",
      "706:\tlearn: 0.2796804\ttotal: 1m 23s\tremaining: 34.8s\n",
      "707:\tlearn: 0.2796445\ttotal: 1m 24s\tremaining: 34.7s\n",
      "708:\tlearn: 0.2796018\ttotal: 1m 24s\tremaining: 34.6s\n",
      "709:\tlearn: 0.2795503\ttotal: 1m 24s\tremaining: 34.5s\n",
      "710:\tlearn: 0.2795065\ttotal: 1m 24s\tremaining: 34.4s\n",
      "711:\tlearn: 0.2794548\ttotal: 1m 24s\tremaining: 34.3s\n",
      "712:\tlearn: 0.2794245\ttotal: 1m 24s\tremaining: 34.2s\n",
      "713:\tlearn: 0.2793659\ttotal: 1m 25s\tremaining: 34.1s\n",
      "714:\tlearn: 0.2793247\ttotal: 1m 25s\tremaining: 34s\n",
      "715:\tlearn: 0.2792848\ttotal: 1m 25s\tremaining: 33.8s\n",
      "716:\tlearn: 0.2792552\ttotal: 1m 25s\tremaining: 33.7s\n",
      "717:\tlearn: 0.2792184\ttotal: 1m 25s\tremaining: 33.6s\n",
      "718:\tlearn: 0.2791616\ttotal: 1m 25s\tremaining: 33.5s\n",
      "719:\tlearn: 0.2791489\ttotal: 1m 25s\tremaining: 33.4s\n",
      "720:\tlearn: 0.2791179\ttotal: 1m 26s\tremaining: 33.3s\n",
      "721:\tlearn: 0.2790702\ttotal: 1m 26s\tremaining: 33.2s\n",
      "722:\tlearn: 0.2790451\ttotal: 1m 26s\tremaining: 33.1s\n",
      "723:\tlearn: 0.2790017\ttotal: 1m 26s\tremaining: 33s\n",
      "724:\tlearn: 0.2789531\ttotal: 1m 26s\tremaining: 32.8s\n",
      "725:\tlearn: 0.2789251\ttotal: 1m 26s\tremaining: 32.7s\n",
      "726:\tlearn: 0.2788824\ttotal: 1m 26s\tremaining: 32.6s\n",
      "727:\tlearn: 0.2788322\ttotal: 1m 27s\tremaining: 32.5s\n",
      "728:\tlearn: 0.2787953\ttotal: 1m 27s\tremaining: 32.4s\n",
      "729:\tlearn: 0.2787504\ttotal: 1m 27s\tremaining: 32.3s\n",
      "730:\tlearn: 0.2787181\ttotal: 1m 27s\tremaining: 32.2s\n",
      "731:\tlearn: 0.2787020\ttotal: 1m 27s\tremaining: 32.1s\n",
      "732:\tlearn: 0.2786725\ttotal: 1m 27s\tremaining: 32s\n",
      "733:\tlearn: 0.2786237\ttotal: 1m 27s\tremaining: 31.9s\n",
      "734:\tlearn: 0.2785660\ttotal: 1m 28s\tremaining: 31.8s\n",
      "735:\tlearn: 0.2785265\ttotal: 1m 28s\tremaining: 31.6s\n",
      "736:\tlearn: 0.2784860\ttotal: 1m 28s\tremaining: 31.5s\n",
      "737:\tlearn: 0.2784425\ttotal: 1m 28s\tremaining: 31.4s\n",
      "738:\tlearn: 0.2783974\ttotal: 1m 28s\tremaining: 31.3s\n",
      "739:\tlearn: 0.2783689\ttotal: 1m 28s\tremaining: 31.2s\n",
      "740:\tlearn: 0.2783218\ttotal: 1m 28s\tremaining: 31.1s\n",
      "741:\tlearn: 0.2782618\ttotal: 1m 29s\tremaining: 31s\n",
      "742:\tlearn: 0.2782140\ttotal: 1m 29s\tremaining: 30.9s\n",
      "743:\tlearn: 0.2781723\ttotal: 1m 29s\tremaining: 30.8s\n",
      "744:\tlearn: 0.2781141\ttotal: 1m 29s\tremaining: 30.7s\n",
      "745:\tlearn: 0.2780961\ttotal: 1m 29s\tremaining: 30.5s\n",
      "746:\tlearn: 0.2780631\ttotal: 1m 29s\tremaining: 30.4s\n",
      "747:\tlearn: 0.2780220\ttotal: 1m 29s\tremaining: 30.3s\n",
      "748:\tlearn: 0.2779958\ttotal: 1m 30s\tremaining: 30.2s\n",
      "749:\tlearn: 0.2779693\ttotal: 1m 30s\tremaining: 30.1s\n",
      "750:\tlearn: 0.2779134\ttotal: 1m 30s\tremaining: 30s\n",
      "751:\tlearn: 0.2778828\ttotal: 1m 30s\tremaining: 29.9s\n",
      "752:\tlearn: 0.2778279\ttotal: 1m 30s\tremaining: 29.8s\n",
      "753:\tlearn: 0.2777894\ttotal: 1m 30s\tremaining: 29.6s\n",
      "754:\tlearn: 0.2777428\ttotal: 1m 31s\tremaining: 29.5s\n",
      "755:\tlearn: 0.2776845\ttotal: 1m 31s\tremaining: 29.4s\n",
      "756:\tlearn: 0.2776321\ttotal: 1m 31s\tremaining: 29.3s\n",
      "757:\tlearn: 0.2775979\ttotal: 1m 31s\tremaining: 29.2s\n",
      "758:\tlearn: 0.2775510\ttotal: 1m 31s\tremaining: 29.1s\n",
      "759:\tlearn: 0.2775134\ttotal: 1m 31s\tremaining: 29s\n",
      "760:\tlearn: 0.2774889\ttotal: 1m 31s\tremaining: 28.9s\n",
      "761:\tlearn: 0.2774439\ttotal: 1m 32s\tremaining: 28.7s\n",
      "762:\tlearn: 0.2774107\ttotal: 1m 32s\tremaining: 28.6s\n",
      "763:\tlearn: 0.2773589\ttotal: 1m 32s\tremaining: 28.5s\n",
      "764:\tlearn: 0.2773253\ttotal: 1m 32s\tremaining: 28.4s\n",
      "765:\tlearn: 0.2772760\ttotal: 1m 32s\tremaining: 28.3s\n",
      "766:\tlearn: 0.2772386\ttotal: 1m 32s\tremaining: 28.2s\n",
      "767:\tlearn: 0.2771899\ttotal: 1m 32s\tremaining: 28.1s\n",
      "768:\tlearn: 0.2771582\ttotal: 1m 33s\tremaining: 28s\n",
      "769:\tlearn: 0.2771251\ttotal: 1m 33s\tremaining: 27.8s\n",
      "770:\tlearn: 0.2770972\ttotal: 1m 33s\tremaining: 27.7s\n",
      "771:\tlearn: 0.2770685\ttotal: 1m 33s\tremaining: 27.6s\n",
      "772:\tlearn: 0.2770260\ttotal: 1m 33s\tremaining: 27.5s\n",
      "773:\tlearn: 0.2769991\ttotal: 1m 33s\tremaining: 27.4s\n",
      "774:\tlearn: 0.2769531\ttotal: 1m 33s\tremaining: 27.3s\n",
      "775:\tlearn: 0.2769082\ttotal: 1m 34s\tremaining: 27.2s\n",
      "776:\tlearn: 0.2768739\ttotal: 1m 34s\tremaining: 27.1s\n",
      "777:\tlearn: 0.2768246\ttotal: 1m 34s\tremaining: 26.9s\n",
      "778:\tlearn: 0.2767971\ttotal: 1m 34s\tremaining: 26.8s\n",
      "779:\tlearn: 0.2767569\ttotal: 1m 34s\tremaining: 26.7s\n",
      "780:\tlearn: 0.2767103\ttotal: 1m 34s\tremaining: 26.6s\n",
      "781:\tlearn: 0.2766780\ttotal: 1m 35s\tremaining: 26.5s\n",
      "782:\tlearn: 0.2766286\ttotal: 1m 35s\tremaining: 26.4s\n",
      "783:\tlearn: 0.2765964\ttotal: 1m 35s\tremaining: 26.3s\n",
      "784:\tlearn: 0.2765681\ttotal: 1m 35s\tremaining: 26.1s\n",
      "785:\tlearn: 0.2765517\ttotal: 1m 35s\tremaining: 26s\n",
      "786:\tlearn: 0.2765165\ttotal: 1m 35s\tremaining: 25.9s\n",
      "787:\tlearn: 0.2764990\ttotal: 1m 35s\tremaining: 25.8s\n",
      "788:\tlearn: 0.2764697\ttotal: 1m 35s\tremaining: 25.7s\n",
      "789:\tlearn: 0.2764327\ttotal: 1m 36s\tremaining: 25.6s\n",
      "790:\tlearn: 0.2763896\ttotal: 1m 36s\tremaining: 25.4s\n",
      "791:\tlearn: 0.2763574\ttotal: 1m 36s\tremaining: 25.3s\n",
      "792:\tlearn: 0.2763147\ttotal: 1m 36s\tremaining: 25.2s\n",
      "793:\tlearn: 0.2762649\ttotal: 1m 36s\tremaining: 25.1s\n",
      "794:\tlearn: 0.2762136\ttotal: 1m 36s\tremaining: 25s\n",
      "795:\tlearn: 0.2761738\ttotal: 1m 36s\tremaining: 24.9s\n",
      "796:\tlearn: 0.2761218\ttotal: 1m 37s\tremaining: 24.7s\n",
      "797:\tlearn: 0.2760983\ttotal: 1m 37s\tremaining: 24.6s\n",
      "798:\tlearn: 0.2760585\ttotal: 1m 37s\tremaining: 24.5s\n",
      "799:\tlearn: 0.2760117\ttotal: 1m 37s\tremaining: 24.4s\n",
      "800:\tlearn: 0.2759661\ttotal: 1m 37s\tremaining: 24.3s\n",
      "801:\tlearn: 0.2759275\ttotal: 1m 37s\tremaining: 24.2s\n",
      "802:\tlearn: 0.2758796\ttotal: 1m 38s\tremaining: 24.1s\n",
      "803:\tlearn: 0.2758280\ttotal: 1m 38s\tremaining: 23.9s\n",
      "804:\tlearn: 0.2757813\ttotal: 1m 38s\tremaining: 23.8s\n",
      "805:\tlearn: 0.2757355\ttotal: 1m 38s\tremaining: 23.7s\n",
      "806:\tlearn: 0.2756885\ttotal: 1m 38s\tremaining: 23.6s\n",
      "807:\tlearn: 0.2756519\ttotal: 1m 38s\tremaining: 23.5s\n",
      "808:\tlearn: 0.2755999\ttotal: 1m 38s\tremaining: 23.4s\n",
      "809:\tlearn: 0.2755575\ttotal: 1m 39s\tremaining: 23.2s\n",
      "810:\tlearn: 0.2755220\ttotal: 1m 39s\tremaining: 23.1s\n",
      "811:\tlearn: 0.2754894\ttotal: 1m 39s\tremaining: 23s\n",
      "812:\tlearn: 0.2754565\ttotal: 1m 39s\tremaining: 22.9s\n",
      "813:\tlearn: 0.2754307\ttotal: 1m 39s\tremaining: 22.8s\n",
      "814:\tlearn: 0.2754140\ttotal: 1m 39s\tremaining: 22.6s\n",
      "815:\tlearn: 0.2753755\ttotal: 1m 39s\tremaining: 22.5s\n",
      "816:\tlearn: 0.2753431\ttotal: 1m 39s\tremaining: 22.4s\n",
      "817:\tlearn: 0.2752977\ttotal: 1m 40s\tremaining: 22.3s\n",
      "818:\tlearn: 0.2752604\ttotal: 1m 40s\tremaining: 22.2s\n",
      "819:\tlearn: 0.2752198\ttotal: 1m 40s\tremaining: 22.1s\n",
      "820:\tlearn: 0.2751666\ttotal: 1m 40s\tremaining: 21.9s\n",
      "821:\tlearn: 0.2751273\ttotal: 1m 40s\tremaining: 21.8s\n",
      "822:\tlearn: 0.2750987\ttotal: 1m 40s\tremaining: 21.7s\n",
      "823:\tlearn: 0.2750529\ttotal: 1m 41s\tremaining: 21.6s\n",
      "824:\tlearn: 0.2750125\ttotal: 1m 41s\tremaining: 21.5s\n",
      "825:\tlearn: 0.2749795\ttotal: 1m 41s\tremaining: 21.3s\n",
      "826:\tlearn: 0.2749281\ttotal: 1m 41s\tremaining: 21.2s\n",
      "827:\tlearn: 0.2748850\ttotal: 1m 41s\tremaining: 21.1s\n",
      "828:\tlearn: 0.2748500\ttotal: 1m 41s\tremaining: 21s\n",
      "829:\tlearn: 0.2748143\ttotal: 1m 41s\tremaining: 20.9s\n",
      "830:\tlearn: 0.2747836\ttotal: 1m 42s\tremaining: 20.8s\n",
      "831:\tlearn: 0.2747690\ttotal: 1m 42s\tremaining: 20.6s\n",
      "832:\tlearn: 0.2747306\ttotal: 1m 42s\tremaining: 20.5s\n",
      "833:\tlearn: 0.2746873\ttotal: 1m 42s\tremaining: 20.4s\n",
      "834:\tlearn: 0.2746401\ttotal: 1m 42s\tremaining: 20.3s\n",
      "835:\tlearn: 0.2746007\ttotal: 1m 42s\tremaining: 20.2s\n",
      "836:\tlearn: 0.2745466\ttotal: 1m 42s\tremaining: 20s\n",
      "837:\tlearn: 0.2745189\ttotal: 1m 43s\tremaining: 19.9s\n",
      "838:\tlearn: 0.2744749\ttotal: 1m 43s\tremaining: 19.8s\n",
      "839:\tlearn: 0.2744320\ttotal: 1m 43s\tremaining: 19.7s\n",
      "840:\tlearn: 0.2743993\ttotal: 1m 43s\tremaining: 19.6s\n",
      "841:\tlearn: 0.2743610\ttotal: 1m 43s\tremaining: 19.4s\n",
      "842:\tlearn: 0.2743283\ttotal: 1m 43s\tremaining: 19.3s\n",
      "843:\tlearn: 0.2742943\ttotal: 1m 43s\tremaining: 19.2s\n",
      "844:\tlearn: 0.2742580\ttotal: 1m 44s\tremaining: 19.1s\n",
      "845:\tlearn: 0.2742359\ttotal: 1m 44s\tremaining: 19s\n",
      "846:\tlearn: 0.2742045\ttotal: 1m 44s\tremaining: 18.8s\n",
      "847:\tlearn: 0.2741746\ttotal: 1m 44s\tremaining: 18.7s\n",
      "848:\tlearn: 0.2741311\ttotal: 1m 44s\tremaining: 18.6s\n",
      "849:\tlearn: 0.2741030\ttotal: 1m 44s\tremaining: 18.5s\n",
      "850:\tlearn: 0.2740639\ttotal: 1m 44s\tremaining: 18.4s\n",
      "851:\tlearn: 0.2740344\ttotal: 1m 44s\tremaining: 18.2s\n",
      "852:\tlearn: 0.2739837\ttotal: 1m 45s\tremaining: 18.1s\n",
      "853:\tlearn: 0.2739430\ttotal: 1m 45s\tremaining: 18s\n",
      "854:\tlearn: 0.2739023\ttotal: 1m 45s\tremaining: 17.9s\n",
      "855:\tlearn: 0.2738604\ttotal: 1m 45s\tremaining: 17.8s\n",
      "856:\tlearn: 0.2738315\ttotal: 1m 45s\tremaining: 17.6s\n",
      "857:\tlearn: 0.2737919\ttotal: 1m 45s\tremaining: 17.5s\n",
      "858:\tlearn: 0.2737602\ttotal: 1m 45s\tremaining: 17.4s\n",
      "859:\tlearn: 0.2737263\ttotal: 1m 46s\tremaining: 17.3s\n",
      "860:\tlearn: 0.2736893\ttotal: 1m 46s\tremaining: 17.2s\n",
      "861:\tlearn: 0.2736573\ttotal: 1m 46s\tremaining: 17s\n",
      "862:\tlearn: 0.2736242\ttotal: 1m 46s\tremaining: 16.9s\n",
      "863:\tlearn: 0.2735865\ttotal: 1m 46s\tremaining: 16.8s\n",
      "864:\tlearn: 0.2735500\ttotal: 1m 46s\tremaining: 16.7s\n",
      "865:\tlearn: 0.2735206\ttotal: 1m 46s\tremaining: 16.5s\n",
      "866:\tlearn: 0.2734816\ttotal: 1m 47s\tremaining: 16.4s\n",
      "867:\tlearn: 0.2734417\ttotal: 1m 47s\tremaining: 16.3s\n",
      "868:\tlearn: 0.2734109\ttotal: 1m 47s\tremaining: 16.2s\n",
      "869:\tlearn: 0.2733941\ttotal: 1m 47s\tremaining: 16.1s\n",
      "870:\tlearn: 0.2733512\ttotal: 1m 47s\tremaining: 15.9s\n",
      "871:\tlearn: 0.2733046\ttotal: 1m 47s\tremaining: 15.8s\n",
      "872:\tlearn: 0.2732498\ttotal: 1m 47s\tremaining: 15.7s\n",
      "873:\tlearn: 0.2732195\ttotal: 1m 48s\tremaining: 15.6s\n",
      "874:\tlearn: 0.2731626\ttotal: 1m 48s\tremaining: 15.5s\n",
      "875:\tlearn: 0.2731248\ttotal: 1m 48s\tremaining: 15.3s\n",
      "876:\tlearn: 0.2730895\ttotal: 1m 48s\tremaining: 15.2s\n",
      "877:\tlearn: 0.2730405\ttotal: 1m 48s\tremaining: 15.1s\n",
      "878:\tlearn: 0.2730287\ttotal: 1m 48s\tremaining: 15s\n",
      "879:\tlearn: 0.2729922\ttotal: 1m 48s\tremaining: 14.9s\n",
      "880:\tlearn: 0.2729570\ttotal: 1m 49s\tremaining: 14.7s\n",
      "881:\tlearn: 0.2729208\ttotal: 1m 49s\tremaining: 14.6s\n",
      "882:\tlearn: 0.2728908\ttotal: 1m 49s\tremaining: 14.5s\n",
      "883:\tlearn: 0.2728483\ttotal: 1m 49s\tremaining: 14.4s\n",
      "884:\tlearn: 0.2728244\ttotal: 1m 49s\tremaining: 14.3s\n",
      "885:\tlearn: 0.2727950\ttotal: 1m 49s\tremaining: 14.1s\n",
      "886:\tlearn: 0.2727583\ttotal: 1m 49s\tremaining: 14s\n",
      "887:\tlearn: 0.2727121\ttotal: 1m 50s\tremaining: 13.9s\n",
      "888:\tlearn: 0.2726658\ttotal: 1m 50s\tremaining: 13.8s\n",
      "889:\tlearn: 0.2726330\ttotal: 1m 50s\tremaining: 13.6s\n",
      "890:\tlearn: 0.2726008\ttotal: 1m 50s\tremaining: 13.5s\n",
      "891:\tlearn: 0.2725634\ttotal: 1m 50s\tremaining: 13.4s\n",
      "892:\tlearn: 0.2725309\ttotal: 1m 50s\tremaining: 13.3s\n",
      "893:\tlearn: 0.2725008\ttotal: 1m 50s\tremaining: 13.2s\n",
      "894:\tlearn: 0.2724632\ttotal: 1m 51s\tremaining: 13s\n",
      "895:\tlearn: 0.2724257\ttotal: 1m 51s\tremaining: 12.9s\n",
      "896:\tlearn: 0.2724041\ttotal: 1m 51s\tremaining: 12.8s\n",
      "897:\tlearn: 0.2723609\ttotal: 1m 51s\tremaining: 12.7s\n",
      "898:\tlearn: 0.2723199\ttotal: 1m 51s\tremaining: 12.5s\n",
      "899:\tlearn: 0.2722737\ttotal: 1m 51s\tremaining: 12.4s\n",
      "900:\tlearn: 0.2722273\ttotal: 1m 51s\tremaining: 12.3s\n",
      "901:\tlearn: 0.2721906\ttotal: 1m 52s\tremaining: 12.2s\n",
      "902:\tlearn: 0.2721487\ttotal: 1m 52s\tremaining: 12.1s\n",
      "903:\tlearn: 0.2720952\ttotal: 1m 52s\tremaining: 11.9s\n",
      "904:\tlearn: 0.2720392\ttotal: 1m 52s\tremaining: 11.8s\n",
      "905:\tlearn: 0.2720155\ttotal: 1m 52s\tremaining: 11.7s\n",
      "906:\tlearn: 0.2719801\ttotal: 1m 52s\tremaining: 11.6s\n",
      "907:\tlearn: 0.2719650\ttotal: 1m 52s\tremaining: 11.4s\n",
      "908:\tlearn: 0.2719401\ttotal: 1m 53s\tremaining: 11.3s\n",
      "909:\tlearn: 0.2718948\ttotal: 1m 53s\tremaining: 11.2s\n",
      "910:\tlearn: 0.2718622\ttotal: 1m 53s\tremaining: 11.1s\n",
      "911:\tlearn: 0.2718366\ttotal: 1m 53s\tremaining: 10.9s\n",
      "912:\tlearn: 0.2717814\ttotal: 1m 53s\tremaining: 10.8s\n",
      "913:\tlearn: 0.2717403\ttotal: 1m 53s\tremaining: 10.7s\n",
      "914:\tlearn: 0.2716915\ttotal: 1m 53s\tremaining: 10.6s\n",
      "915:\tlearn: 0.2716454\ttotal: 1m 53s\tremaining: 10.4s\n",
      "916:\tlearn: 0.2715957\ttotal: 1m 54s\tremaining: 10.3s\n",
      "917:\tlearn: 0.2715532\ttotal: 1m 54s\tremaining: 10.2s\n",
      "918:\tlearn: 0.2715176\ttotal: 1m 54s\tremaining: 10.1s\n",
      "919:\tlearn: 0.2714696\ttotal: 1m 54s\tremaining: 9.95s\n",
      "920:\tlearn: 0.2714338\ttotal: 1m 54s\tremaining: 9.83s\n",
      "921:\tlearn: 0.2714055\ttotal: 1m 54s\tremaining: 9.7s\n",
      "922:\tlearn: 0.2713607\ttotal: 1m 54s\tremaining: 9.58s\n",
      "923:\tlearn: 0.2713205\ttotal: 1m 54s\tremaining: 9.46s\n",
      "924:\tlearn: 0.2712902\ttotal: 1m 55s\tremaining: 9.33s\n",
      "925:\tlearn: 0.2712383\ttotal: 1m 55s\tremaining: 9.21s\n",
      "926:\tlearn: 0.2711886\ttotal: 1m 55s\tremaining: 9.09s\n",
      "927:\tlearn: 0.2711522\ttotal: 1m 55s\tremaining: 8.96s\n",
      "928:\tlearn: 0.2711226\ttotal: 1m 55s\tremaining: 8.84s\n",
      "929:\tlearn: 0.2710902\ttotal: 1m 55s\tremaining: 8.72s\n",
      "930:\tlearn: 0.2710498\ttotal: 1m 55s\tremaining: 8.6s\n",
      "931:\tlearn: 0.2709983\ttotal: 1m 56s\tremaining: 8.47s\n",
      "932:\tlearn: 0.2709736\ttotal: 1m 56s\tremaining: 8.35s\n",
      "933:\tlearn: 0.2709344\ttotal: 1m 56s\tremaining: 8.22s\n",
      "934:\tlearn: 0.2708964\ttotal: 1m 56s\tremaining: 8.1s\n",
      "935:\tlearn: 0.2708633\ttotal: 1m 56s\tremaining: 7.98s\n",
      "936:\tlearn: 0.2708141\ttotal: 1m 56s\tremaining: 7.85s\n",
      "937:\tlearn: 0.2707857\ttotal: 1m 56s\tremaining: 7.73s\n",
      "938:\tlearn: 0.2707379\ttotal: 1m 57s\tremaining: 7.61s\n",
      "939:\tlearn: 0.2706919\ttotal: 1m 57s\tremaining: 7.49s\n",
      "940:\tlearn: 0.2706593\ttotal: 1m 57s\tremaining: 7.36s\n",
      "941:\tlearn: 0.2706140\ttotal: 1m 57s\tremaining: 7.24s\n",
      "942:\tlearn: 0.2705837\ttotal: 1m 57s\tremaining: 7.12s\n",
      "943:\tlearn: 0.2705436\ttotal: 1m 57s\tremaining: 6.99s\n",
      "944:\tlearn: 0.2705280\ttotal: 1m 58s\tremaining: 6.87s\n",
      "945:\tlearn: 0.2705237\ttotal: 1m 58s\tremaining: 6.74s\n",
      "946:\tlearn: 0.2704849\ttotal: 1m 58s\tremaining: 6.62s\n",
      "947:\tlearn: 0.2704506\ttotal: 1m 58s\tremaining: 6.49s\n",
      "948:\tlearn: 0.2704204\ttotal: 1m 58s\tremaining: 6.37s\n",
      "949:\tlearn: 0.2703907\ttotal: 1m 58s\tremaining: 6.25s\n",
      "950:\tlearn: 0.2703552\ttotal: 1m 58s\tremaining: 6.12s\n",
      "951:\tlearn: 0.2703262\ttotal: 1m 58s\tremaining: 6s\n",
      "952:\tlearn: 0.2702868\ttotal: 1m 59s\tremaining: 5.87s\n",
      "953:\tlearn: 0.2702527\ttotal: 1m 59s\tremaining: 5.75s\n",
      "954:\tlearn: 0.2702165\ttotal: 1m 59s\tremaining: 5.63s\n",
      "955:\tlearn: 0.2701884\ttotal: 1m 59s\tremaining: 5.5s\n",
      "956:\tlearn: 0.2701428\ttotal: 1m 59s\tremaining: 5.38s\n",
      "957:\tlearn: 0.2700955\ttotal: 1m 59s\tremaining: 5.25s\n",
      "958:\tlearn: 0.2700505\ttotal: 1m 59s\tremaining: 5.13s\n",
      "959:\tlearn: 0.2700049\ttotal: 2m\tremaining: 5s\n",
      "960:\tlearn: 0.2699543\ttotal: 2m\tremaining: 4.88s\n",
      "961:\tlearn: 0.2699065\ttotal: 2m\tremaining: 4.75s\n",
      "962:\tlearn: 0.2698590\ttotal: 2m\tremaining: 4.63s\n",
      "963:\tlearn: 0.2698253\ttotal: 2m\tremaining: 4.5s\n",
      "964:\tlearn: 0.2697835\ttotal: 2m\tremaining: 4.38s\n",
      "965:\tlearn: 0.2697693\ttotal: 2m\tremaining: 4.25s\n",
      "966:\tlearn: 0.2697384\ttotal: 2m\tremaining: 4.13s\n",
      "967:\tlearn: 0.2697084\ttotal: 2m\tremaining: 4s\n",
      "968:\tlearn: 0.2696630\ttotal: 2m 1s\tremaining: 3.88s\n",
      "969:\tlearn: 0.2696284\ttotal: 2m 1s\tremaining: 3.75s\n",
      "970:\tlearn: 0.2696087\ttotal: 2m 1s\tremaining: 3.63s\n",
      "971:\tlearn: 0.2695649\ttotal: 2m 1s\tremaining: 3.5s\n",
      "972:\tlearn: 0.2695272\ttotal: 2m 1s\tremaining: 3.38s\n",
      "973:\tlearn: 0.2694869\ttotal: 2m 1s\tremaining: 3.25s\n",
      "974:\tlearn: 0.2694548\ttotal: 2m 1s\tremaining: 3.13s\n",
      "975:\tlearn: 0.2694117\ttotal: 2m 2s\tremaining: 3s\n",
      "976:\tlearn: 0.2693554\ttotal: 2m 2s\tremaining: 2.88s\n",
      "977:\tlearn: 0.2693206\ttotal: 2m 2s\tremaining: 2.75s\n",
      "978:\tlearn: 0.2692975\ttotal: 2m 2s\tremaining: 2.63s\n",
      "979:\tlearn: 0.2692588\ttotal: 2m 2s\tremaining: 2.5s\n",
      "980:\tlearn: 0.2692116\ttotal: 2m 2s\tremaining: 2.38s\n",
      "981:\tlearn: 0.2691883\ttotal: 2m 2s\tremaining: 2.25s\n",
      "982:\tlearn: 0.2691465\ttotal: 2m 2s\tremaining: 2.13s\n",
      "983:\tlearn: 0.2691214\ttotal: 2m 3s\tremaining: 2s\n",
      "984:\tlearn: 0.2690823\ttotal: 2m 3s\tremaining: 1.88s\n",
      "985:\tlearn: 0.2690289\ttotal: 2m 3s\tremaining: 1.75s\n",
      "986:\tlearn: 0.2689878\ttotal: 2m 3s\tremaining: 1.63s\n",
      "987:\tlearn: 0.2689590\ttotal: 2m 3s\tremaining: 1.5s\n",
      "988:\tlearn: 0.2689327\ttotal: 2m 3s\tremaining: 1.38s\n",
      "989:\tlearn: 0.2688878\ttotal: 2m 3s\tremaining: 1.25s\n",
      "990:\tlearn: 0.2688496\ttotal: 2m 4s\tremaining: 1.13s\n",
      "991:\tlearn: 0.2687950\ttotal: 2m 4s\tremaining: 1s\n",
      "992:\tlearn: 0.2687494\ttotal: 2m 4s\tremaining: 876ms\n",
      "993:\tlearn: 0.2687006\ttotal: 2m 4s\tremaining: 752ms\n",
      "994:\tlearn: 0.2686586\ttotal: 2m 4s\tremaining: 627ms\n",
      "995:\tlearn: 0.2686224\ttotal: 2m 4s\tremaining: 502ms\n",
      "996:\tlearn: 0.2685808\ttotal: 2m 5s\tremaining: 376ms\n",
      "997:\tlearn: 0.2685418\ttotal: 2m 5s\tremaining: 251ms\n",
      "998:\tlearn: 0.2685090\ttotal: 2m 5s\tremaining: 125ms\n",
      "999:\tlearn: 0.2684781\ttotal: 2m 5s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2c4a3813a60>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "catboost = CatBoostClassifier()\n",
    "\n",
    "catboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = catboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.89      0.92     65666\n",
      "         1.0       0.49      0.69      0.57      9915\n",
      "\n",
      "    accuracy                           0.86     75581\n",
      "   macro avg       0.72      0.79      0.75     75581\n",
      "weighted avg       0.89      0.86      0.87     75581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(X_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### С оверсемплингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearnNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n",
      "     ------------------------------------ 226.0/226.0 kB 726.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (3.1.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.22.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.8.1)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.10.1 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    186799\n",
       "0.0    186799\n",
       "Name: is_owner, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X, Y)\n",
    "y_resampled.value_counts()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7202079683343067"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6318289\ttotal: 309ms\tremaining: 5m 8s\n",
      "1:\tlearn: 0.5849996\ttotal: 595ms\tremaining: 4m 56s\n",
      "2:\tlearn: 0.5096673\ttotal: 861ms\tremaining: 4m 46s\n",
      "3:\tlearn: 0.4592881\ttotal: 1.09s\tremaining: 4m 32s\n",
      "4:\tlearn: 0.4402512\ttotal: 1.35s\tremaining: 4m 29s\n",
      "5:\tlearn: 0.3946773\ttotal: 1.6s\tremaining: 4m 24s\n",
      "6:\tlearn: 0.3664434\ttotal: 1.89s\tremaining: 4m 28s\n",
      "7:\tlearn: 0.3528585\ttotal: 2.22s\tremaining: 4m 35s\n",
      "8:\tlearn: 0.3437503\ttotal: 2.47s\tremaining: 4m 32s\n",
      "9:\tlearn: 0.3270515\ttotal: 2.69s\tremaining: 4m 25s\n",
      "10:\tlearn: 0.3158142\ttotal: 2.92s\tremaining: 4m 22s\n",
      "11:\tlearn: 0.3112493\ttotal: 3.16s\tremaining: 4m 20s\n",
      "12:\tlearn: 0.3048823\ttotal: 3.43s\tremaining: 4m 20s\n",
      "13:\tlearn: 0.2979362\ttotal: 3.63s\tremaining: 4m 15s\n",
      "14:\tlearn: 0.2952592\ttotal: 3.87s\tremaining: 4m 14s\n",
      "15:\tlearn: 0.2891351\ttotal: 4.1s\tremaining: 4m 12s\n",
      "16:\tlearn: 0.2832017\ttotal: 4.34s\tremaining: 4m 11s\n",
      "17:\tlearn: 0.2786852\ttotal: 4.6s\tremaining: 4m 10s\n",
      "18:\tlearn: 0.2765943\ttotal: 4.81s\tremaining: 4m 8s\n",
      "19:\tlearn: 0.2736636\ttotal: 5.04s\tremaining: 4m 6s\n",
      "20:\tlearn: 0.2726151\ttotal: 5.24s\tremaining: 4m 4s\n",
      "21:\tlearn: 0.2715066\ttotal: 5.45s\tremaining: 4m 2s\n",
      "22:\tlearn: 0.2704457\ttotal: 5.63s\tremaining: 3m 59s\n",
      "23:\tlearn: 0.2686033\ttotal: 5.86s\tremaining: 3m 58s\n",
      "24:\tlearn: 0.2654675\ttotal: 6.09s\tremaining: 3m 57s\n",
      "25:\tlearn: 0.2644765\ttotal: 6.29s\tremaining: 3m 55s\n",
      "26:\tlearn: 0.2622054\ttotal: 6.52s\tremaining: 3m 54s\n",
      "27:\tlearn: 0.2603001\ttotal: 6.71s\tremaining: 3m 53s\n",
      "28:\tlearn: 0.2597376\ttotal: 6.92s\tremaining: 3m 51s\n",
      "29:\tlearn: 0.2591436\ttotal: 7.15s\tremaining: 3m 51s\n",
      "30:\tlearn: 0.2586500\ttotal: 7.38s\tremaining: 3m 50s\n",
      "31:\tlearn: 0.2580098\ttotal: 7.64s\tremaining: 3m 51s\n",
      "32:\tlearn: 0.2576586\ttotal: 7.85s\tremaining: 3m 50s\n",
      "33:\tlearn: 0.2570973\ttotal: 8.08s\tremaining: 3m 49s\n",
      "34:\tlearn: 0.2567668\ttotal: 8.31s\tremaining: 3m 49s\n",
      "35:\tlearn: 0.2564827\ttotal: 8.57s\tremaining: 3m 49s\n",
      "36:\tlearn: 0.2552932\ttotal: 8.81s\tremaining: 3m 49s\n",
      "37:\tlearn: 0.2548727\ttotal: 9.03s\tremaining: 3m 48s\n",
      "38:\tlearn: 0.2545713\ttotal: 9.23s\tremaining: 3m 47s\n",
      "39:\tlearn: 0.2538107\ttotal: 9.44s\tremaining: 3m 46s\n",
      "40:\tlearn: 0.2527850\ttotal: 9.65s\tremaining: 3m 45s\n",
      "41:\tlearn: 0.2512682\ttotal: 9.87s\tremaining: 3m 45s\n",
      "42:\tlearn: 0.2509958\ttotal: 10.1s\tremaining: 3m 44s\n",
      "43:\tlearn: 0.2505986\ttotal: 10.3s\tremaining: 3m 44s\n",
      "44:\tlearn: 0.2504159\ttotal: 10.5s\tremaining: 3m 43s\n",
      "45:\tlearn: 0.2499256\ttotal: 10.7s\tremaining: 3m 42s\n",
      "46:\tlearn: 0.2496747\ttotal: 11s\tremaining: 3m 42s\n",
      "47:\tlearn: 0.2494842\ttotal: 11.2s\tremaining: 3m 41s\n",
      "48:\tlearn: 0.2492441\ttotal: 11.4s\tremaining: 3m 41s\n",
      "49:\tlearn: 0.2483378\ttotal: 11.6s\tremaining: 3m 40s\n",
      "50:\tlearn: 0.2481601\ttotal: 11.8s\tremaining: 3m 40s\n",
      "51:\tlearn: 0.2479261\ttotal: 12s\tremaining: 3m 39s\n",
      "52:\tlearn: 0.2474158\ttotal: 12.2s\tremaining: 3m 38s\n",
      "53:\tlearn: 0.2472581\ttotal: 12.5s\tremaining: 3m 38s\n",
      "54:\tlearn: 0.2471192\ttotal: 12.7s\tremaining: 3m 37s\n",
      "55:\tlearn: 0.2469997\ttotal: 12.9s\tremaining: 3m 37s\n",
      "56:\tlearn: 0.2468921\ttotal: 13.1s\tremaining: 3m 36s\n",
      "57:\tlearn: 0.2467863\ttotal: 13.3s\tremaining: 3m 35s\n",
      "58:\tlearn: 0.2463820\ttotal: 13.5s\tremaining: 3m 35s\n",
      "59:\tlearn: 0.2462355\ttotal: 13.7s\tremaining: 3m 35s\n",
      "60:\tlearn: 0.2461365\ttotal: 14s\tremaining: 3m 34s\n",
      "61:\tlearn: 0.2458852\ttotal: 14.2s\tremaining: 3m 35s\n",
      "62:\tlearn: 0.2457473\ttotal: 14.5s\tremaining: 3m 35s\n",
      "63:\tlearn: 0.2456113\ttotal: 14.6s\tremaining: 3m 34s\n",
      "64:\tlearn: 0.2449174\ttotal: 14.9s\tremaining: 3m 33s\n",
      "65:\tlearn: 0.2447440\ttotal: 15.1s\tremaining: 3m 33s\n",
      "66:\tlearn: 0.2446468\ttotal: 15.3s\tremaining: 3m 32s\n",
      "67:\tlearn: 0.2442938\ttotal: 15.5s\tremaining: 3m 32s\n",
      "68:\tlearn: 0.2442161\ttotal: 15.7s\tremaining: 3m 32s\n",
      "69:\tlearn: 0.2441139\ttotal: 16s\tremaining: 3m 31s\n",
      "70:\tlearn: 0.2435551\ttotal: 16.2s\tremaining: 3m 31s\n",
      "71:\tlearn: 0.2434569\ttotal: 16.4s\tremaining: 3m 30s\n",
      "72:\tlearn: 0.2427252\ttotal: 16.6s\tremaining: 3m 30s\n",
      "73:\tlearn: 0.2426240\ttotal: 16.8s\tremaining: 3m 29s\n",
      "74:\tlearn: 0.2425495\ttotal: 17s\tremaining: 3m 29s\n",
      "75:\tlearn: 0.2424264\ttotal: 17.2s\tremaining: 3m 29s\n",
      "76:\tlearn: 0.2423343\ttotal: 17.4s\tremaining: 3m 28s\n",
      "77:\tlearn: 0.2422671\ttotal: 17.6s\tremaining: 3m 28s\n",
      "78:\tlearn: 0.2421889\ttotal: 17.9s\tremaining: 3m 29s\n",
      "79:\tlearn: 0.2421115\ttotal: 18.1s\tremaining: 3m 28s\n",
      "80:\tlearn: 0.2420232\ttotal: 18.4s\tremaining: 3m 28s\n",
      "81:\tlearn: 0.2419529\ttotal: 18.7s\tremaining: 3m 29s\n",
      "82:\tlearn: 0.2418668\ttotal: 18.9s\tremaining: 3m 28s\n",
      "83:\tlearn: 0.2417835\ttotal: 19.1s\tremaining: 3m 28s\n",
      "84:\tlearn: 0.2416906\ttotal: 19.4s\tremaining: 3m 28s\n",
      "85:\tlearn: 0.2413786\ttotal: 19.6s\tremaining: 3m 27s\n",
      "86:\tlearn: 0.2413147\ttotal: 19.8s\tremaining: 3m 27s\n",
      "87:\tlearn: 0.2412277\ttotal: 20s\tremaining: 3m 27s\n",
      "88:\tlearn: 0.2411493\ttotal: 20.3s\tremaining: 3m 27s\n",
      "89:\tlearn: 0.2410479\ttotal: 20.5s\tremaining: 3m 27s\n",
      "90:\tlearn: 0.2409569\ttotal: 20.8s\tremaining: 3m 28s\n",
      "91:\tlearn: 0.2408674\ttotal: 21s\tremaining: 3m 27s\n",
      "92:\tlearn: 0.2408027\ttotal: 21.3s\tremaining: 3m 27s\n",
      "93:\tlearn: 0.2405855\ttotal: 21.4s\tremaining: 3m 26s\n",
      "94:\tlearn: 0.2404947\ttotal: 21.7s\tremaining: 3m 26s\n",
      "95:\tlearn: 0.2404417\ttotal: 21.8s\tremaining: 3m 25s\n",
      "96:\tlearn: 0.2403678\ttotal: 22s\tremaining: 3m 25s\n",
      "97:\tlearn: 0.2402861\ttotal: 22.2s\tremaining: 3m 24s\n",
      "98:\tlearn: 0.2402046\ttotal: 22.5s\tremaining: 3m 24s\n",
      "99:\tlearn: 0.2401455\ttotal: 22.7s\tremaining: 3m 24s\n",
      "100:\tlearn: 0.2400908\ttotal: 22.9s\tremaining: 3m 23s\n",
      "101:\tlearn: 0.2389895\ttotal: 23.1s\tremaining: 3m 23s\n",
      "102:\tlearn: 0.2389189\ttotal: 23.3s\tremaining: 3m 23s\n",
      "103:\tlearn: 0.2388549\ttotal: 23.6s\tremaining: 3m 23s\n",
      "104:\tlearn: 0.2387854\ttotal: 23.8s\tremaining: 3m 22s\n",
      "105:\tlearn: 0.2387292\ttotal: 24s\tremaining: 3m 22s\n",
      "106:\tlearn: 0.2385801\ttotal: 24.2s\tremaining: 3m 22s\n",
      "107:\tlearn: 0.2377112\ttotal: 24.5s\tremaining: 3m 22s\n",
      "108:\tlearn: 0.2376398\ttotal: 24.7s\tremaining: 3m 21s\n",
      "109:\tlearn: 0.2375681\ttotal: 24.9s\tremaining: 3m 21s\n",
      "110:\tlearn: 0.2375085\ttotal: 25.1s\tremaining: 3m 20s\n",
      "111:\tlearn: 0.2374525\ttotal: 25.3s\tremaining: 3m 20s\n",
      "112:\tlearn: 0.2373919\ttotal: 25.5s\tremaining: 3m 19s\n",
      "113:\tlearn: 0.2373256\ttotal: 25.7s\tremaining: 3m 19s\n",
      "114:\tlearn: 0.2371551\ttotal: 25.9s\tremaining: 3m 19s\n",
      "115:\tlearn: 0.2370732\ttotal: 26.1s\tremaining: 3m 18s\n",
      "116:\tlearn: 0.2369954\ttotal: 26.4s\tremaining: 3m 18s\n",
      "117:\tlearn: 0.2369148\ttotal: 26.6s\tremaining: 3m 18s\n",
      "118:\tlearn: 0.2367363\ttotal: 26.8s\tremaining: 3m 18s\n",
      "119:\tlearn: 0.2366184\ttotal: 27s\tremaining: 3m 18s\n",
      "120:\tlearn: 0.2365523\ttotal: 27.2s\tremaining: 3m 17s\n",
      "121:\tlearn: 0.2364714\ttotal: 27.4s\tremaining: 3m 17s\n",
      "122:\tlearn: 0.2364144\ttotal: 27.6s\tremaining: 3m 16s\n",
      "123:\tlearn: 0.2361882\ttotal: 27.8s\tremaining: 3m 16s\n",
      "124:\tlearn: 0.2360733\ttotal: 28.1s\tremaining: 3m 16s\n",
      "125:\tlearn: 0.2359752\ttotal: 28.3s\tremaining: 3m 16s\n",
      "126:\tlearn: 0.2358798\ttotal: 28.6s\tremaining: 3m 16s\n",
      "127:\tlearn: 0.2357941\ttotal: 28.8s\tremaining: 3m 16s\n",
      "128:\tlearn: 0.2357437\ttotal: 29s\tremaining: 3m 16s\n",
      "129:\tlearn: 0.2356734\ttotal: 29.2s\tremaining: 3m 15s\n",
      "130:\tlearn: 0.2355509\ttotal: 29.4s\tremaining: 3m 15s\n",
      "131:\tlearn: 0.2353743\ttotal: 29.6s\tremaining: 3m 14s\n",
      "132:\tlearn: 0.2353266\ttotal: 29.8s\tremaining: 3m 14s\n",
      "133:\tlearn: 0.2352541\ttotal: 30s\tremaining: 3m 13s\n",
      "134:\tlearn: 0.2351850\ttotal: 30.2s\tremaining: 3m 13s\n",
      "135:\tlearn: 0.2351182\ttotal: 30.4s\tremaining: 3m 13s\n",
      "136:\tlearn: 0.2350664\ttotal: 30.6s\tremaining: 3m 12s\n",
      "137:\tlearn: 0.2349903\ttotal: 30.8s\tremaining: 3m 12s\n",
      "138:\tlearn: 0.2348530\ttotal: 31s\tremaining: 3m 12s\n",
      "139:\tlearn: 0.2347951\ttotal: 31.3s\tremaining: 3m 11s\n",
      "140:\tlearn: 0.2347324\ttotal: 31.5s\tremaining: 3m 11s\n",
      "141:\tlearn: 0.2346746\ttotal: 31.7s\tremaining: 3m 11s\n",
      "142:\tlearn: 0.2346132\ttotal: 31.9s\tremaining: 3m 10s\n",
      "143:\tlearn: 0.2339786\ttotal: 32s\tremaining: 3m 10s\n",
      "144:\tlearn: 0.2338893\ttotal: 32.3s\tremaining: 3m 10s\n",
      "145:\tlearn: 0.2338376\ttotal: 32.5s\tremaining: 3m 9s\n",
      "146:\tlearn: 0.2337807\ttotal: 32.7s\tremaining: 3m 9s\n",
      "147:\tlearn: 0.2337471\ttotal: 32.8s\tremaining: 3m 8s\n",
      "148:\tlearn: 0.2336657\ttotal: 33.1s\tremaining: 3m 8s\n",
      "149:\tlearn: 0.2335591\ttotal: 33.3s\tremaining: 3m 8s\n",
      "150:\tlearn: 0.2335071\ttotal: 33.5s\tremaining: 3m 8s\n",
      "151:\tlearn: 0.2334584\ttotal: 33.7s\tremaining: 3m 7s\n",
      "152:\tlearn: 0.2333929\ttotal: 33.9s\tremaining: 3m 7s\n",
      "153:\tlearn: 0.2333281\ttotal: 34.1s\tremaining: 3m 7s\n",
      "154:\tlearn: 0.2332776\ttotal: 34.3s\tremaining: 3m 7s\n",
      "155:\tlearn: 0.2332054\ttotal: 34.5s\tremaining: 3m 6s\n",
      "156:\tlearn: 0.2331543\ttotal: 34.7s\tremaining: 3m 6s\n",
      "157:\tlearn: 0.2331023\ttotal: 34.9s\tremaining: 3m 5s\n",
      "158:\tlearn: 0.2330304\ttotal: 35.1s\tremaining: 3m 5s\n",
      "159:\tlearn: 0.2329721\ttotal: 35.3s\tremaining: 3m 5s\n",
      "160:\tlearn: 0.2329073\ttotal: 35.5s\tremaining: 3m 5s\n",
      "161:\tlearn: 0.2321540\ttotal: 35.7s\tremaining: 3m 4s\n",
      "162:\tlearn: 0.2320777\ttotal: 36s\tremaining: 3m 4s\n",
      "163:\tlearn: 0.2320151\ttotal: 36.1s\tremaining: 3m 4s\n",
      "164:\tlearn: 0.2319419\ttotal: 36.3s\tremaining: 3m 3s\n",
      "165:\tlearn: 0.2318894\ttotal: 36.5s\tremaining: 3m 3s\n",
      "166:\tlearn: 0.2318239\ttotal: 36.7s\tremaining: 3m 3s\n",
      "167:\tlearn: 0.2317666\ttotal: 36.9s\tremaining: 3m 2s\n",
      "168:\tlearn: 0.2316982\ttotal: 37.1s\tremaining: 3m 2s\n",
      "169:\tlearn: 0.2316392\ttotal: 37.3s\tremaining: 3m 2s\n",
      "170:\tlearn: 0.2315773\ttotal: 37.5s\tremaining: 3m 1s\n",
      "171:\tlearn: 0.2315053\ttotal: 37.7s\tremaining: 3m 1s\n",
      "172:\tlearn: 0.2314606\ttotal: 37.9s\tremaining: 3m 1s\n",
      "173:\tlearn: 0.2313549\ttotal: 38.1s\tremaining: 3m\n",
      "174:\tlearn: 0.2313059\ttotal: 38.3s\tremaining: 3m\n",
      "175:\tlearn: 0.2309533\ttotal: 38.4s\tremaining: 2m 59s\n",
      "176:\tlearn: 0.2309056\ttotal: 38.6s\tremaining: 2m 59s\n",
      "177:\tlearn: 0.2308353\ttotal: 38.9s\tremaining: 2m 59s\n",
      "178:\tlearn: 0.2307766\ttotal: 39.1s\tremaining: 2m 59s\n",
      "179:\tlearn: 0.2307355\ttotal: 39.2s\tremaining: 2m 58s\n",
      "180:\tlearn: 0.2306760\ttotal: 39.5s\tremaining: 2m 58s\n",
      "181:\tlearn: 0.2306395\ttotal: 39.7s\tremaining: 2m 58s\n",
      "182:\tlearn: 0.2305767\ttotal: 40s\tremaining: 2m 58s\n",
      "183:\tlearn: 0.2305226\ttotal: 40.2s\tremaining: 2m 58s\n",
      "184:\tlearn: 0.2303989\ttotal: 40.4s\tremaining: 2m 57s\n",
      "185:\tlearn: 0.2303413\ttotal: 40.6s\tremaining: 2m 57s\n",
      "186:\tlearn: 0.2302904\ttotal: 40.8s\tremaining: 2m 57s\n",
      "187:\tlearn: 0.2302384\ttotal: 41s\tremaining: 2m 56s\n",
      "188:\tlearn: 0.2301912\ttotal: 41.2s\tremaining: 2m 56s\n",
      "189:\tlearn: 0.2301332\ttotal: 41.3s\tremaining: 2m 56s\n",
      "190:\tlearn: 0.2300759\ttotal: 41.5s\tremaining: 2m 55s\n",
      "191:\tlearn: 0.2300173\ttotal: 41.8s\tremaining: 2m 55s\n",
      "192:\tlearn: 0.2299491\ttotal: 42s\tremaining: 2m 55s\n",
      "193:\tlearn: 0.2298901\ttotal: 42.2s\tremaining: 2m 55s\n",
      "194:\tlearn: 0.2297882\ttotal: 42.4s\tremaining: 2m 55s\n",
      "195:\tlearn: 0.2297416\ttotal: 42.6s\tremaining: 2m 54s\n",
      "196:\tlearn: 0.2296852\ttotal: 42.8s\tremaining: 2m 54s\n",
      "197:\tlearn: 0.2296416\ttotal: 43s\tremaining: 2m 54s\n",
      "198:\tlearn: 0.2294519\ttotal: 43.2s\tremaining: 2m 53s\n",
      "199:\tlearn: 0.2293900\ttotal: 43.4s\tremaining: 2m 53s\n",
      "200:\tlearn: 0.2293342\ttotal: 43.6s\tremaining: 2m 53s\n",
      "201:\tlearn: 0.2292928\ttotal: 43.8s\tremaining: 2m 53s\n",
      "202:\tlearn: 0.2292413\ttotal: 44s\tremaining: 2m 52s\n",
      "203:\tlearn: 0.2291815\ttotal: 44.3s\tremaining: 2m 52s\n",
      "204:\tlearn: 0.2291444\ttotal: 44.4s\tremaining: 2m 52s\n",
      "205:\tlearn: 0.2291019\ttotal: 44.6s\tremaining: 2m 52s\n",
      "206:\tlearn: 0.2290618\ttotal: 44.8s\tremaining: 2m 51s\n",
      "207:\tlearn: 0.2290028\ttotal: 45.1s\tremaining: 2m 51s\n",
      "208:\tlearn: 0.2289528\ttotal: 45.3s\tremaining: 2m 51s\n",
      "209:\tlearn: 0.2289044\ttotal: 45.5s\tremaining: 2m 51s\n",
      "210:\tlearn: 0.2288177\ttotal: 45.7s\tremaining: 2m 50s\n",
      "211:\tlearn: 0.2287685\ttotal: 45.9s\tremaining: 2m 50s\n",
      "212:\tlearn: 0.2287132\ttotal: 46.2s\tremaining: 2m 50s\n",
      "213:\tlearn: 0.2286465\ttotal: 46.4s\tremaining: 2m 50s\n",
      "214:\tlearn: 0.2286019\ttotal: 46.5s\tremaining: 2m 49s\n",
      "215:\tlearn: 0.2285457\ttotal: 46.7s\tremaining: 2m 49s\n",
      "216:\tlearn: 0.2285166\ttotal: 46.9s\tremaining: 2m 49s\n",
      "217:\tlearn: 0.2284723\ttotal: 47.1s\tremaining: 2m 48s\n",
      "218:\tlearn: 0.2284256\ttotal: 47.3s\tremaining: 2m 48s\n",
      "219:\tlearn: 0.2283797\ttotal: 47.6s\tremaining: 2m 48s\n",
      "220:\tlearn: 0.2283247\ttotal: 47.8s\tremaining: 2m 48s\n",
      "221:\tlearn: 0.2282748\ttotal: 48.1s\tremaining: 2m 48s\n",
      "222:\tlearn: 0.2282270\ttotal: 48.3s\tremaining: 2m 48s\n",
      "223:\tlearn: 0.2281947\ttotal: 48.4s\tremaining: 2m 47s\n",
      "224:\tlearn: 0.2281454\ttotal: 48.6s\tremaining: 2m 47s\n",
      "225:\tlearn: 0.2281020\ttotal: 48.8s\tremaining: 2m 47s\n",
      "226:\tlearn: 0.2278763\ttotal: 49s\tremaining: 2m 47s\n",
      "227:\tlearn: 0.2278326\ttotal: 49.3s\tremaining: 2m 46s\n",
      "228:\tlearn: 0.2277824\ttotal: 49.5s\tremaining: 2m 46s\n",
      "229:\tlearn: 0.2275644\ttotal: 49.7s\tremaining: 2m 46s\n",
      "230:\tlearn: 0.2275083\ttotal: 50s\tremaining: 2m 46s\n",
      "231:\tlearn: 0.2274735\ttotal: 50.4s\tremaining: 2m 46s\n",
      "232:\tlearn: 0.2274267\ttotal: 50.6s\tremaining: 2m 46s\n",
      "233:\tlearn: 0.2273835\ttotal: 50.9s\tremaining: 2m 46s\n",
      "234:\tlearn: 0.2273412\ttotal: 51.1s\tremaining: 2m 46s\n",
      "235:\tlearn: 0.2272909\ttotal: 51.4s\tremaining: 2m 46s\n",
      "236:\tlearn: 0.2272517\ttotal: 51.6s\tremaining: 2m 46s\n",
      "237:\tlearn: 0.2272073\ttotal: 51.9s\tremaining: 2m 46s\n",
      "238:\tlearn: 0.2271663\ttotal: 52.1s\tremaining: 2m 46s\n",
      "239:\tlearn: 0.2271210\ttotal: 52.4s\tremaining: 2m 45s\n",
      "240:\tlearn: 0.2270669\ttotal: 52.8s\tremaining: 2m 46s\n",
      "241:\tlearn: 0.2270247\ttotal: 53.1s\tremaining: 2m 46s\n",
      "242:\tlearn: 0.2269830\ttotal: 53.3s\tremaining: 2m 46s\n",
      "243:\tlearn: 0.2269277\ttotal: 53.6s\tremaining: 2m 46s\n",
      "244:\tlearn: 0.2268737\ttotal: 53.9s\tremaining: 2m 46s\n",
      "245:\tlearn: 0.2268413\ttotal: 54.1s\tremaining: 2m 45s\n",
      "246:\tlearn: 0.2267650\ttotal: 54.3s\tremaining: 2m 45s\n",
      "247:\tlearn: 0.2267286\ttotal: 54.5s\tremaining: 2m 45s\n",
      "248:\tlearn: 0.2266753\ttotal: 54.7s\tremaining: 2m 44s\n",
      "249:\tlearn: 0.2266310\ttotal: 55s\tremaining: 2m 44s\n",
      "250:\tlearn: 0.2265762\ttotal: 55.2s\tremaining: 2m 44s\n",
      "251:\tlearn: 0.2265424\ttotal: 55.4s\tremaining: 2m 44s\n",
      "252:\tlearn: 0.2264965\ttotal: 55.6s\tremaining: 2m 44s\n",
      "253:\tlearn: 0.2263550\ttotal: 55.8s\tremaining: 2m 43s\n",
      "254:\tlearn: 0.2263151\ttotal: 56s\tremaining: 2m 43s\n",
      "255:\tlearn: 0.2262756\ttotal: 56.3s\tremaining: 2m 43s\n",
      "256:\tlearn: 0.2262375\ttotal: 56.5s\tremaining: 2m 43s\n",
      "257:\tlearn: 0.2261878\ttotal: 56.7s\tremaining: 2m 43s\n",
      "258:\tlearn: 0.2261416\ttotal: 57s\tremaining: 2m 42s\n",
      "259:\tlearn: 0.2260994\ttotal: 57.2s\tremaining: 2m 42s\n",
      "260:\tlearn: 0.2258917\ttotal: 57.4s\tremaining: 2m 42s\n",
      "261:\tlearn: 0.2258521\ttotal: 57.6s\tremaining: 2m 42s\n",
      "262:\tlearn: 0.2258117\ttotal: 57.9s\tremaining: 2m 42s\n",
      "263:\tlearn: 0.2257606\ttotal: 58.1s\tremaining: 2m 41s\n",
      "264:\tlearn: 0.2257235\ttotal: 58.2s\tremaining: 2m 41s\n",
      "265:\tlearn: 0.2256659\ttotal: 58.4s\tremaining: 2m 41s\n",
      "266:\tlearn: 0.2256300\ttotal: 58.6s\tremaining: 2m 41s\n",
      "267:\tlearn: 0.2254399\ttotal: 58.9s\tremaining: 2m 40s\n",
      "268:\tlearn: 0.2253983\ttotal: 59.1s\tremaining: 2m 40s\n",
      "269:\tlearn: 0.2253562\ttotal: 59.3s\tremaining: 2m 40s\n",
      "270:\tlearn: 0.2253120\ttotal: 59.5s\tremaining: 2m 40s\n",
      "271:\tlearn: 0.2252695\ttotal: 59.7s\tremaining: 2m 39s\n",
      "272:\tlearn: 0.2252372\ttotal: 59.9s\tremaining: 2m 39s\n",
      "273:\tlearn: 0.2251934\ttotal: 1m\tremaining: 2m 39s\n",
      "274:\tlearn: 0.2251439\ttotal: 1m\tremaining: 2m 39s\n",
      "275:\tlearn: 0.2251090\ttotal: 1m\tremaining: 2m 38s\n",
      "276:\tlearn: 0.2250712\ttotal: 1m\tremaining: 2m 38s\n",
      "277:\tlearn: 0.2250244\ttotal: 1m\tremaining: 2m 38s\n",
      "278:\tlearn: 0.2249809\ttotal: 1m 1s\tremaining: 2m 38s\n",
      "279:\tlearn: 0.2249294\ttotal: 1m 1s\tremaining: 2m 37s\n",
      "280:\tlearn: 0.2248923\ttotal: 1m 1s\tremaining: 2m 37s\n",
      "281:\tlearn: 0.2248473\ttotal: 1m 1s\tremaining: 2m 37s\n",
      "282:\tlearn: 0.2247837\ttotal: 1m 2s\tremaining: 2m 37s\n",
      "283:\tlearn: 0.2247488\ttotal: 1m 2s\tremaining: 2m 37s\n",
      "284:\tlearn: 0.2245188\ttotal: 1m 2s\tremaining: 2m 36s\n",
      "285:\tlearn: 0.2244882\ttotal: 1m 2s\tremaining: 2m 36s\n",
      "286:\tlearn: 0.2244496\ttotal: 1m 2s\tremaining: 2m 36s\n",
      "287:\tlearn: 0.2244137\ttotal: 1m 3s\tremaining: 2m 36s\n",
      "288:\tlearn: 0.2243751\ttotal: 1m 3s\tremaining: 2m 35s\n",
      "289:\tlearn: 0.2243421\ttotal: 1m 3s\tremaining: 2m 35s\n",
      "290:\tlearn: 0.2242949\ttotal: 1m 3s\tremaining: 2m 35s\n",
      "291:\tlearn: 0.2242504\ttotal: 1m 4s\tremaining: 2m 35s\n",
      "292:\tlearn: 0.2242071\ttotal: 1m 4s\tremaining: 2m 34s\n",
      "293:\tlearn: 0.2241594\ttotal: 1m 4s\tremaining: 2m 34s\n",
      "294:\tlearn: 0.2241130\ttotal: 1m 4s\tremaining: 2m 34s\n",
      "295:\tlearn: 0.2240665\ttotal: 1m 4s\tremaining: 2m 34s\n",
      "296:\tlearn: 0.2240314\ttotal: 1m 5s\tremaining: 2m 33s\n",
      "297:\tlearn: 0.2239858\ttotal: 1m 5s\tremaining: 2m 33s\n",
      "298:\tlearn: 0.2239495\ttotal: 1m 5s\tremaining: 2m 33s\n",
      "299:\tlearn: 0.2238211\ttotal: 1m 5s\tremaining: 2m 33s\n",
      "300:\tlearn: 0.2237888\ttotal: 1m 5s\tremaining: 2m 32s\n",
      "301:\tlearn: 0.2237459\ttotal: 1m 6s\tremaining: 2m 32s\n",
      "302:\tlearn: 0.2237129\ttotal: 1m 6s\tremaining: 2m 32s\n",
      "303:\tlearn: 0.2236736\ttotal: 1m 6s\tremaining: 2m 31s\n",
      "304:\tlearn: 0.2236404\ttotal: 1m 6s\tremaining: 2m 31s\n",
      "305:\tlearn: 0.2236079\ttotal: 1m 6s\tremaining: 2m 31s\n",
      "306:\tlearn: 0.2235768\ttotal: 1m 6s\tremaining: 2m 30s\n",
      "307:\tlearn: 0.2235412\ttotal: 1m 7s\tremaining: 2m 30s\n",
      "308:\tlearn: 0.2234848\ttotal: 1m 7s\tremaining: 2m 30s\n",
      "309:\tlearn: 0.2234430\ttotal: 1m 7s\tremaining: 2m 30s\n",
      "310:\tlearn: 0.2234050\ttotal: 1m 7s\tremaining: 2m 30s\n",
      "311:\tlearn: 0.2233815\ttotal: 1m 7s\tremaining: 2m 29s\n",
      "312:\tlearn: 0.2233457\ttotal: 1m 8s\tremaining: 2m 29s\n",
      "313:\tlearn: 0.2233113\ttotal: 1m 8s\tremaining: 2m 29s\n",
      "314:\tlearn: 0.2232653\ttotal: 1m 8s\tremaining: 2m 28s\n",
      "315:\tlearn: 0.2232148\ttotal: 1m 8s\tremaining: 2m 28s\n",
      "316:\tlearn: 0.2230984\ttotal: 1m 8s\tremaining: 2m 28s\n",
      "317:\tlearn: 0.2230518\ttotal: 1m 9s\tremaining: 2m 28s\n",
      "318:\tlearn: 0.2230154\ttotal: 1m 9s\tremaining: 2m 28s\n",
      "319:\tlearn: 0.2229861\ttotal: 1m 9s\tremaining: 2m 27s\n",
      "320:\tlearn: 0.2229612\ttotal: 1m 9s\tremaining: 2m 27s\n",
      "321:\tlearn: 0.2229170\ttotal: 1m 9s\tremaining: 2m 27s\n",
      "322:\tlearn: 0.2226604\ttotal: 1m 10s\tremaining: 2m 26s\n",
      "323:\tlearn: 0.2226236\ttotal: 1m 10s\tremaining: 2m 26s\n",
      "324:\tlearn: 0.2225831\ttotal: 1m 10s\tremaining: 2m 26s\n",
      "325:\tlearn: 0.2225274\ttotal: 1m 10s\tremaining: 2m 26s\n",
      "326:\tlearn: 0.2224916\ttotal: 1m 10s\tremaining: 2m 26s\n",
      "327:\tlearn: 0.2224399\ttotal: 1m 11s\tremaining: 2m 25s\n",
      "328:\tlearn: 0.2224111\ttotal: 1m 11s\tremaining: 2m 25s\n",
      "329:\tlearn: 0.2223763\ttotal: 1m 11s\tremaining: 2m 25s\n",
      "330:\tlearn: 0.2223422\ttotal: 1m 11s\tremaining: 2m 25s\n",
      "331:\tlearn: 0.2223066\ttotal: 1m 11s\tremaining: 2m 24s\n",
      "332:\tlearn: 0.2222729\ttotal: 1m 12s\tremaining: 2m 24s\n",
      "333:\tlearn: 0.2222397\ttotal: 1m 12s\tremaining: 2m 24s\n",
      "334:\tlearn: 0.2222034\ttotal: 1m 12s\tremaining: 2m 24s\n",
      "335:\tlearn: 0.2221810\ttotal: 1m 12s\tremaining: 2m 23s\n",
      "336:\tlearn: 0.2221371\ttotal: 1m 12s\tremaining: 2m 23s\n",
      "337:\tlearn: 0.2221025\ttotal: 1m 13s\tremaining: 2m 23s\n",
      "338:\tlearn: 0.2220602\ttotal: 1m 13s\tremaining: 2m 22s\n",
      "339:\tlearn: 0.2220252\ttotal: 1m 13s\tremaining: 2m 22s\n",
      "340:\tlearn: 0.2219942\ttotal: 1m 13s\tremaining: 2m 22s\n",
      "341:\tlearn: 0.2216599\ttotal: 1m 13s\tremaining: 2m 22s\n",
      "342:\tlearn: 0.2216272\ttotal: 1m 14s\tremaining: 2m 21s\n",
      "343:\tlearn: 0.2215870\ttotal: 1m 14s\tremaining: 2m 21s\n",
      "344:\tlearn: 0.2215443\ttotal: 1m 14s\tremaining: 2m 21s\n",
      "345:\tlearn: 0.2215073\ttotal: 1m 14s\tremaining: 2m 21s\n",
      "346:\tlearn: 0.2213730\ttotal: 1m 14s\tremaining: 2m 20s\n",
      "347:\tlearn: 0.2213485\ttotal: 1m 15s\tremaining: 2m 20s\n",
      "348:\tlearn: 0.2213054\ttotal: 1m 15s\tremaining: 2m 20s\n",
      "349:\tlearn: 0.2212783\ttotal: 1m 15s\tremaining: 2m 20s\n",
      "350:\tlearn: 0.2212571\ttotal: 1m 15s\tremaining: 2m 19s\n",
      "351:\tlearn: 0.2212158\ttotal: 1m 15s\tremaining: 2m 19s\n",
      "352:\tlearn: 0.2211970\ttotal: 1m 16s\tremaining: 2m 19s\n",
      "353:\tlearn: 0.2211333\ttotal: 1m 16s\tremaining: 2m 19s\n",
      "354:\tlearn: 0.2210962\ttotal: 1m 16s\tremaining: 2m 18s\n",
      "355:\tlearn: 0.2210617\ttotal: 1m 16s\tremaining: 2m 18s\n",
      "356:\tlearn: 0.2210207\ttotal: 1m 16s\tremaining: 2m 18s\n",
      "357:\tlearn: 0.2209897\ttotal: 1m 17s\tremaining: 2m 18s\n",
      "358:\tlearn: 0.2209625\ttotal: 1m 17s\tremaining: 2m 17s\n",
      "359:\tlearn: 0.2209342\ttotal: 1m 17s\tremaining: 2m 17s\n",
      "360:\tlearn: 0.2209067\ttotal: 1m 17s\tremaining: 2m 17s\n",
      "361:\tlearn: 0.2208302\ttotal: 1m 17s\tremaining: 2m 17s\n",
      "362:\tlearn: 0.2207864\ttotal: 1m 18s\tremaining: 2m 17s\n",
      "363:\tlearn: 0.2207515\ttotal: 1m 18s\tremaining: 2m 16s\n",
      "364:\tlearn: 0.2207268\ttotal: 1m 18s\tremaining: 2m 16s\n",
      "365:\tlearn: 0.2206986\ttotal: 1m 18s\tremaining: 2m 16s\n",
      "366:\tlearn: 0.2206719\ttotal: 1m 18s\tremaining: 2m 15s\n",
      "367:\tlearn: 0.2206334\ttotal: 1m 19s\tremaining: 2m 15s\n",
      "368:\tlearn: 0.2205723\ttotal: 1m 19s\tremaining: 2m 15s\n",
      "369:\tlearn: 0.2205329\ttotal: 1m 19s\tremaining: 2m 15s\n",
      "370:\tlearn: 0.2204956\ttotal: 1m 19s\tremaining: 2m 15s\n",
      "371:\tlearn: 0.2204650\ttotal: 1m 19s\tremaining: 2m 14s\n",
      "372:\tlearn: 0.2204365\ttotal: 1m 20s\tremaining: 2m 14s\n",
      "373:\tlearn: 0.2203993\ttotal: 1m 20s\tremaining: 2m 14s\n",
      "374:\tlearn: 0.2203749\ttotal: 1m 20s\tremaining: 2m 14s\n",
      "375:\tlearn: 0.2203303\ttotal: 1m 20s\tremaining: 2m 13s\n",
      "376:\tlearn: 0.2202987\ttotal: 1m 20s\tremaining: 2m 13s\n",
      "377:\tlearn: 0.2202692\ttotal: 1m 21s\tremaining: 2m 13s\n",
      "378:\tlearn: 0.2202303\ttotal: 1m 21s\tremaining: 2m 13s\n",
      "379:\tlearn: 0.2202041\ttotal: 1m 21s\tremaining: 2m 12s\n",
      "380:\tlearn: 0.2201651\ttotal: 1m 21s\tremaining: 2m 12s\n",
      "381:\tlearn: 0.2201337\ttotal: 1m 21s\tremaining: 2m 12s\n",
      "382:\tlearn: 0.2201004\ttotal: 1m 22s\tremaining: 2m 12s\n",
      "383:\tlearn: 0.2200630\ttotal: 1m 22s\tremaining: 2m 11s\n",
      "384:\tlearn: 0.2200317\ttotal: 1m 22s\tremaining: 2m 11s\n",
      "385:\tlearn: 0.2199931\ttotal: 1m 22s\tremaining: 2m 11s\n",
      "386:\tlearn: 0.2199661\ttotal: 1m 22s\tremaining: 2m 11s\n",
      "387:\tlearn: 0.2199246\ttotal: 1m 22s\tremaining: 2m 10s\n",
      "388:\tlearn: 0.2198944\ttotal: 1m 23s\tremaining: 2m 10s\n",
      "389:\tlearn: 0.2198547\ttotal: 1m 23s\tremaining: 2m 10s\n",
      "390:\tlearn: 0.2198252\ttotal: 1m 23s\tremaining: 2m 10s\n",
      "391:\tlearn: 0.2197943\ttotal: 1m 23s\tremaining: 2m 9s\n",
      "392:\tlearn: 0.2197508\ttotal: 1m 23s\tremaining: 2m 9s\n",
      "393:\tlearn: 0.2196525\ttotal: 1m 24s\tremaining: 2m 9s\n",
      "394:\tlearn: 0.2196204\ttotal: 1m 24s\tremaining: 2m 9s\n",
      "395:\tlearn: 0.2195856\ttotal: 1m 24s\tremaining: 2m 9s\n",
      "396:\tlearn: 0.2195560\ttotal: 1m 24s\tremaining: 2m 8s\n",
      "397:\tlearn: 0.2195204\ttotal: 1m 24s\tremaining: 2m 8s\n",
      "398:\tlearn: 0.2194911\ttotal: 1m 25s\tremaining: 2m 8s\n",
      "399:\tlearn: 0.2194557\ttotal: 1m 25s\tremaining: 2m 7s\n",
      "400:\tlearn: 0.2194216\ttotal: 1m 25s\tremaining: 2m 7s\n",
      "401:\tlearn: 0.2193869\ttotal: 1m 25s\tremaining: 2m 7s\n",
      "402:\tlearn: 0.2193504\ttotal: 1m 25s\tremaining: 2m 7s\n",
      "403:\tlearn: 0.2193120\ttotal: 1m 26s\tremaining: 2m 7s\n",
      "404:\tlearn: 0.2192860\ttotal: 1m 26s\tremaining: 2m 6s\n",
      "405:\tlearn: 0.2192444\ttotal: 1m 26s\tremaining: 2m 6s\n",
      "406:\tlearn: 0.2192117\ttotal: 1m 26s\tremaining: 2m 6s\n",
      "407:\tlearn: 0.2191721\ttotal: 1m 26s\tremaining: 2m 6s\n",
      "408:\tlearn: 0.2191618\ttotal: 1m 27s\tremaining: 2m 5s\n",
      "409:\tlearn: 0.2191345\ttotal: 1m 27s\tremaining: 2m 5s\n",
      "410:\tlearn: 0.2190920\ttotal: 1m 27s\tremaining: 2m 5s\n",
      "411:\tlearn: 0.2190601\ttotal: 1m 27s\tremaining: 2m 5s\n",
      "412:\tlearn: 0.2190238\ttotal: 1m 27s\tremaining: 2m 4s\n",
      "413:\tlearn: 0.2189941\ttotal: 1m 28s\tremaining: 2m 4s\n",
      "414:\tlearn: 0.2189701\ttotal: 1m 28s\tremaining: 2m 4s\n",
      "415:\tlearn: 0.2187865\ttotal: 1m 28s\tremaining: 2m 4s\n",
      "416:\tlearn: 0.2187380\ttotal: 1m 28s\tremaining: 2m 3s\n",
      "417:\tlearn: 0.2187011\ttotal: 1m 28s\tremaining: 2m 3s\n",
      "418:\tlearn: 0.2186635\ttotal: 1m 29s\tremaining: 2m 3s\n",
      "419:\tlearn: 0.2186262\ttotal: 1m 29s\tremaining: 2m 3s\n",
      "420:\tlearn: 0.2185960\ttotal: 1m 29s\tremaining: 2m 3s\n",
      "421:\tlearn: 0.2185534\ttotal: 1m 29s\tremaining: 2m 2s\n",
      "422:\tlearn: 0.2185251\ttotal: 1m 29s\tremaining: 2m 2s\n",
      "423:\tlearn: 0.2184987\ttotal: 1m 30s\tremaining: 2m 2s\n",
      "424:\tlearn: 0.2184678\ttotal: 1m 30s\tremaining: 2m 2s\n",
      "425:\tlearn: 0.2184383\ttotal: 1m 30s\tremaining: 2m 1s\n",
      "426:\tlearn: 0.2184161\ttotal: 1m 30s\tremaining: 2m 1s\n",
      "427:\tlearn: 0.2183775\ttotal: 1m 30s\tremaining: 2m 1s\n",
      "428:\tlearn: 0.2183484\ttotal: 1m 31s\tremaining: 2m 1s\n",
      "429:\tlearn: 0.2183199\ttotal: 1m 31s\tremaining: 2m\n",
      "430:\tlearn: 0.2182914\ttotal: 1m 31s\tremaining: 2m\n",
      "431:\tlearn: 0.2182566\ttotal: 1m 31s\tremaining: 2m\n",
      "432:\tlearn: 0.2182110\ttotal: 1m 31s\tremaining: 2m\n",
      "433:\tlearn: 0.2181761\ttotal: 1m 32s\tremaining: 2m\n",
      "434:\tlearn: 0.2181435\ttotal: 1m 32s\tremaining: 1m 59s\n",
      "435:\tlearn: 0.2181148\ttotal: 1m 32s\tremaining: 1m 59s\n",
      "436:\tlearn: 0.2180794\ttotal: 1m 32s\tremaining: 1m 59s\n",
      "437:\tlearn: 0.2180572\ttotal: 1m 33s\tremaining: 1m 59s\n",
      "438:\tlearn: 0.2180437\ttotal: 1m 33s\tremaining: 1m 59s\n",
      "439:\tlearn: 0.2180020\ttotal: 1m 33s\tremaining: 1m 58s\n",
      "440:\tlearn: 0.2179784\ttotal: 1m 33s\tremaining: 1m 58s\n",
      "441:\tlearn: 0.2179449\ttotal: 1m 33s\tremaining: 1m 58s\n",
      "442:\tlearn: 0.2179187\ttotal: 1m 34s\tremaining: 1m 58s\n",
      "443:\tlearn: 0.2178838\ttotal: 1m 34s\tremaining: 1m 58s\n",
      "444:\tlearn: 0.2178097\ttotal: 1m 34s\tremaining: 1m 57s\n",
      "445:\tlearn: 0.2177752\ttotal: 1m 34s\tremaining: 1m 57s\n",
      "446:\tlearn: 0.2177467\ttotal: 1m 34s\tremaining: 1m 57s\n",
      "447:\tlearn: 0.2177133\ttotal: 1m 35s\tremaining: 1m 57s\n",
      "448:\tlearn: 0.2176741\ttotal: 1m 35s\tremaining: 1m 57s\n",
      "449:\tlearn: 0.2176355\ttotal: 1m 35s\tremaining: 1m 56s\n",
      "450:\tlearn: 0.2176169\ttotal: 1m 35s\tremaining: 1m 56s\n",
      "451:\tlearn: 0.2175853\ttotal: 1m 36s\tremaining: 1m 56s\n",
      "452:\tlearn: 0.2175496\ttotal: 1m 36s\tremaining: 1m 56s\n",
      "453:\tlearn: 0.2175180\ttotal: 1m 36s\tremaining: 1m 56s\n",
      "454:\tlearn: 0.2174942\ttotal: 1m 36s\tremaining: 1m 55s\n",
      "455:\tlearn: 0.2174624\ttotal: 1m 36s\tremaining: 1m 55s\n",
      "456:\tlearn: 0.2174326\ttotal: 1m 37s\tremaining: 1m 55s\n",
      "457:\tlearn: 0.2173944\ttotal: 1m 37s\tremaining: 1m 55s\n",
      "458:\tlearn: 0.2173665\ttotal: 1m 37s\tremaining: 1m 54s\n",
      "459:\tlearn: 0.2173387\ttotal: 1m 37s\tremaining: 1m 54s\n",
      "460:\tlearn: 0.2173042\ttotal: 1m 37s\tremaining: 1m 54s\n",
      "461:\tlearn: 0.2172682\ttotal: 1m 38s\tremaining: 1m 54s\n",
      "462:\tlearn: 0.2172392\ttotal: 1m 38s\tremaining: 1m 54s\n",
      "463:\tlearn: 0.2172136\ttotal: 1m 38s\tremaining: 1m 53s\n",
      "464:\tlearn: 0.2171809\ttotal: 1m 38s\tremaining: 1m 53s\n",
      "465:\tlearn: 0.2171583\ttotal: 1m 38s\tremaining: 1m 53s\n",
      "466:\tlearn: 0.2171343\ttotal: 1m 39s\tremaining: 1m 53s\n",
      "467:\tlearn: 0.2171011\ttotal: 1m 39s\tremaining: 1m 52s\n",
      "468:\tlearn: 0.2170814\ttotal: 1m 39s\tremaining: 1m 52s\n",
      "469:\tlearn: 0.2170408\ttotal: 1m 39s\tremaining: 1m 52s\n",
      "470:\tlearn: 0.2170168\ttotal: 1m 39s\tremaining: 1m 52s\n",
      "471:\tlearn: 0.2169905\ttotal: 1m 40s\tremaining: 1m 52s\n",
      "472:\tlearn: 0.2169489\ttotal: 1m 40s\tremaining: 1m 51s\n",
      "473:\tlearn: 0.2169205\ttotal: 1m 40s\tremaining: 1m 51s\n",
      "474:\tlearn: 0.2168909\ttotal: 1m 40s\tremaining: 1m 51s\n",
      "475:\tlearn: 0.2168506\ttotal: 1m 41s\tremaining: 1m 51s\n",
      "476:\tlearn: 0.2168081\ttotal: 1m 41s\tremaining: 1m 51s\n",
      "477:\tlearn: 0.2167828\ttotal: 1m 41s\tremaining: 1m 50s\n",
      "478:\tlearn: 0.2167596\ttotal: 1m 41s\tremaining: 1m 50s\n",
      "479:\tlearn: 0.2167278\ttotal: 1m 41s\tremaining: 1m 50s\n",
      "480:\tlearn: 0.2166898\ttotal: 1m 42s\tremaining: 1m 50s\n",
      "481:\tlearn: 0.2166577\ttotal: 1m 42s\tremaining: 1m 50s\n",
      "482:\tlearn: 0.2166450\ttotal: 1m 42s\tremaining: 1m 49s\n",
      "483:\tlearn: 0.2166194\ttotal: 1m 42s\tremaining: 1m 49s\n",
      "484:\tlearn: 0.2165937\ttotal: 1m 42s\tremaining: 1m 49s\n",
      "485:\tlearn: 0.2165634\ttotal: 1m 43s\tremaining: 1m 49s\n",
      "486:\tlearn: 0.2165313\ttotal: 1m 43s\tremaining: 1m 48s\n",
      "487:\tlearn: 0.2165046\ttotal: 1m 43s\tremaining: 1m 48s\n",
      "488:\tlearn: 0.2164721\ttotal: 1m 43s\tremaining: 1m 48s\n",
      "489:\tlearn: 0.2164466\ttotal: 1m 43s\tremaining: 1m 48s\n",
      "490:\tlearn: 0.2164075\ttotal: 1m 44s\tremaining: 1m 47s\n",
      "491:\tlearn: 0.2163895\ttotal: 1m 44s\tremaining: 1m 47s\n",
      "492:\tlearn: 0.2163495\ttotal: 1m 44s\tremaining: 1m 47s\n",
      "493:\tlearn: 0.2163180\ttotal: 1m 44s\tremaining: 1m 47s\n",
      "494:\tlearn: 0.2162876\ttotal: 1m 44s\tremaining: 1m 47s\n",
      "495:\tlearn: 0.2162529\ttotal: 1m 45s\tremaining: 1m 46s\n",
      "496:\tlearn: 0.2162140\ttotal: 1m 45s\tremaining: 1m 46s\n",
      "497:\tlearn: 0.2161821\ttotal: 1m 45s\tremaining: 1m 46s\n",
      "498:\tlearn: 0.2161531\ttotal: 1m 45s\tremaining: 1m 46s\n",
      "499:\tlearn: 0.2161269\ttotal: 1m 46s\tremaining: 1m 46s\n",
      "500:\tlearn: 0.2160908\ttotal: 1m 46s\tremaining: 1m 45s\n",
      "501:\tlearn: 0.2160595\ttotal: 1m 46s\tremaining: 1m 45s\n",
      "502:\tlearn: 0.2160295\ttotal: 1m 46s\tremaining: 1m 45s\n",
      "503:\tlearn: 0.2159992\ttotal: 1m 46s\tremaining: 1m 45s\n",
      "504:\tlearn: 0.2159676\ttotal: 1m 47s\tremaining: 1m 45s\n",
      "505:\tlearn: 0.2159513\ttotal: 1m 47s\tremaining: 1m 44s\n",
      "506:\tlearn: 0.2159242\ttotal: 1m 47s\tremaining: 1m 44s\n",
      "507:\tlearn: 0.2158954\ttotal: 1m 47s\tremaining: 1m 44s\n",
      "508:\tlearn: 0.2158577\ttotal: 1m 48s\tremaining: 1m 44s\n",
      "509:\tlearn: 0.2158245\ttotal: 1m 48s\tremaining: 1m 44s\n",
      "510:\tlearn: 0.2157858\ttotal: 1m 48s\tremaining: 1m 43s\n",
      "511:\tlearn: 0.2157648\ttotal: 1m 48s\tremaining: 1m 43s\n",
      "512:\tlearn: 0.2157375\ttotal: 1m 49s\tremaining: 1m 43s\n",
      "513:\tlearn: 0.2157104\ttotal: 1m 49s\tremaining: 1m 43s\n",
      "514:\tlearn: 0.2156702\ttotal: 1m 49s\tremaining: 1m 43s\n",
      "515:\tlearn: 0.2156358\ttotal: 1m 49s\tremaining: 1m 42s\n",
      "516:\tlearn: 0.2156080\ttotal: 1m 49s\tremaining: 1m 42s\n",
      "517:\tlearn: 0.2155762\ttotal: 1m 50s\tremaining: 1m 42s\n",
      "518:\tlearn: 0.2155557\ttotal: 1m 50s\tremaining: 1m 42s\n",
      "519:\tlearn: 0.2155295\ttotal: 1m 50s\tremaining: 1m 42s\n",
      "520:\tlearn: 0.2151987\ttotal: 1m 50s\tremaining: 1m 41s\n",
      "521:\tlearn: 0.2151667\ttotal: 1m 51s\tremaining: 1m 41s\n",
      "522:\tlearn: 0.2151468\ttotal: 1m 51s\tremaining: 1m 41s\n",
      "523:\tlearn: 0.2151079\ttotal: 1m 51s\tremaining: 1m 41s\n",
      "524:\tlearn: 0.2150758\ttotal: 1m 51s\tremaining: 1m 41s\n",
      "525:\tlearn: 0.2150430\ttotal: 1m 52s\tremaining: 1m 41s\n",
      "526:\tlearn: 0.2150117\ttotal: 1m 52s\tremaining: 1m 40s\n",
      "527:\tlearn: 0.2149846\ttotal: 1m 52s\tremaining: 1m 40s\n",
      "528:\tlearn: 0.2149482\ttotal: 1m 52s\tremaining: 1m 40s\n",
      "529:\tlearn: 0.2149201\ttotal: 1m 53s\tremaining: 1m 40s\n",
      "530:\tlearn: 0.2148967\ttotal: 1m 53s\tremaining: 1m 40s\n",
      "531:\tlearn: 0.2148597\ttotal: 1m 53s\tremaining: 1m 39s\n",
      "532:\tlearn: 0.2148218\ttotal: 1m 53s\tremaining: 1m 39s\n",
      "533:\tlearn: 0.2147832\ttotal: 1m 53s\tremaining: 1m 39s\n",
      "534:\tlearn: 0.2147552\ttotal: 1m 54s\tremaining: 1m 39s\n",
      "535:\tlearn: 0.2147294\ttotal: 1m 54s\tremaining: 1m 38s\n",
      "536:\tlearn: 0.2146946\ttotal: 1m 54s\tremaining: 1m 38s\n",
      "537:\tlearn: 0.2146615\ttotal: 1m 54s\tremaining: 1m 38s\n",
      "538:\tlearn: 0.2146488\ttotal: 1m 55s\tremaining: 1m 38s\n",
      "539:\tlearn: 0.2146263\ttotal: 1m 55s\tremaining: 1m 38s\n",
      "540:\tlearn: 0.2145959\ttotal: 1m 55s\tremaining: 1m 37s\n",
      "541:\tlearn: 0.2145687\ttotal: 1m 55s\tremaining: 1m 37s\n",
      "542:\tlearn: 0.2145327\ttotal: 1m 55s\tremaining: 1m 37s\n",
      "543:\tlearn: 0.2144973\ttotal: 1m 56s\tremaining: 1m 37s\n",
      "544:\tlearn: 0.2144633\ttotal: 1m 56s\tremaining: 1m 37s\n",
      "545:\tlearn: 0.2144447\ttotal: 1m 56s\tremaining: 1m 36s\n",
      "546:\tlearn: 0.2144124\ttotal: 1m 56s\tremaining: 1m 36s\n",
      "547:\tlearn: 0.2143799\ttotal: 1m 57s\tremaining: 1m 36s\n",
      "548:\tlearn: 0.2143505\ttotal: 1m 57s\tremaining: 1m 36s\n",
      "549:\tlearn: 0.2143319\ttotal: 1m 57s\tremaining: 1m 36s\n",
      "550:\tlearn: 0.2143026\ttotal: 1m 57s\tremaining: 1m 35s\n",
      "551:\tlearn: 0.2142655\ttotal: 1m 57s\tremaining: 1m 35s\n",
      "552:\tlearn: 0.2142383\ttotal: 1m 58s\tremaining: 1m 35s\n",
      "553:\tlearn: 0.2142096\ttotal: 1m 58s\tremaining: 1m 35s\n",
      "554:\tlearn: 0.2141717\ttotal: 1m 58s\tremaining: 1m 35s\n",
      "555:\tlearn: 0.2141382\ttotal: 1m 58s\tremaining: 1m 34s\n",
      "556:\tlearn: 0.2141111\ttotal: 1m 58s\tremaining: 1m 34s\n",
      "557:\tlearn: 0.2140858\ttotal: 1m 59s\tremaining: 1m 34s\n",
      "558:\tlearn: 0.2140576\ttotal: 1m 59s\tremaining: 1m 34s\n",
      "559:\tlearn: 0.2140241\ttotal: 1m 59s\tremaining: 1m 33s\n",
      "560:\tlearn: 0.2140027\ttotal: 1m 59s\tremaining: 1m 33s\n",
      "561:\tlearn: 0.2139881\ttotal: 1m 59s\tremaining: 1m 33s\n",
      "562:\tlearn: 0.2139591\ttotal: 2m\tremaining: 1m 33s\n",
      "563:\tlearn: 0.2139331\ttotal: 2m\tremaining: 1m 32s\n",
      "564:\tlearn: 0.2139045\ttotal: 2m\tremaining: 1m 32s\n",
      "565:\tlearn: 0.2138731\ttotal: 2m\tremaining: 1m 32s\n",
      "566:\tlearn: 0.2138483\ttotal: 2m\tremaining: 1m 32s\n",
      "567:\tlearn: 0.2138159\ttotal: 2m 1s\tremaining: 1m 32s\n",
      "568:\tlearn: 0.2137805\ttotal: 2m 1s\tremaining: 1m 31s\n",
      "569:\tlearn: 0.2137425\ttotal: 2m 1s\tremaining: 1m 31s\n",
      "570:\tlearn: 0.2136987\ttotal: 2m 1s\tremaining: 1m 31s\n",
      "571:\tlearn: 0.2136695\ttotal: 2m 2s\tremaining: 1m 31s\n",
      "572:\tlearn: 0.2136386\ttotal: 2m 2s\tremaining: 1m 31s\n",
      "573:\tlearn: 0.2136056\ttotal: 2m 2s\tremaining: 1m 30s\n",
      "574:\tlearn: 0.2135844\ttotal: 2m 2s\tremaining: 1m 30s\n",
      "575:\tlearn: 0.2135494\ttotal: 2m 2s\tremaining: 1m 30s\n",
      "576:\tlearn: 0.2135274\ttotal: 2m 3s\tremaining: 1m 30s\n",
      "577:\tlearn: 0.2135087\ttotal: 2m 3s\tremaining: 1m 30s\n",
      "578:\tlearn: 0.2134717\ttotal: 2m 3s\tremaining: 1m 29s\n",
      "579:\tlearn: 0.2134514\ttotal: 2m 3s\tremaining: 1m 29s\n",
      "580:\tlearn: 0.2134174\ttotal: 2m 4s\tremaining: 1m 29s\n",
      "581:\tlearn: 0.2133848\ttotal: 2m 4s\tremaining: 1m 29s\n",
      "582:\tlearn: 0.2133523\ttotal: 2m 4s\tremaining: 1m 29s\n",
      "583:\tlearn: 0.2133169\ttotal: 2m 4s\tremaining: 1m 28s\n",
      "584:\tlearn: 0.2132948\ttotal: 2m 4s\tremaining: 1m 28s\n",
      "585:\tlearn: 0.2132685\ttotal: 2m 5s\tremaining: 1m 28s\n",
      "586:\tlearn: 0.2132287\ttotal: 2m 5s\tremaining: 1m 28s\n",
      "587:\tlearn: 0.2132009\ttotal: 2m 5s\tremaining: 1m 27s\n",
      "588:\tlearn: 0.2131754\ttotal: 2m 5s\tremaining: 1m 27s\n",
      "589:\tlearn: 0.2131478\ttotal: 2m 5s\tremaining: 1m 27s\n",
      "590:\tlearn: 0.2131267\ttotal: 2m 6s\tremaining: 1m 27s\n",
      "591:\tlearn: 0.2130991\ttotal: 2m 6s\tremaining: 1m 27s\n",
      "592:\tlearn: 0.2130680\ttotal: 2m 6s\tremaining: 1m 26s\n",
      "593:\tlearn: 0.2130344\ttotal: 2m 6s\tremaining: 1m 26s\n",
      "594:\tlearn: 0.2130075\ttotal: 2m 6s\tremaining: 1m 26s\n",
      "595:\tlearn: 0.2129870\ttotal: 2m 7s\tremaining: 1m 26s\n",
      "596:\tlearn: 0.2129685\ttotal: 2m 7s\tremaining: 1m 25s\n",
      "597:\tlearn: 0.2129318\ttotal: 2m 7s\tremaining: 1m 25s\n",
      "598:\tlearn: 0.2129001\ttotal: 2m 7s\tremaining: 1m 25s\n",
      "599:\tlearn: 0.2128749\ttotal: 2m 7s\tremaining: 1m 25s\n",
      "600:\tlearn: 0.2128479\ttotal: 2m 8s\tremaining: 1m 25s\n",
      "601:\tlearn: 0.2128129\ttotal: 2m 8s\tremaining: 1m 24s\n",
      "602:\tlearn: 0.2127909\ttotal: 2m 8s\tremaining: 1m 24s\n",
      "603:\tlearn: 0.2127582\ttotal: 2m 8s\tremaining: 1m 24s\n",
      "604:\tlearn: 0.2127393\ttotal: 2m 9s\tremaining: 1m 24s\n",
      "605:\tlearn: 0.2127096\ttotal: 2m 9s\tremaining: 1m 24s\n",
      "606:\tlearn: 0.2126772\ttotal: 2m 9s\tremaining: 1m 23s\n",
      "607:\tlearn: 0.2126373\ttotal: 2m 9s\tremaining: 1m 23s\n",
      "608:\tlearn: 0.2126053\ttotal: 2m 10s\tremaining: 1m 23s\n",
      "609:\tlearn: 0.2125750\ttotal: 2m 10s\tremaining: 1m 23s\n",
      "610:\tlearn: 0.2125478\ttotal: 2m 10s\tremaining: 1m 23s\n",
      "611:\tlearn: 0.2125268\ttotal: 2m 11s\tremaining: 1m 23s\n",
      "612:\tlearn: 0.2125066\ttotal: 2m 11s\tremaining: 1m 22s\n",
      "613:\tlearn: 0.2124793\ttotal: 2m 11s\tremaining: 1m 22s\n",
      "614:\tlearn: 0.2124558\ttotal: 2m 11s\tremaining: 1m 22s\n",
      "615:\tlearn: 0.2124246\ttotal: 2m 12s\tremaining: 1m 22s\n",
      "616:\tlearn: 0.2124044\ttotal: 2m 12s\tremaining: 1m 22s\n",
      "617:\tlearn: 0.2123832\ttotal: 2m 12s\tremaining: 1m 21s\n",
      "618:\tlearn: 0.2123574\ttotal: 2m 12s\tremaining: 1m 21s\n",
      "619:\tlearn: 0.2123272\ttotal: 2m 13s\tremaining: 1m 21s\n",
      "620:\tlearn: 0.2123037\ttotal: 2m 13s\tremaining: 1m 21s\n",
      "621:\tlearn: 0.2122620\ttotal: 2m 13s\tremaining: 1m 21s\n",
      "622:\tlearn: 0.2122268\ttotal: 2m 13s\tremaining: 1m 21s\n",
      "623:\tlearn: 0.2122034\ttotal: 2m 14s\tremaining: 1m 20s\n",
      "624:\tlearn: 0.2121706\ttotal: 2m 14s\tremaining: 1m 20s\n",
      "625:\tlearn: 0.2121371\ttotal: 2m 14s\tremaining: 1m 20s\n",
      "626:\tlearn: 0.2121014\ttotal: 2m 14s\tremaining: 1m 20s\n",
      "627:\tlearn: 0.2120805\ttotal: 2m 14s\tremaining: 1m 19s\n",
      "628:\tlearn: 0.2120484\ttotal: 2m 15s\tremaining: 1m 19s\n",
      "629:\tlearn: 0.2120186\ttotal: 2m 15s\tremaining: 1m 19s\n",
      "630:\tlearn: 0.2119834\ttotal: 2m 15s\tremaining: 1m 19s\n",
      "631:\tlearn: 0.2119554\ttotal: 2m 16s\tremaining: 1m 19s\n",
      "632:\tlearn: 0.2119271\ttotal: 2m 16s\tremaining: 1m 18s\n",
      "633:\tlearn: 0.2118963\ttotal: 2m 16s\tremaining: 1m 18s\n",
      "634:\tlearn: 0.2118784\ttotal: 2m 16s\tremaining: 1m 18s\n",
      "635:\tlearn: 0.2118402\ttotal: 2m 16s\tremaining: 1m 18s\n",
      "636:\tlearn: 0.2118057\ttotal: 2m 17s\tremaining: 1m 18s\n",
      "637:\tlearn: 0.2117806\ttotal: 2m 17s\tremaining: 1m 17s\n",
      "638:\tlearn: 0.2117490\ttotal: 2m 17s\tremaining: 1m 17s\n",
      "639:\tlearn: 0.2117214\ttotal: 2m 17s\tremaining: 1m 17s\n",
      "640:\tlearn: 0.2117026\ttotal: 2m 17s\tremaining: 1m 17s\n",
      "641:\tlearn: 0.2116716\ttotal: 2m 18s\tremaining: 1m 17s\n",
      "642:\tlearn: 0.2116490\ttotal: 2m 18s\tremaining: 1m 16s\n",
      "643:\tlearn: 0.2116221\ttotal: 2m 18s\tremaining: 1m 16s\n",
      "644:\tlearn: 0.2115876\ttotal: 2m 18s\tremaining: 1m 16s\n",
      "645:\tlearn: 0.2115606\ttotal: 2m 18s\tremaining: 1m 16s\n",
      "646:\tlearn: 0.2115314\ttotal: 2m 19s\tremaining: 1m 15s\n",
      "647:\tlearn: 0.2114949\ttotal: 2m 19s\tremaining: 1m 15s\n",
      "648:\tlearn: 0.2114697\ttotal: 2m 19s\tremaining: 1m 15s\n",
      "649:\tlearn: 0.2114450\ttotal: 2m 19s\tremaining: 1m 15s\n",
      "650:\tlearn: 0.2114099\ttotal: 2m 19s\tremaining: 1m 15s\n",
      "651:\tlearn: 0.2113887\ttotal: 2m 20s\tremaining: 1m 14s\n",
      "652:\tlearn: 0.2113579\ttotal: 2m 20s\tremaining: 1m 14s\n",
      "653:\tlearn: 0.2113326\ttotal: 2m 20s\tremaining: 1m 14s\n",
      "654:\tlearn: 0.2113071\ttotal: 2m 20s\tremaining: 1m 14s\n",
      "655:\tlearn: 0.2112865\ttotal: 2m 20s\tremaining: 1m 13s\n",
      "656:\tlearn: 0.2112528\ttotal: 2m 21s\tremaining: 1m 13s\n",
      "657:\tlearn: 0.2112246\ttotal: 2m 21s\tremaining: 1m 13s\n",
      "658:\tlearn: 0.2111907\ttotal: 2m 21s\tremaining: 1m 13s\n",
      "659:\tlearn: 0.2111589\ttotal: 2m 21s\tremaining: 1m 13s\n",
      "660:\tlearn: 0.2111406\ttotal: 2m 21s\tremaining: 1m 12s\n",
      "661:\tlearn: 0.2111142\ttotal: 2m 22s\tremaining: 1m 12s\n",
      "662:\tlearn: 0.2110829\ttotal: 2m 22s\tremaining: 1m 12s\n",
      "663:\tlearn: 0.2109450\ttotal: 2m 22s\tremaining: 1m 12s\n",
      "664:\tlearn: 0.2109176\ttotal: 2m 22s\tremaining: 1m 11s\n",
      "665:\tlearn: 0.2108936\ttotal: 2m 23s\tremaining: 1m 11s\n",
      "666:\tlearn: 0.2108660\ttotal: 2m 23s\tremaining: 1m 11s\n",
      "667:\tlearn: 0.2108386\ttotal: 2m 23s\tremaining: 1m 11s\n",
      "668:\tlearn: 0.2107853\ttotal: 2m 23s\tremaining: 1m 11s\n",
      "669:\tlearn: 0.2107520\ttotal: 2m 23s\tremaining: 1m 10s\n",
      "670:\tlearn: 0.2107232\ttotal: 2m 24s\tremaining: 1m 10s\n",
      "671:\tlearn: 0.2106916\ttotal: 2m 24s\tremaining: 1m 10s\n",
      "672:\tlearn: 0.2106614\ttotal: 2m 24s\tremaining: 1m 10s\n",
      "673:\tlearn: 0.2106307\ttotal: 2m 24s\tremaining: 1m 10s\n",
      "674:\tlearn: 0.2106031\ttotal: 2m 25s\tremaining: 1m 9s\n",
      "675:\tlearn: 0.2105803\ttotal: 2m 25s\tremaining: 1m 9s\n",
      "676:\tlearn: 0.2105458\ttotal: 2m 25s\tremaining: 1m 9s\n",
      "677:\tlearn: 0.2105218\ttotal: 2m 25s\tremaining: 1m 9s\n",
      "678:\tlearn: 0.2104927\ttotal: 2m 25s\tremaining: 1m 8s\n",
      "679:\tlearn: 0.2104722\ttotal: 2m 26s\tremaining: 1m 8s\n",
      "680:\tlearn: 0.2104478\ttotal: 2m 26s\tremaining: 1m 8s\n",
      "681:\tlearn: 0.2104313\ttotal: 2m 26s\tremaining: 1m 8s\n",
      "682:\tlearn: 0.2104092\ttotal: 2m 26s\tremaining: 1m 8s\n",
      "683:\tlearn: 0.2103749\ttotal: 2m 26s\tremaining: 1m 7s\n",
      "684:\tlearn: 0.2103414\ttotal: 2m 27s\tremaining: 1m 7s\n",
      "685:\tlearn: 0.2103189\ttotal: 2m 27s\tremaining: 1m 7s\n",
      "686:\tlearn: 0.2102851\ttotal: 2m 27s\tremaining: 1m 7s\n",
      "687:\tlearn: 0.2102598\ttotal: 2m 27s\tremaining: 1m 7s\n",
      "688:\tlearn: 0.2102295\ttotal: 2m 28s\tremaining: 1m 6s\n",
      "689:\tlearn: 0.2101931\ttotal: 2m 28s\tremaining: 1m 6s\n",
      "690:\tlearn: 0.2101579\ttotal: 2m 28s\tremaining: 1m 6s\n",
      "691:\tlearn: 0.2101384\ttotal: 2m 28s\tremaining: 1m 6s\n",
      "692:\tlearn: 0.2101179\ttotal: 2m 28s\tremaining: 1m 5s\n",
      "693:\tlearn: 0.2100949\ttotal: 2m 29s\tremaining: 1m 5s\n",
      "694:\tlearn: 0.2100669\ttotal: 2m 29s\tremaining: 1m 5s\n",
      "695:\tlearn: 0.2100397\ttotal: 2m 29s\tremaining: 1m 5s\n",
      "696:\tlearn: 0.2100068\ttotal: 2m 29s\tremaining: 1m 5s\n",
      "697:\tlearn: 0.2099838\ttotal: 2m 29s\tremaining: 1m 4s\n",
      "698:\tlearn: 0.2099556\ttotal: 2m 30s\tremaining: 1m 4s\n",
      "699:\tlearn: 0.2099346\ttotal: 2m 30s\tremaining: 1m 4s\n",
      "700:\tlearn: 0.2099054\ttotal: 2m 30s\tremaining: 1m 4s\n",
      "701:\tlearn: 0.2098753\ttotal: 2m 30s\tremaining: 1m 4s\n",
      "702:\tlearn: 0.2098369\ttotal: 2m 30s\tremaining: 1m 3s\n",
      "703:\tlearn: 0.2098037\ttotal: 2m 31s\tremaining: 1m 3s\n",
      "704:\tlearn: 0.2097800\ttotal: 2m 31s\tremaining: 1m 3s\n",
      "705:\tlearn: 0.2097561\ttotal: 2m 31s\tremaining: 1m 3s\n",
      "706:\tlearn: 0.2097342\ttotal: 2m 31s\tremaining: 1m 2s\n",
      "707:\tlearn: 0.2096995\ttotal: 2m 32s\tremaining: 1m 2s\n",
      "708:\tlearn: 0.2096800\ttotal: 2m 32s\tremaining: 1m 2s\n",
      "709:\tlearn: 0.2096595\ttotal: 2m 32s\tremaining: 1m 2s\n",
      "710:\tlearn: 0.2096433\ttotal: 2m 32s\tremaining: 1m 2s\n",
      "711:\tlearn: 0.2096106\ttotal: 2m 32s\tremaining: 1m 1s\n",
      "712:\tlearn: 0.2095798\ttotal: 2m 33s\tremaining: 1m 1s\n",
      "713:\tlearn: 0.2095508\ttotal: 2m 33s\tremaining: 1m 1s\n",
      "714:\tlearn: 0.2095247\ttotal: 2m 33s\tremaining: 1m 1s\n",
      "715:\tlearn: 0.2094925\ttotal: 2m 33s\tremaining: 1m\n",
      "716:\tlearn: 0.2094698\ttotal: 2m 33s\tremaining: 1m\n",
      "717:\tlearn: 0.2094268\ttotal: 2m 34s\tremaining: 1m\n",
      "718:\tlearn: 0.2093930\ttotal: 2m 34s\tremaining: 1m\n",
      "719:\tlearn: 0.2093694\ttotal: 2m 34s\tremaining: 1m\n",
      "720:\tlearn: 0.2093348\ttotal: 2m 34s\tremaining: 59.9s\n",
      "721:\tlearn: 0.2093100\ttotal: 2m 34s\tremaining: 59.6s\n",
      "722:\tlearn: 0.2092735\ttotal: 2m 35s\tremaining: 59.4s\n",
      "723:\tlearn: 0.2092505\ttotal: 2m 35s\tremaining: 59.2s\n",
      "724:\tlearn: 0.2092185\ttotal: 2m 35s\tremaining: 59s\n",
      "725:\tlearn: 0.2091806\ttotal: 2m 35s\tremaining: 58.8s\n",
      "726:\tlearn: 0.2091594\ttotal: 2m 35s\tremaining: 58.5s\n",
      "727:\tlearn: 0.2091380\ttotal: 2m 36s\tremaining: 58.3s\n",
      "728:\tlearn: 0.2091114\ttotal: 2m 36s\tremaining: 58.1s\n",
      "729:\tlearn: 0.2090862\ttotal: 2m 36s\tremaining: 57.9s\n",
      "730:\tlearn: 0.2090659\ttotal: 2m 36s\tremaining: 57.6s\n",
      "731:\tlearn: 0.2090399\ttotal: 2m 36s\tremaining: 57.4s\n",
      "732:\tlearn: 0.2090144\ttotal: 2m 37s\tremaining: 57.2s\n",
      "733:\tlearn: 0.2089936\ttotal: 2m 37s\tremaining: 57s\n",
      "734:\tlearn: 0.2088291\ttotal: 2m 37s\tremaining: 56.8s\n",
      "735:\tlearn: 0.2088043\ttotal: 2m 37s\tremaining: 56.6s\n",
      "736:\tlearn: 0.2087800\ttotal: 2m 37s\tremaining: 56.4s\n",
      "737:\tlearn: 0.2087502\ttotal: 2m 38s\tremaining: 56.2s\n",
      "738:\tlearn: 0.2087283\ttotal: 2m 38s\tremaining: 56s\n",
      "739:\tlearn: 0.2087051\ttotal: 2m 38s\tremaining: 55.7s\n",
      "740:\tlearn: 0.2086771\ttotal: 2m 38s\tremaining: 55.5s\n",
      "741:\tlearn: 0.2086635\ttotal: 2m 39s\tremaining: 55.3s\n",
      "742:\tlearn: 0.2086432\ttotal: 2m 39s\tremaining: 55.1s\n",
      "743:\tlearn: 0.2086148\ttotal: 2m 39s\tremaining: 54.9s\n",
      "744:\tlearn: 0.2085960\ttotal: 2m 39s\tremaining: 54.7s\n",
      "745:\tlearn: 0.2085671\ttotal: 2m 40s\tremaining: 54.5s\n",
      "746:\tlearn: 0.2085424\ttotal: 2m 40s\tremaining: 54.3s\n",
      "747:\tlearn: 0.2085163\ttotal: 2m 40s\tremaining: 54.1s\n",
      "748:\tlearn: 0.2084939\ttotal: 2m 40s\tremaining: 53.9s\n",
      "749:\tlearn: 0.2084670\ttotal: 2m 41s\tremaining: 53.7s\n",
      "750:\tlearn: 0.2084496\ttotal: 2m 41s\tremaining: 53.5s\n",
      "751:\tlearn: 0.2084252\ttotal: 2m 41s\tremaining: 53.3s\n",
      "752:\tlearn: 0.2084011\ttotal: 2m 41s\tremaining: 53.1s\n",
      "753:\tlearn: 0.2083704\ttotal: 2m 42s\tremaining: 52.9s\n",
      "754:\tlearn: 0.2083423\ttotal: 2m 42s\tremaining: 52.7s\n",
      "755:\tlearn: 0.2083078\ttotal: 2m 42s\tremaining: 52.4s\n",
      "756:\tlearn: 0.2082828\ttotal: 2m 42s\tremaining: 52.3s\n",
      "757:\tlearn: 0.2082623\ttotal: 2m 42s\tremaining: 52s\n",
      "758:\tlearn: 0.2082324\ttotal: 2m 43s\tremaining: 51.8s\n",
      "759:\tlearn: 0.2082063\ttotal: 2m 43s\tremaining: 51.6s\n",
      "760:\tlearn: 0.2081764\ttotal: 2m 43s\tremaining: 51.4s\n",
      "761:\tlearn: 0.2081330\ttotal: 2m 43s\tremaining: 51.2s\n",
      "762:\tlearn: 0.2081082\ttotal: 2m 44s\tremaining: 51s\n",
      "763:\tlearn: 0.2080760\ttotal: 2m 44s\tremaining: 50.8s\n",
      "764:\tlearn: 0.2080518\ttotal: 2m 44s\tremaining: 50.6s\n",
      "765:\tlearn: 0.2080281\ttotal: 2m 44s\tremaining: 50.4s\n",
      "766:\tlearn: 0.2079993\ttotal: 2m 45s\tremaining: 50.1s\n",
      "767:\tlearn: 0.2079788\ttotal: 2m 45s\tremaining: 49.9s\n",
      "768:\tlearn: 0.2079489\ttotal: 2m 45s\tremaining: 49.7s\n",
      "769:\tlearn: 0.2079254\ttotal: 2m 45s\tremaining: 49.5s\n",
      "770:\tlearn: 0.2079020\ttotal: 2m 45s\tremaining: 49.3s\n",
      "771:\tlearn: 0.2078818\ttotal: 2m 46s\tremaining: 49.1s\n",
      "772:\tlearn: 0.2078585\ttotal: 2m 46s\tremaining: 48.8s\n",
      "773:\tlearn: 0.2078344\ttotal: 2m 46s\tremaining: 48.6s\n",
      "774:\tlearn: 0.2078048\ttotal: 2m 46s\tremaining: 48.4s\n",
      "775:\tlearn: 0.2077792\ttotal: 2m 46s\tremaining: 48.2s\n",
      "776:\tlearn: 0.2077502\ttotal: 2m 47s\tremaining: 48s\n",
      "777:\tlearn: 0.2077272\ttotal: 2m 47s\tremaining: 47.8s\n",
      "778:\tlearn: 0.2076941\ttotal: 2m 47s\tremaining: 47.6s\n",
      "779:\tlearn: 0.2076767\ttotal: 2m 47s\tremaining: 47.3s\n",
      "780:\tlearn: 0.2076522\ttotal: 2m 48s\tremaining: 47.1s\n",
      "781:\tlearn: 0.2076242\ttotal: 2m 48s\tremaining: 46.9s\n",
      "782:\tlearn: 0.2075908\ttotal: 2m 48s\tremaining: 46.7s\n",
      "783:\tlearn: 0.2075578\ttotal: 2m 48s\tremaining: 46.5s\n",
      "784:\tlearn: 0.2075257\ttotal: 2m 48s\tremaining: 46.2s\n",
      "785:\tlearn: 0.2075026\ttotal: 2m 49s\tremaining: 46s\n",
      "786:\tlearn: 0.2074694\ttotal: 2m 49s\tremaining: 45.8s\n",
      "787:\tlearn: 0.2074509\ttotal: 2m 49s\tremaining: 45.6s\n",
      "788:\tlearn: 0.2074177\ttotal: 2m 49s\tremaining: 45.4s\n",
      "789:\tlearn: 0.2073849\ttotal: 2m 49s\tremaining: 45.1s\n",
      "790:\tlearn: 0.2073656\ttotal: 2m 50s\tremaining: 44.9s\n",
      "791:\tlearn: 0.2073467\ttotal: 2m 50s\tremaining: 44.7s\n",
      "792:\tlearn: 0.2073201\ttotal: 2m 50s\tremaining: 44.5s\n",
      "793:\tlearn: 0.2072547\ttotal: 2m 50s\tremaining: 44.3s\n",
      "794:\tlearn: 0.2072231\ttotal: 2m 50s\tremaining: 44s\n",
      "795:\tlearn: 0.2071966\ttotal: 2m 51s\tremaining: 43.8s\n",
      "796:\tlearn: 0.2071747\ttotal: 2m 51s\tremaining: 43.6s\n",
      "797:\tlearn: 0.2071527\ttotal: 2m 51s\tremaining: 43.4s\n",
      "798:\tlearn: 0.2071324\ttotal: 2m 51s\tremaining: 43.2s\n",
      "799:\tlearn: 0.2071114\ttotal: 2m 51s\tremaining: 43s\n",
      "800:\tlearn: 0.2070803\ttotal: 2m 52s\tremaining: 42.8s\n",
      "801:\tlearn: 0.2070579\ttotal: 2m 52s\tremaining: 42.5s\n",
      "802:\tlearn: 0.2070404\ttotal: 2m 52s\tremaining: 42.3s\n",
      "803:\tlearn: 0.2070185\ttotal: 2m 52s\tremaining: 42.1s\n",
      "804:\tlearn: 0.2069879\ttotal: 2m 52s\tremaining: 41.9s\n",
      "805:\tlearn: 0.2069539\ttotal: 2m 53s\tremaining: 41.7s\n",
      "806:\tlearn: 0.2068336\ttotal: 2m 53s\tremaining: 41.4s\n",
      "807:\tlearn: 0.2068045\ttotal: 2m 53s\tremaining: 41.2s\n",
      "808:\tlearn: 0.2067843\ttotal: 2m 53s\tremaining: 41s\n",
      "809:\tlearn: 0.2067561\ttotal: 2m 53s\tremaining: 40.8s\n",
      "810:\tlearn: 0.2067202\ttotal: 2m 54s\tremaining: 40.6s\n",
      "811:\tlearn: 0.2066940\ttotal: 2m 54s\tremaining: 40.4s\n",
      "812:\tlearn: 0.2066671\ttotal: 2m 54s\tremaining: 40.1s\n",
      "813:\tlearn: 0.2066371\ttotal: 2m 54s\tremaining: 39.9s\n",
      "814:\tlearn: 0.2066027\ttotal: 2m 54s\tremaining: 39.7s\n",
      "815:\tlearn: 0.2065754\ttotal: 2m 55s\tremaining: 39.5s\n",
      "816:\tlearn: 0.2065424\ttotal: 2m 55s\tremaining: 39.3s\n",
      "817:\tlearn: 0.2065180\ttotal: 2m 55s\tremaining: 39.1s\n",
      "818:\tlearn: 0.2064964\ttotal: 2m 55s\tremaining: 38.9s\n",
      "819:\tlearn: 0.2064690\ttotal: 2m 56s\tremaining: 38.7s\n",
      "820:\tlearn: 0.2064451\ttotal: 2m 56s\tremaining: 38.4s\n",
      "821:\tlearn: 0.2064223\ttotal: 2m 56s\tremaining: 38.2s\n",
      "822:\tlearn: 0.2063950\ttotal: 2m 56s\tremaining: 38s\n",
      "823:\tlearn: 0.2063737\ttotal: 2m 56s\tremaining: 37.8s\n",
      "824:\tlearn: 0.2063573\ttotal: 2m 57s\tremaining: 37.6s\n",
      "825:\tlearn: 0.2063242\ttotal: 2m 57s\tremaining: 37.4s\n",
      "826:\tlearn: 0.2063023\ttotal: 2m 57s\tremaining: 37.2s\n",
      "827:\tlearn: 0.2062710\ttotal: 2m 57s\tremaining: 36.9s\n",
      "828:\tlearn: 0.2062386\ttotal: 2m 58s\tremaining: 36.7s\n",
      "829:\tlearn: 0.2062150\ttotal: 2m 58s\tremaining: 36.5s\n",
      "830:\tlearn: 0.2061945\ttotal: 2m 58s\tremaining: 36.3s\n",
      "831:\tlearn: 0.2061686\ttotal: 2m 58s\tremaining: 36.1s\n",
      "832:\tlearn: 0.2061518\ttotal: 2m 58s\tremaining: 35.9s\n",
      "833:\tlearn: 0.2061404\ttotal: 2m 59s\tremaining: 35.6s\n",
      "834:\tlearn: 0.2061082\ttotal: 2m 59s\tremaining: 35.4s\n",
      "835:\tlearn: 0.2060866\ttotal: 2m 59s\tremaining: 35.2s\n",
      "836:\tlearn: 0.2060644\ttotal: 2m 59s\tremaining: 35s\n",
      "837:\tlearn: 0.2060336\ttotal: 2m 59s\tremaining: 34.8s\n",
      "838:\tlearn: 0.2060127\ttotal: 3m\tremaining: 34.6s\n",
      "839:\tlearn: 0.2059833\ttotal: 3m\tremaining: 34.4s\n",
      "840:\tlearn: 0.2059581\ttotal: 3m\tremaining: 34.1s\n",
      "841:\tlearn: 0.2059333\ttotal: 3m\tremaining: 33.9s\n",
      "842:\tlearn: 0.2059088\ttotal: 3m\tremaining: 33.7s\n",
      "843:\tlearn: 0.2058782\ttotal: 3m 1s\tremaining: 33.5s\n",
      "844:\tlearn: 0.2058582\ttotal: 3m 1s\tremaining: 33.3s\n",
      "845:\tlearn: 0.2058320\ttotal: 3m 1s\tremaining: 33.1s\n",
      "846:\tlearn: 0.2058141\ttotal: 3m 1s\tremaining: 32.8s\n",
      "847:\tlearn: 0.2057844\ttotal: 3m 2s\tremaining: 32.6s\n",
      "848:\tlearn: 0.2057508\ttotal: 3m 2s\tremaining: 32.4s\n",
      "849:\tlearn: 0.2057201\ttotal: 3m 2s\tremaining: 32.2s\n",
      "850:\tlearn: 0.2056982\ttotal: 3m 2s\tremaining: 32s\n",
      "851:\tlearn: 0.2056736\ttotal: 3m 2s\tremaining: 31.8s\n",
      "852:\tlearn: 0.2056544\ttotal: 3m 3s\tremaining: 31.6s\n",
      "853:\tlearn: 0.2056277\ttotal: 3m 3s\tremaining: 31.3s\n",
      "854:\tlearn: 0.2054725\ttotal: 3m 3s\tremaining: 31.1s\n",
      "855:\tlearn: 0.2054426\ttotal: 3m 3s\tremaining: 30.9s\n",
      "856:\tlearn: 0.2054254\ttotal: 3m 3s\tremaining: 30.7s\n",
      "857:\tlearn: 0.2053945\ttotal: 3m 4s\tremaining: 30.5s\n",
      "858:\tlearn: 0.2053788\ttotal: 3m 4s\tremaining: 30.3s\n",
      "859:\tlearn: 0.2053600\ttotal: 3m 4s\tremaining: 30.1s\n",
      "860:\tlearn: 0.2053349\ttotal: 3m 4s\tremaining: 29.8s\n",
      "861:\tlearn: 0.2053161\ttotal: 3m 5s\tremaining: 29.6s\n",
      "862:\tlearn: 0.2052983\ttotal: 3m 5s\tremaining: 29.4s\n",
      "863:\tlearn: 0.2052622\ttotal: 3m 5s\tremaining: 29.2s\n",
      "864:\tlearn: 0.2052474\ttotal: 3m 5s\tremaining: 29s\n",
      "865:\tlearn: 0.2052136\ttotal: 3m 5s\tremaining: 28.8s\n",
      "866:\tlearn: 0.2051888\ttotal: 3m 6s\tremaining: 28.6s\n",
      "867:\tlearn: 0.2051659\ttotal: 3m 6s\tremaining: 28.3s\n",
      "868:\tlearn: 0.2051526\ttotal: 3m 6s\tremaining: 28.1s\n",
      "869:\tlearn: 0.2051275\ttotal: 3m 6s\tremaining: 27.9s\n",
      "870:\tlearn: 0.2051060\ttotal: 3m 6s\tremaining: 27.7s\n",
      "871:\tlearn: 0.2050846\ttotal: 3m 7s\tremaining: 27.5s\n",
      "872:\tlearn: 0.2050549\ttotal: 3m 7s\tremaining: 27.3s\n",
      "873:\tlearn: 0.2050296\ttotal: 3m 7s\tremaining: 27s\n",
      "874:\tlearn: 0.2050011\ttotal: 3m 7s\tremaining: 26.8s\n",
      "875:\tlearn: 0.2049821\ttotal: 3m 8s\tremaining: 26.6s\n",
      "876:\tlearn: 0.2049602\ttotal: 3m 8s\tremaining: 26.4s\n",
      "877:\tlearn: 0.2049462\ttotal: 3m 8s\tremaining: 26.2s\n",
      "878:\tlearn: 0.2049155\ttotal: 3m 8s\tremaining: 26s\n",
      "879:\tlearn: 0.2048876\ttotal: 3m 8s\tremaining: 25.8s\n",
      "880:\tlearn: 0.2048683\ttotal: 3m 9s\tremaining: 25.5s\n",
      "881:\tlearn: 0.2048589\ttotal: 3m 9s\tremaining: 25.3s\n",
      "882:\tlearn: 0.2048280\ttotal: 3m 9s\tremaining: 25.1s\n",
      "883:\tlearn: 0.2047993\ttotal: 3m 9s\tremaining: 24.9s\n",
      "884:\tlearn: 0.2047764\ttotal: 3m 9s\tremaining: 24.7s\n",
      "885:\tlearn: 0.2047578\ttotal: 3m 10s\tremaining: 24.5s\n",
      "886:\tlearn: 0.2047333\ttotal: 3m 10s\tremaining: 24.2s\n",
      "887:\tlearn: 0.2047103\ttotal: 3m 10s\tremaining: 24s\n",
      "888:\tlearn: 0.2046811\ttotal: 3m 10s\tremaining: 23.8s\n",
      "889:\tlearn: 0.2046537\ttotal: 3m 10s\tremaining: 23.6s\n",
      "890:\tlearn: 0.2046342\ttotal: 3m 11s\tremaining: 23.4s\n",
      "891:\tlearn: 0.2046159\ttotal: 3m 11s\tremaining: 23.2s\n",
      "892:\tlearn: 0.2045947\ttotal: 3m 11s\tremaining: 23s\n",
      "893:\tlearn: 0.2045719\ttotal: 3m 11s\tremaining: 22.7s\n",
      "894:\tlearn: 0.2045385\ttotal: 3m 12s\tremaining: 22.5s\n",
      "895:\tlearn: 0.2045169\ttotal: 3m 12s\tremaining: 22.3s\n",
      "896:\tlearn: 0.2044895\ttotal: 3m 12s\tremaining: 22.1s\n",
      "897:\tlearn: 0.2044668\ttotal: 3m 12s\tremaining: 21.9s\n",
      "898:\tlearn: 0.2044408\ttotal: 3m 12s\tremaining: 21.7s\n",
      "899:\tlearn: 0.2044130\ttotal: 3m 13s\tremaining: 21.5s\n",
      "900:\tlearn: 0.2043889\ttotal: 3m 13s\tremaining: 21.2s\n",
      "901:\tlearn: 0.2043659\ttotal: 3m 13s\tremaining: 21s\n",
      "902:\tlearn: 0.2043422\ttotal: 3m 13s\tremaining: 20.8s\n",
      "903:\tlearn: 0.2043174\ttotal: 3m 13s\tremaining: 20.6s\n",
      "904:\tlearn: 0.2042896\ttotal: 3m 14s\tremaining: 20.4s\n",
      "905:\tlearn: 0.2042699\ttotal: 3m 14s\tremaining: 20.1s\n",
      "906:\tlearn: 0.2042489\ttotal: 3m 14s\tremaining: 19.9s\n",
      "907:\tlearn: 0.2042253\ttotal: 3m 14s\tremaining: 19.7s\n",
      "908:\tlearn: 0.2042014\ttotal: 3m 14s\tremaining: 19.5s\n",
      "909:\tlearn: 0.2041806\ttotal: 3m 14s\tremaining: 19.3s\n",
      "910:\tlearn: 0.2040987\ttotal: 3m 15s\tremaining: 19.1s\n",
      "911:\tlearn: 0.2040707\ttotal: 3m 15s\tremaining: 18.8s\n",
      "912:\tlearn: 0.2040413\ttotal: 3m 15s\tremaining: 18.6s\n",
      "913:\tlearn: 0.2040048\ttotal: 3m 15s\tremaining: 18.4s\n",
      "914:\tlearn: 0.2039751\ttotal: 3m 16s\tremaining: 18.2s\n",
      "915:\tlearn: 0.2039478\ttotal: 3m 16s\tremaining: 18s\n",
      "916:\tlearn: 0.2039188\ttotal: 3m 16s\tremaining: 17.8s\n",
      "917:\tlearn: 0.2038917\ttotal: 3m 16s\tremaining: 17.6s\n",
      "918:\tlearn: 0.2038758\ttotal: 3m 16s\tremaining: 17.4s\n",
      "919:\tlearn: 0.2038467\ttotal: 3m 17s\tremaining: 17.1s\n",
      "920:\tlearn: 0.2038198\ttotal: 3m 17s\tremaining: 16.9s\n",
      "921:\tlearn: 0.2037966\ttotal: 3m 17s\tremaining: 16.7s\n",
      "922:\tlearn: 0.2037534\ttotal: 3m 17s\tremaining: 16.5s\n",
      "923:\tlearn: 0.2037229\ttotal: 3m 17s\tremaining: 16.3s\n",
      "924:\tlearn: 0.2036987\ttotal: 3m 18s\tremaining: 16.1s\n",
      "925:\tlearn: 0.2036725\ttotal: 3m 18s\tremaining: 15.9s\n",
      "926:\tlearn: 0.2036489\ttotal: 3m 18s\tremaining: 15.6s\n",
      "927:\tlearn: 0.2036249\ttotal: 3m 18s\tremaining: 15.4s\n",
      "928:\tlearn: 0.2036028\ttotal: 3m 18s\tremaining: 15.2s\n",
      "929:\tlearn: 0.2035701\ttotal: 3m 19s\tremaining: 15s\n",
      "930:\tlearn: 0.2035398\ttotal: 3m 19s\tremaining: 14.8s\n",
      "931:\tlearn: 0.2035215\ttotal: 3m 19s\tremaining: 14.6s\n",
      "932:\tlearn: 0.2034863\ttotal: 3m 19s\tremaining: 14.3s\n",
      "933:\tlearn: 0.2034538\ttotal: 3m 20s\tremaining: 14.1s\n",
      "934:\tlearn: 0.2034225\ttotal: 3m 20s\tremaining: 13.9s\n",
      "935:\tlearn: 0.2034005\ttotal: 3m 20s\tremaining: 13.7s\n",
      "936:\tlearn: 0.2033771\ttotal: 3m 20s\tremaining: 13.5s\n",
      "937:\tlearn: 0.2033475\ttotal: 3m 20s\tremaining: 13.3s\n",
      "938:\tlearn: 0.2033265\ttotal: 3m 21s\tremaining: 13.1s\n",
      "939:\tlearn: 0.2033064\ttotal: 3m 21s\tremaining: 12.8s\n",
      "940:\tlearn: 0.2032872\ttotal: 3m 21s\tremaining: 12.6s\n",
      "941:\tlearn: 0.2032658\ttotal: 3m 21s\tremaining: 12.4s\n",
      "942:\tlearn: 0.2032439\ttotal: 3m 22s\tremaining: 12.2s\n",
      "943:\tlearn: 0.2032270\ttotal: 3m 22s\tremaining: 12s\n",
      "944:\tlearn: 0.2032088\ttotal: 3m 22s\tremaining: 11.8s\n",
      "945:\tlearn: 0.2031805\ttotal: 3m 22s\tremaining: 11.6s\n",
      "946:\tlearn: 0.2031486\ttotal: 3m 22s\tremaining: 11.4s\n",
      "947:\tlearn: 0.2031245\ttotal: 3m 23s\tremaining: 11.1s\n",
      "948:\tlearn: 0.2030985\ttotal: 3m 23s\tremaining: 10.9s\n",
      "949:\tlearn: 0.2030680\ttotal: 3m 23s\tremaining: 10.7s\n",
      "950:\tlearn: 0.2030359\ttotal: 3m 23s\tremaining: 10.5s\n",
      "951:\tlearn: 0.2030083\ttotal: 3m 24s\tremaining: 10.3s\n",
      "952:\tlearn: 0.2029844\ttotal: 3m 24s\tremaining: 10.1s\n",
      "953:\tlearn: 0.2029547\ttotal: 3m 24s\tremaining: 9.87s\n",
      "954:\tlearn: 0.2029288\ttotal: 3m 24s\tremaining: 9.65s\n",
      "955:\tlearn: 0.2029051\ttotal: 3m 25s\tremaining: 9.44s\n",
      "956:\tlearn: 0.2028873\ttotal: 3m 25s\tremaining: 9.22s\n",
      "957:\tlearn: 0.2028539\ttotal: 3m 25s\tremaining: 9.01s\n",
      "958:\tlearn: 0.2028231\ttotal: 3m 25s\tremaining: 8.8s\n",
      "959:\tlearn: 0.2027970\ttotal: 3m 26s\tremaining: 8.59s\n",
      "960:\tlearn: 0.2027695\ttotal: 3m 26s\tremaining: 8.37s\n",
      "961:\tlearn: 0.2027391\ttotal: 3m 26s\tremaining: 8.16s\n",
      "962:\tlearn: 0.2027141\ttotal: 3m 26s\tremaining: 7.94s\n",
      "963:\tlearn: 0.2026893\ttotal: 3m 26s\tremaining: 7.73s\n",
      "964:\tlearn: 0.2026714\ttotal: 3m 27s\tremaining: 7.51s\n",
      "965:\tlearn: 0.2026388\ttotal: 3m 27s\tremaining: 7.3s\n",
      "966:\tlearn: 0.2026192\ttotal: 3m 27s\tremaining: 7.08s\n",
      "967:\tlearn: 0.2025905\ttotal: 3m 27s\tremaining: 6.87s\n",
      "968:\tlearn: 0.2025664\ttotal: 3m 28s\tremaining: 6.66s\n",
      "969:\tlearn: 0.2025432\ttotal: 3m 28s\tremaining: 6.44s\n",
      "970:\tlearn: 0.2025200\ttotal: 3m 28s\tremaining: 6.23s\n",
      "971:\tlearn: 0.2024917\ttotal: 3m 28s\tremaining: 6.01s\n",
      "972:\tlearn: 0.2024617\ttotal: 3m 29s\tremaining: 5.8s\n",
      "973:\tlearn: 0.2024385\ttotal: 3m 29s\tremaining: 5.59s\n",
      "974:\tlearn: 0.2024128\ttotal: 3m 29s\tremaining: 5.37s\n",
      "975:\tlearn: 0.2023977\ttotal: 3m 29s\tremaining: 5.16s\n",
      "976:\tlearn: 0.2023195\ttotal: 3m 29s\tremaining: 4.94s\n",
      "977:\tlearn: 0.2023027\ttotal: 3m 30s\tremaining: 4.73s\n",
      "978:\tlearn: 0.2022883\ttotal: 3m 30s\tremaining: 4.51s\n",
      "979:\tlearn: 0.2022587\ttotal: 3m 30s\tremaining: 4.3s\n",
      "980:\tlearn: 0.2022425\ttotal: 3m 30s\tremaining: 4.08s\n",
      "981:\tlearn: 0.2022221\ttotal: 3m 31s\tremaining: 3.87s\n",
      "982:\tlearn: 0.2021964\ttotal: 3m 31s\tremaining: 3.65s\n",
      "983:\tlearn: 0.2021839\ttotal: 3m 31s\tremaining: 3.44s\n",
      "984:\tlearn: 0.2021613\ttotal: 3m 31s\tremaining: 3.22s\n",
      "985:\tlearn: 0.2021348\ttotal: 3m 31s\tremaining: 3.01s\n",
      "986:\tlearn: 0.2021122\ttotal: 3m 32s\tremaining: 2.79s\n",
      "987:\tlearn: 0.2020851\ttotal: 3m 32s\tremaining: 2.58s\n",
      "988:\tlearn: 0.2020678\ttotal: 3m 32s\tremaining: 2.36s\n",
      "989:\tlearn: 0.2020457\ttotal: 3m 32s\tremaining: 2.15s\n",
      "990:\tlearn: 0.2020284\ttotal: 3m 32s\tremaining: 1.93s\n",
      "991:\tlearn: 0.2020050\ttotal: 3m 33s\tremaining: 1.72s\n",
      "992:\tlearn: 0.2019788\ttotal: 3m 33s\tremaining: 1.5s\n",
      "993:\tlearn: 0.2019576\ttotal: 3m 33s\tremaining: 1.29s\n",
      "994:\tlearn: 0.2019373\ttotal: 3m 33s\tremaining: 1.07s\n",
      "995:\tlearn: 0.2019138\ttotal: 3m 33s\tremaining: 859ms\n",
      "996:\tlearn: 0.2018899\ttotal: 3m 34s\tremaining: 644ms\n",
      "997:\tlearn: 0.2018688\ttotal: 3m 34s\tremaining: 429ms\n",
      "998:\tlearn: 0.2017966\ttotal: 3m 34s\tremaining: 215ms\n",
      "999:\tlearn: 0.2017691\ttotal: 3m 34s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2c4f65d8250>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "catboost = CatBoostClassifier(l2_leaf_reg=1,\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='Logloss',\n",
    "    verbose=True)\n",
    "\n",
    "catboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = catboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91     40638\n",
      "         1.0       0.86      0.94      0.90     34082\n",
      "\n",
      "    accuracy                           0.90     74720\n",
      "   macro avg       0.90      0.91      0.90     74720\n",
      "weighted avg       0.91      0.90      0.90     74720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7823/7823 [==============================] - 51s 6ms/step - loss: 3107.2209 - accuracy: 0.6453 - val_loss: 5127.2896 - val_accuracy: 0.6528\n",
      "Epoch 2/10\n",
      "7823/7823 [==============================] - 52s 7ms/step - loss: 647.9689 - accuracy: 0.6293 - val_loss: 24.6616 - val_accuracy: 0.5391\n",
      "Epoch 3/10\n",
      "7823/7823 [==============================] - 48s 6ms/step - loss: 5.1767 - accuracy: 0.5043 - val_loss: 4.6025 - val_accuracy: 0.4995\n",
      "Epoch 4/10\n",
      "7823/7823 [==============================] - 47s 6ms/step - loss: 1.4748 - accuracy: 0.4997 - val_loss: 0.8654 - val_accuracy: 0.5009\n",
      "Epoch 5/10\n",
      "7823/7823 [==============================] - 46s 6ms/step - loss: 2.0833 - accuracy: 0.5001 - val_loss: 0.7870 - val_accuracy: 0.4992\n",
      "Epoch 6/10\n",
      "7823/7823 [==============================] - 50s 6ms/step - loss: 0.7444 - accuracy: 0.4988 - val_loss: 0.6931 - val_accuracy: 0.4992\n",
      "Epoch 7/10\n",
      "7823/7823 [==============================] - 57s 7ms/step - loss: 0.6932 - accuracy: 0.5007 - val_loss: 0.6931 - val_accuracy: 0.5009\n",
      "Epoch 8/10\n",
      "7823/7823 [==============================] - 49s 6ms/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6931 - val_accuracy: 0.5009\n",
      "Epoch 9/10\n",
      "7823/7823 [==============================] - 47s 6ms/step - loss: 0.6933 - accuracy: 0.4994 - val_loss: 0.6932 - val_accuracy: 0.5009\n",
      "Epoch 10/10\n",
      "7823/7823 [==============================] - 46s 6ms/step - loss: 0.6980 - accuracy: 0.4979 - val_loss: 0.6982 - val_accuracy: 0.5009\n",
      "3853/3853 [==============================] - 15s 4ms/step - loss: 0.6982 - accuracy: 0.5009\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'new_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Предсказание на новых данных\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mnew_data\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_data' is not defined"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(32, activation='relu', input_dim=X_train.shape[1]),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "\n",
    "predictions = model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    186799\n",
       "0.0    186799\n",
       "Name: is_owner, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_resampled).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=0.01, hidden_layer_sizes=(50, 30))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.01, hidden_layer_sizes=(50, 30))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=0.01, hidden_layer_sizes=(50, 30))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(50, 30), activation='relu', solver='adam', alpha=0.01)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.50      0.67    123288\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50    123288\n",
      "   macro avg       0.50      0.25      0.33    123288\n",
      "weighted avg       1.00      0.50      0.67    123288\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_category_pharmacy_percent_amt_2m</th>\n",
       "      <th>transaction_category_pharmacy_percent_cnt_2m</th>\n",
       "      <th>transaction_category_pharmacy_sum_cnt_m2</th>\n",
       "      <th>by_category__amount__SUM__eoperation_type_name__perevod_po_nomeru_telefona</th>\n",
       "      <th>transaction_category_fastfood_percent_amt_2m</th>\n",
       "      <th>transaction_category_fastfood_percent_cnt_2m</th>\n",
       "      <th>transaction_category_other_retail_purchase_percent_amt_2m</th>\n",
       "      <th>transaction_category_other_retail_purchase_sum_amt_m2</th>\n",
       "      <th>transaction_category_other_retail_purchase_sum_cnt_m2</th>\n",
       "      <th>transaction_category_other_retail_purchase_percent_cnt_2m</th>\n",
       "      <th>...</th>\n",
       "      <th>srvpackage_Комфорт</th>\n",
       "      <th>srvpackage_КомфортUltra</th>\n",
       "      <th>srvpackage_КомфортUltrafree</th>\n",
       "      <th>srvpackage_Комфортfree</th>\n",
       "      <th>srvpackage_Корпоративный</th>\n",
       "      <th>srvpackage_Максимум+</th>\n",
       "      <th>srvpackage_Максимум+free</th>\n",
       "      <th>srvpackage_МаксимумUltra</th>\n",
       "      <th>srvpackage_МаксимумUltrafree</th>\n",
       "      <th>addrref_coder_г. Санкт - Петербург</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349363</th>\n",
       "      <td>0.053145</td>\n",
       "      <td>0.083475</td>\n",
       "      <td>7.428864</td>\n",
       "      <td>3951.870185</td>\n",
       "      <td>0.021537</td>\n",
       "      <td>0.044148</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>295.677264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337901</th>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.020727</td>\n",
       "      <td>4.145459</td>\n",
       "      <td>2185.634980</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.053662</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>18803.516072</td>\n",
       "      <td>6.803643</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92453</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83146</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360757</th>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.422343</td>\n",
       "      <td>26938.538984</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>0.014398</td>\n",
       "      <td>0.061844</td>\n",
       "      <td>18154.891760</td>\n",
       "      <td>6.645769</td>\n",
       "      <td>0.057453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.577657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259178</th>\n",
       "      <td>0.003496</td>\n",
       "      <td>0.024595</td>\n",
       "      <td>4.458740</td>\n",
       "      <td>480.734794</td>\n",
       "      <td>0.007151</td>\n",
       "      <td>0.125158</td>\n",
       "      <td>0.022301</td>\n",
       "      <td>16719.756092</td>\n",
       "      <td>5.541260</td>\n",
       "      <td>0.033396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.45874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365838</th>\n",
       "      <td>0.007848</td>\n",
       "      <td>0.015584</td>\n",
       "      <td>2.072601</td>\n",
       "      <td>15322.140064</td>\n",
       "      <td>0.029020</td>\n",
       "      <td>0.080195</td>\n",
       "      <td>0.063810</td>\n",
       "      <td>24456.559490</td>\n",
       "      <td>11.564393</td>\n",
       "      <td>0.086535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>0.006781</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>272.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146867</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64734.041096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006256</td>\n",
       "      <td>6053.857500</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250310 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        transaction_category_pharmacy_percent_amt_2m  \\\n",
       "349363                                      0.053145   \n",
       "337901                                      0.001017   \n",
       "92453                                       0.000000   \n",
       "83146                                       0.000000   \n",
       "360757                                      0.000244   \n",
       "...                                              ...   \n",
       "259178                                      0.003496   \n",
       "365838                                      0.007848   \n",
       "131932                                      0.006781   \n",
       "146867                                      0.000000   \n",
       "121958                                      0.000000   \n",
       "\n",
       "        transaction_category_pharmacy_percent_cnt_2m  \\\n",
       "349363                                      0.083475   \n",
       "337901                                      0.020727   \n",
       "92453                                       0.000000   \n",
       "83146                                       0.000000   \n",
       "360757                                      0.002400   \n",
       "...                                              ...   \n",
       "259178                                      0.024595   \n",
       "365838                                      0.015584   \n",
       "131932                                      0.020833   \n",
       "146867                                      0.000000   \n",
       "121958                                      0.000000   \n",
       "\n",
       "        transaction_category_pharmacy_sum_cnt_m2  \\\n",
       "349363                                  7.428864   \n",
       "337901                                  4.145459   \n",
       "92453                                   0.000000   \n",
       "83146                                   0.000000   \n",
       "360757                                  0.422343   \n",
       "...                                          ...   \n",
       "259178                                  4.458740   \n",
       "365838                                  2.072601   \n",
       "131932                                  1.000000   \n",
       "146867                                  0.000000   \n",
       "121958                                  0.000000   \n",
       "\n",
       "        by_category__amount__SUM__eoperation_type_name__perevod_po_nomeru_telefona  \\\n",
       "349363                                        3951.870185                            \n",
       "337901                                        2185.634980                            \n",
       "92453                                            0.000000                            \n",
       "83146                                            0.000000                            \n",
       "360757                                       26938.538984                            \n",
       "...                                                   ...                            \n",
       "259178                                         480.734794                            \n",
       "365838                                       15322.140064                            \n",
       "131932                                         272.727273                            \n",
       "146867                                           0.000000                            \n",
       "121958                                       64734.041096                            \n",
       "\n",
       "        transaction_category_fastfood_percent_amt_2m  \\\n",
       "349363                                      0.021537   \n",
       "337901                                      0.001862   \n",
       "92453                                       0.000000   \n",
       "83146                                       0.000000   \n",
       "360757                                      0.004255   \n",
       "...                                              ...   \n",
       "259178                                      0.007151   \n",
       "365838                                      0.029020   \n",
       "131932                                      0.000000   \n",
       "146867                                      0.000000   \n",
       "121958                                      0.000000   \n",
       "\n",
       "        transaction_category_fastfood_percent_cnt_2m  \\\n",
       "349363                                      0.044148   \n",
       "337901                                      0.053662   \n",
       "92453                                       0.000000   \n",
       "83146                                       0.000000   \n",
       "360757                                      0.014398   \n",
       "...                                              ...   \n",
       "259178                                      0.125158   \n",
       "365838                                      0.080195   \n",
       "131932                                      0.000000   \n",
       "146867                                      0.000000   \n",
       "121958                                      0.000000   \n",
       "\n",
       "        transaction_category_other_retail_purchase_percent_amt_2m  \\\n",
       "349363                                           0.004980           \n",
       "337901                                           0.017115           \n",
       "92453                                            0.000000           \n",
       "83146                                            0.000000           \n",
       "360757                                           0.061844           \n",
       "...                                                   ...           \n",
       "259178                                           0.022301           \n",
       "365838                                           0.063810           \n",
       "131932                                           0.000000           \n",
       "146867                                           0.000000           \n",
       "121958                                           0.006256           \n",
       "\n",
       "        transaction_category_other_retail_purchase_sum_amt_m2  \\\n",
       "349363                                         295.677264       \n",
       "337901                                       18803.516072       \n",
       "92453                                            0.000000       \n",
       "83146                                            0.000000       \n",
       "360757                                       18154.891760       \n",
       "...                                                   ...       \n",
       "259178                                       16719.756092       \n",
       "365838                                       24456.559490       \n",
       "131932                                           0.000000       \n",
       "146867                                           0.000000       \n",
       "121958                                        6053.857500       \n",
       "\n",
       "        transaction_category_other_retail_purchase_sum_cnt_m2  \\\n",
       "349363                                           1.000000       \n",
       "337901                                           6.803643       \n",
       "92453                                            0.000000       \n",
       "83146                                            0.000000       \n",
       "360757                                           6.645769       \n",
       "...                                                   ...       \n",
       "259178                                           5.541260       \n",
       "365838                                          11.564393       \n",
       "131932                                           0.000000       \n",
       "146867                                           0.000000       \n",
       "121958                                           3.000000       \n",
       "\n",
       "        transaction_category_other_retail_purchase_percent_cnt_2m  ...  \\\n",
       "349363                                           0.011602          ...   \n",
       "337901                                           0.045371          ...   \n",
       "92453                                            0.000000          ...   \n",
       "83146                                            0.000000          ...   \n",
       "360757                                           0.057453          ...   \n",
       "...                                                   ...          ...   \n",
       "259178                                           0.033396          ...   \n",
       "365838                                           0.086535          ...   \n",
       "131932                                           0.000000          ...   \n",
       "146867                                           0.000000          ...   \n",
       "121958                                           0.142857          ...   \n",
       "\n",
       "        srvpackage_Комфорт  srvpackage_КомфортUltra  \\\n",
       "349363                 0.0                      0.0   \n",
       "337901                 0.0                      0.0   \n",
       "92453                  0.0                      0.0   \n",
       "83146                  0.0                      0.0   \n",
       "360757                 0.0                      0.0   \n",
       "...                    ...                      ...   \n",
       "259178                 0.0                      0.0   \n",
       "365838                 0.0                      0.0   \n",
       "131932                 0.0                      0.0   \n",
       "146867                 0.0                      0.0   \n",
       "121958                 0.0                      0.0   \n",
       "\n",
       "        srvpackage_КомфортUltrafree  srvpackage_Комфортfree  \\\n",
       "349363                          0.0                     0.0   \n",
       "337901                          0.0                     0.0   \n",
       "92453                           0.0                     0.0   \n",
       "83146                           0.0                     0.0   \n",
       "360757                          0.0                     0.0   \n",
       "...                             ...                     ...   \n",
       "259178                          0.0                     0.0   \n",
       "365838                          0.0                     0.0   \n",
       "131932                          0.0                     0.0   \n",
       "146867                          0.0                     0.0   \n",
       "121958                          0.0                     0.0   \n",
       "\n",
       "        srvpackage_Корпоративный  srvpackage_Максимум+  \\\n",
       "349363                  0.000000                   0.0   \n",
       "337901                  0.000000                   0.0   \n",
       "92453                   0.000000                   0.0   \n",
       "83146                   0.000000                   0.0   \n",
       "360757                  0.577657                   0.0   \n",
       "...                          ...                   ...   \n",
       "259178                  0.000000                   0.0   \n",
       "365838                  0.000000                   0.0   \n",
       "131932                  0.000000                   0.0   \n",
       "146867                  0.000000                   0.0   \n",
       "121958                  1.000000                   0.0   \n",
       "\n",
       "        srvpackage_Максимум+free  srvpackage_МаксимумUltra  \\\n",
       "349363                       0.0                       0.0   \n",
       "337901                       0.0                       0.0   \n",
       "92453                        0.0                       0.0   \n",
       "83146                        0.0                       0.0   \n",
       "360757                       0.0                       0.0   \n",
       "...                          ...                       ...   \n",
       "259178                       0.0                       0.0   \n",
       "365838                       0.0                       0.0   \n",
       "131932                       0.0                       0.0   \n",
       "146867                       0.0                       0.0   \n",
       "121958                       0.0                       0.0   \n",
       "\n",
       "        srvpackage_МаксимумUltrafree  addrref_coder_г. Санкт - Петербург  \n",
       "349363                           0.0                             0.00000  \n",
       "337901                           0.0                             0.00000  \n",
       "92453                            0.0                             1.00000  \n",
       "83146                            0.0                             1.00000  \n",
       "360757                           0.0                             0.00000  \n",
       "...                              ...                                 ...  \n",
       "259178                           0.0                             0.45874  \n",
       "365838                           0.0                             0.00000  \n",
       "131932                           0.0                             0.00000  \n",
       "146867                           0.0                             0.00000  \n",
       "121958                           0.0                             0.00000  \n",
       "\n",
       "[250310 rows x 86 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7823/7823 [==============================] - 48s 6ms/step - loss: 2643.6892 - accuracy: 0.5272\n",
      "Epoch 2/10\n",
      "7823/7823 [==============================] - 47s 6ms/step - loss: 5.6764 - accuracy: 0.4990\n",
      "Epoch 3/10\n",
      "7823/7823 [==============================] - 46s 6ms/step - loss: 1.1332 - accuracy: 0.5001\n",
      "Epoch 4/10\n",
      "7823/7823 [==============================] - 48s 6ms/step - loss: 0.7561 - accuracy: 0.4980\n",
      "Epoch 5/10\n",
      "7823/7823 [==============================] - 42s 5ms/step - loss: 0.8899 - accuracy: 0.4997\n",
      "Epoch 6/10\n",
      "7823/7823 [==============================] - 46s 6ms/step - loss: 0.7544 - accuracy: 0.5009\n",
      "Epoch 7/10\n",
      "7823/7823 [==============================] - 51s 6ms/step - loss: 0.7446 - accuracy: 0.4985\n",
      "Epoch 8/10\n",
      "7823/7823 [==============================] - 45s 6ms/step - loss: 0.6940 - accuracy: 0.4999\n",
      "Epoch 9/10\n",
      "7823/7823 [==============================] - 41s 5ms/step - loss: 0.6982 - accuracy: 0.5004\n",
      "Epoch 10/10\n",
      "7823/7823 [==============================] - 42s 5ms/step - loss: 0.6934 - accuracy: 0.5012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c4f33be0b0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight(class_weight= 'balanced', y = y_train, classes = np.unique(y_train))\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(86,)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3853/3853 [==============================] - 16s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0...\n",
       "dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous-multioutput and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [107]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2310\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassification_report\u001b[39m(\n\u001b[0;32m   2196\u001b[0m     y_true,\n\u001b[0;32m   2197\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2204\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2205\u001b[0m ):\n\u001b[0;32m   2206\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[0;32m   2207\u001b[0m \n\u001b[0;32m   2208\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2307\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[0;32m   2308\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2310\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2313\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     92\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     97\u001b[0m             type_true, type_pred\n\u001b[0;32m     98\u001b[0m         )\n\u001b[0;32m     99\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    102\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and binary targets"
     ]
    }
   ],
   "source": [
    "classification_report(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 2004, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py\", line 5532, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 2) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [132]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mopt, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Обучение модели\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Оценка модели\u001b[39;00m\n\u001b[0;32m     25\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filenzlaeq13.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 2004, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py\", line 5532, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 2) are incompatible\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=86))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9340/9340 [==============================] - 97s 10ms/step - loss: 0.6567 - accuracy: 0.7244 - val_loss: 0.7446 - val_accuracy: 0.4981\n",
      "Epoch 2/50\n",
      "9340/9340 [==============================] - 101s 11ms/step - loss: 0.5639 - accuracy: 0.7296 - val_loss: 0.6973 - val_accuracy: 0.5119\n",
      "Epoch 3/50\n",
      "9340/9340 [==============================] - 90s 10ms/step - loss: 0.5605 - accuracy: 0.7313 - val_loss: 0.6778 - val_accuracy: 0.6469\n",
      "Epoch 4/50\n",
      "9340/9340 [==============================] - 91s 10ms/step - loss: 0.5564 - accuracy: 0.7350 - val_loss: 0.7795 - val_accuracy: 0.5029\n",
      "Epoch 5/50\n",
      "9340/9340 [==============================] - 100s 11ms/step - loss: 0.5565 - accuracy: 0.7345 - val_loss: 0.6327 - val_accuracy: 0.6959\n",
      "Epoch 6/50\n",
      "9340/9340 [==============================] - 90s 10ms/step - loss: 0.5547 - accuracy: 0.7355 - val_loss: 0.6272 - val_accuracy: 0.6687\n",
      "Epoch 7/50\n",
      "9340/9340 [==============================] - 93s 10ms/step - loss: 0.5538 - accuracy: 0.7350 - val_loss: 0.7129 - val_accuracy: 0.6337\n",
      "Epoch 8/50\n",
      "9340/9340 [==============================] - 100s 11ms/step - loss: 0.5530 - accuracy: 0.7362 - val_loss: 0.6854 - val_accuracy: 0.6693\n",
      "Epoch 9/50\n",
      "9340/9340 [==============================] - 99s 11ms/step - loss: 0.5502 - accuracy: 0.7374 - val_loss: 0.6456 - val_accuracy: 0.6533\n",
      "Epoch 10/50\n",
      "9340/9340 [==============================] - 99s 11ms/step - loss: 0.5506 - accuracy: 0.7373 - val_loss: 0.7360 - val_accuracy: 0.5003\n",
      "Epoch 11/50\n",
      "9340/9340 [==============================] - 98s 10ms/step - loss: 0.5499 - accuracy: 0.7371 - val_loss: 0.6899 - val_accuracy: 0.6549\n",
      "Epoch 12/50\n",
      "9340/9340 [==============================] - 93s 10ms/step - loss: 0.5503 - accuracy: 0.7371 - val_loss: 0.7469 - val_accuracy: 0.5103\n",
      "Epoch 13/50\n",
      "9340/9340 [==============================] - 91s 10ms/step - loss: 0.5484 - accuracy: 0.7383 - val_loss: 0.6551 - val_accuracy: 0.6601\n",
      "Epoch 14/50\n",
      "9340/9340 [==============================] - 88s 9ms/step - loss: 0.5484 - accuracy: 0.7392 - val_loss: 0.7138 - val_accuracy: 0.5002\n",
      "Epoch 15/50\n",
      "9340/9340 [==============================] - 90s 10ms/step - loss: 0.5486 - accuracy: 0.7389 - val_loss: 0.6905 - val_accuracy: 0.6598\n",
      "Epoch 16/50\n",
      "9340/9340 [==============================] - 91s 10ms/step - loss: 0.5485 - accuracy: 0.7389 - val_loss: 0.8626 - val_accuracy: 0.5003\n",
      "Epoch 17/50\n",
      "9340/9340 [==============================] - 88s 9ms/step - loss: 0.5494 - accuracy: 0.7373 - val_loss: 0.5863 - val_accuracy: 0.6992\n",
      "Epoch 18/50\n",
      "9340/9340 [==============================] - 89s 10ms/step - loss: 0.5477 - accuracy: 0.7382 - val_loss: 0.7114 - val_accuracy: 0.6424\n",
      "Epoch 19/50\n",
      "9340/9340 [==============================] - 89s 10ms/step - loss: 0.5483 - accuracy: 0.7377 - val_loss: 0.5844 - val_accuracy: 0.7110\n",
      "Epoch 20/50\n",
      "9340/9340 [==============================] - 91s 10ms/step - loss: 0.5493 - accuracy: 0.7381 - val_loss: 0.7431 - val_accuracy: 0.5003\n",
      "Epoch 21/50\n",
      "9340/9340 [==============================] - 89s 10ms/step - loss: 0.5497 - accuracy: 0.7367 - val_loss: 0.6116 - val_accuracy: 0.7148\n",
      "Epoch 22/50\n",
      "9340/9340 [==============================] - 90s 10ms/step - loss: 0.5489 - accuracy: 0.7392 - val_loss: 0.7587 - val_accuracy: 0.5120\n",
      "Epoch 23/50\n",
      "9340/9340 [==============================] - 90s 10ms/step - loss: 0.5492 - accuracy: 0.7382 - val_loss: 0.7086 - val_accuracy: 0.5036\n",
      "Epoch 24/50\n",
      "9340/9340 [==============================] - 87s 9ms/step - loss: 0.5507 - accuracy: 0.7370 - val_loss: 0.8550 - val_accuracy: 0.5001\n",
      "Epoch 25/50\n",
      "9340/9340 [==============================] - 88s 9ms/step - loss: 0.5495 - accuracy: 0.7381 - val_loss: 0.6354 - val_accuracy: 0.6838\n",
      "Epoch 26/50\n",
      "9340/9340 [==============================] - 92s 10ms/step - loss: 0.5490 - accuracy: 0.7394 - val_loss: 0.6787 - val_accuracy: 0.5057\n",
      "Epoch 27/50\n",
      "9340/9340 [==============================] - 90s 10ms/step - loss: 0.5499 - accuracy: 0.7383 - val_loss: 0.7397 - val_accuracy: 0.5075\n",
      "Epoch 28/50\n",
      "9340/9340 [==============================] - 90s 10ms/step - loss: 0.5499 - accuracy: 0.7392 - val_loss: 0.6704 - val_accuracy: 0.5307\n",
      "Epoch 29/50\n",
      "9340/9340 [==============================] - 95s 10ms/step - loss: 0.5507 - accuracy: 0.7372 - val_loss: 0.7518 - val_accuracy: 0.5016\n",
      "Epoch 30/50\n",
      "9340/9340 [==============================] - 37952s 4s/step - loss: 0.5481 - accuracy: 0.7389 - val_loss: 0.6727 - val_accuracy: 0.5066\n",
      "Epoch 31/50\n",
      "9340/9340 [==============================] - 33s 4ms/step - loss: 0.5490 - accuracy: 0.7378 - val_loss: 0.7318 - val_accuracy: 0.4992\n",
      "Epoch 32/50\n",
      "9340/9340 [==============================] - 33s 4ms/step - loss: 0.5492 - accuracy: 0.7385 - val_loss: 0.8534 - val_accuracy: 0.5024\n",
      "Epoch 33/50\n",
      "9340/9340 [==============================] - 33s 4ms/step - loss: 0.5485 - accuracy: 0.7394 - val_loss: 0.7503 - val_accuracy: 0.5002\n",
      "Epoch 34/50\n",
      "9340/9340 [==============================] - 33s 4ms/step - loss: 0.5482 - accuracy: 0.7395 - val_loss: 0.8033 - val_accuracy: 0.5003\n",
      "Epoch 35/50\n",
      "9340/9340 [==============================] - 36s 4ms/step - loss: 0.5498 - accuracy: 0.7378 - val_loss: 0.6443 - val_accuracy: 0.6733\n",
      "Epoch 36/50\n",
      "9340/9340 [==============================] - 39s 4ms/step - loss: 0.5483 - accuracy: 0.7402 - val_loss: 0.7151 - val_accuracy: 0.5187\n",
      "Epoch 37/50\n",
      "9340/9340 [==============================] - 36s 4ms/step - loss: 0.5487 - accuracy: 0.7391 - val_loss: 0.7201 - val_accuracy: 0.5212\n",
      "Epoch 38/50\n",
      "9340/9340 [==============================] - 35s 4ms/step - loss: 0.5481 - accuracy: 0.7400 - val_loss: 0.7160 - val_accuracy: 0.5096\n",
      "Epoch 39/50\n",
      "9340/9340 [==============================] - 34s 4ms/step - loss: 0.5480 - accuracy: 0.7392 - val_loss: 0.7285 - val_accuracy: 0.5015\n",
      "Epoch 40/50\n",
      "9340/9340 [==============================] - 34s 4ms/step - loss: 0.5485 - accuracy: 0.7398 - val_loss: 0.7903 - val_accuracy: 0.5033\n",
      "Epoch 41/50\n",
      "9340/9340 [==============================] - 34s 4ms/step - loss: 0.5489 - accuracy: 0.7397 - val_loss: 0.7329 - val_accuracy: 0.5039\n",
      "Epoch 42/50\n",
      "9340/9340 [==============================] - 34s 4ms/step - loss: 0.5487 - accuracy: 0.7381 - val_loss: 0.8681 - val_accuracy: 0.5002\n",
      "Epoch 43/50\n",
      "9340/9340 [==============================] - 34s 4ms/step - loss: 0.5507 - accuracy: 0.7379 - val_loss: 0.6787 - val_accuracy: 0.5069\n",
      "Epoch 44/50\n",
      "9340/9340 [==============================] - 34s 4ms/step - loss: 0.5488 - accuracy: 0.7396 - val_loss: 0.8612 - val_accuracy: 0.5003\n",
      "Epoch 45/50\n",
      "9340/9340 [==============================] - 45s 5ms/step - loss: 0.5494 - accuracy: 0.7390 - val_loss: 0.8243 - val_accuracy: 0.5003\n",
      "Epoch 46/50\n",
      "9340/9340 [==============================] - 63s 7ms/step - loss: 0.5500 - accuracy: 0.7377 - val_loss: 0.6525 - val_accuracy: 0.5480\n",
      "Epoch 47/50\n",
      "9340/9340 [==============================] - 74s 8ms/step - loss: 0.5487 - accuracy: 0.7381 - val_loss: 0.7256 - val_accuracy: 0.4991\n",
      "Epoch 48/50\n",
      "9340/9340 [==============================] - 75s 8ms/step - loss: 0.5466 - accuracy: 0.7411 - val_loss: 0.7776 - val_accuracy: 0.5003\n",
      "Epoch 49/50\n",
      "9340/9340 [==============================] - 77s 8ms/step - loss: 0.5512 - accuracy: 0.7386 - val_loss: 0.6404 - val_accuracy: 0.6924\n",
      "Epoch 50/50\n",
      "9340/9340 [==============================] - 78s 8ms/step - loss: 0.5497 - accuracy: 0.7402 - val_loss: 0.6921 - val_accuracy: 0.5199\n",
      "2335/2335 [==============================] - 12s 5ms/step - loss: 0.6921 - accuracy: 0.5199\n",
      "Accuracy: 51.99\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X, Y)\n",
    "y_resampled.value_counts()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=86, kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2335/2335 [==============================] - 11s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_pred_classes, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbmNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading lightgbm-3.3.5-py3-none-win_amd64.whl (1.0 MB)\n",
      "     ---------------------------------------- 1.0/1.0 MB 1.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm) (0.40.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm) (1.22.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm) (1.8.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm) (1.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.5\n"
     ]
    }
   ],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=86, kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1,\n",
    "    'class_weight': 'balanced'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[1]\tvalid_0's auc: 0.891451\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's auc: 0.903931\n",
      "[3]\tvalid_0's auc: 0.911335\n",
      "[4]\tvalid_0's auc: 0.914057\n",
      "[5]\tvalid_0's auc: 0.914387\n",
      "[6]\tvalid_0's auc: 0.915159\n",
      "[7]\tvalid_0's auc: 0.916936\n",
      "[8]\tvalid_0's auc: 0.917541\n",
      "[9]\tvalid_0's auc: 0.918187\n",
      "[10]\tvalid_0's auc: 0.918549\n",
      "[11]\tvalid_0's auc: 0.919518\n",
      "[12]\tvalid_0's auc: 0.919419\n",
      "[13]\tvalid_0's auc: 0.920632\n",
      "[14]\tvalid_0's auc: 0.921209\n",
      "[15]\tvalid_0's auc: 0.922329\n",
      "[16]\tvalid_0's auc: 0.92291\n",
      "[17]\tvalid_0's auc: 0.923575\n",
      "[18]\tvalid_0's auc: 0.924103\n",
      "[19]\tvalid_0's auc: 0.924579\n",
      "[20]\tvalid_0's auc: 0.927474\n",
      "[21]\tvalid_0's auc: 0.928661\n",
      "[22]\tvalid_0's auc: 0.929048\n",
      "[23]\tvalid_0's auc: 0.929981\n",
      "[24]\tvalid_0's auc: 0.931123\n",
      "[25]\tvalid_0's auc: 0.932359\n",
      "[26]\tvalid_0's auc: 0.932839\n",
      "[27]\tvalid_0's auc: 0.93323\n",
      "[28]\tvalid_0's auc: 0.933779\n",
      "[29]\tvalid_0's auc: 0.934585\n",
      "[30]\tvalid_0's auc: 0.935308\n",
      "[31]\tvalid_0's auc: 0.936327\n",
      "[32]\tvalid_0's auc: 0.936883\n",
      "[33]\tvalid_0's auc: 0.937275\n",
      "[34]\tvalid_0's auc: 0.938139\n",
      "[35]\tvalid_0's auc: 0.938526\n",
      "[36]\tvalid_0's auc: 0.938896\n",
      "[37]\tvalid_0's auc: 0.939218\n",
      "[38]\tvalid_0's auc: 0.940366\n",
      "[39]\tvalid_0's auc: 0.941013\n",
      "[40]\tvalid_0's auc: 0.941572\n",
      "[41]\tvalid_0's auc: 0.941986\n",
      "[42]\tvalid_0's auc: 0.9424\n",
      "[43]\tvalid_0's auc: 0.942915\n",
      "[44]\tvalid_0's auc: 0.943338\n",
      "[45]\tvalid_0's auc: 0.943827\n",
      "[46]\tvalid_0's auc: 0.944452\n",
      "[47]\tvalid_0's auc: 0.944867\n",
      "[48]\tvalid_0's auc: 0.945406\n",
      "[49]\tvalid_0's auc: 0.945813\n",
      "[50]\tvalid_0's auc: 0.946351\n",
      "[51]\tvalid_0's auc: 0.946893\n",
      "[52]\tvalid_0's auc: 0.947443\n",
      "[53]\tvalid_0's auc: 0.947817\n",
      "[54]\tvalid_0's auc: 0.948074\n",
      "[55]\tvalid_0's auc: 0.948427\n",
      "[56]\tvalid_0's auc: 0.948719\n",
      "[57]\tvalid_0's auc: 0.948964\n",
      "[58]\tvalid_0's auc: 0.94944\n",
      "[59]\tvalid_0's auc: 0.949705\n",
      "[60]\tvalid_0's auc: 0.949934\n",
      "[61]\tvalid_0's auc: 0.950221\n",
      "[62]\tvalid_0's auc: 0.950405\n",
      "[63]\tvalid_0's auc: 0.950718\n",
      "[64]\tvalid_0's auc: 0.95114\n",
      "[65]\tvalid_0's auc: 0.951359\n",
      "[66]\tvalid_0's auc: 0.951594\n",
      "[67]\tvalid_0's auc: 0.951827\n",
      "[68]\tvalid_0's auc: 0.95201\n",
      "[69]\tvalid_0's auc: 0.952251\n",
      "[70]\tvalid_0's auc: 0.95248\n",
      "[71]\tvalid_0's auc: 0.952705\n",
      "[72]\tvalid_0's auc: 0.952882\n",
      "[73]\tvalid_0's auc: 0.953133\n",
      "[74]\tvalid_0's auc: 0.953374\n",
      "[75]\tvalid_0's auc: 0.953502\n",
      "[76]\tvalid_0's auc: 0.953637\n",
      "[77]\tvalid_0's auc: 0.953777\n",
      "[78]\tvalid_0's auc: 0.953893\n",
      "[79]\tvalid_0's auc: 0.954034\n",
      "[80]\tvalid_0's auc: 0.954187\n",
      "[81]\tvalid_0's auc: 0.954419\n",
      "[82]\tvalid_0's auc: 0.954519\n",
      "[83]\tvalid_0's auc: 0.954672\n",
      "[84]\tvalid_0's auc: 0.95485\n",
      "[85]\tvalid_0's auc: 0.954963\n",
      "[86]\tvalid_0's auc: 0.955081\n",
      "[87]\tvalid_0's auc: 0.955217\n",
      "[88]\tvalid_0's auc: 0.955384\n",
      "[89]\tvalid_0's auc: 0.955492\n",
      "[90]\tvalid_0's auc: 0.95557\n",
      "[91]\tvalid_0's auc: 0.955629\n",
      "[92]\tvalid_0's auc: 0.955702\n",
      "[93]\tvalid_0's auc: 0.955845\n",
      "[94]\tvalid_0's auc: 0.955893\n",
      "[95]\tvalid_0's auc: 0.956008\n",
      "[96]\tvalid_0's auc: 0.956125\n",
      "[97]\tvalid_0's auc: 0.956248\n",
      "[98]\tvalid_0's auc: 0.956348\n",
      "[99]\tvalid_0's auc: 0.956456\n",
      "[100]\tvalid_0's auc: 0.956512\n",
      "[101]\tvalid_0's auc: 0.956631\n",
      "[102]\tvalid_0's auc: 0.956717\n",
      "[103]\tvalid_0's auc: 0.956782\n",
      "[104]\tvalid_0's auc: 0.956853\n",
      "[105]\tvalid_0's auc: 0.956917\n",
      "[106]\tvalid_0's auc: 0.957042\n",
      "[107]\tvalid_0's auc: 0.95713\n",
      "[108]\tvalid_0's auc: 0.957201\n",
      "[109]\tvalid_0's auc: 0.957305\n",
      "[110]\tvalid_0's auc: 0.957379\n",
      "[111]\tvalid_0's auc: 0.957426\n",
      "[112]\tvalid_0's auc: 0.957487\n",
      "[113]\tvalid_0's auc: 0.95753\n",
      "[114]\tvalid_0's auc: 0.957574\n",
      "[115]\tvalid_0's auc: 0.95765\n",
      "[116]\tvalid_0's auc: 0.957695\n",
      "[117]\tvalid_0's auc: 0.957748\n",
      "[118]\tvalid_0's auc: 0.957801\n",
      "[119]\tvalid_0's auc: 0.957858\n",
      "[120]\tvalid_0's auc: 0.957925\n",
      "[121]\tvalid_0's auc: 0.957977\n",
      "[122]\tvalid_0's auc: 0.958056\n",
      "[123]\tvalid_0's auc: 0.958109\n",
      "[124]\tvalid_0's auc: 0.958141\n",
      "[125]\tvalid_0's auc: 0.95817\n",
      "[126]\tvalid_0's auc: 0.958216\n",
      "[127]\tvalid_0's auc: 0.958272\n",
      "[128]\tvalid_0's auc: 0.958334\n",
      "[129]\tvalid_0's auc: 0.958441\n",
      "[130]\tvalid_0's auc: 0.958455\n",
      "[131]\tvalid_0's auc: 0.958519\n",
      "[132]\tvalid_0's auc: 0.958569\n",
      "[133]\tvalid_0's auc: 0.958623\n",
      "[134]\tvalid_0's auc: 0.958668\n",
      "[135]\tvalid_0's auc: 0.958714\n",
      "[136]\tvalid_0's auc: 0.958763\n",
      "[137]\tvalid_0's auc: 0.958802\n",
      "[138]\tvalid_0's auc: 0.95883\n",
      "[139]\tvalid_0's auc: 0.958866\n",
      "[140]\tvalid_0's auc: 0.958915\n",
      "[141]\tvalid_0's auc: 0.958947\n",
      "[142]\tvalid_0's auc: 0.958974\n",
      "[143]\tvalid_0's auc: 0.959004\n",
      "[144]\tvalid_0's auc: 0.95904\n",
      "[145]\tvalid_0's auc: 0.959071\n",
      "[146]\tvalid_0's auc: 0.959095\n",
      "[147]\tvalid_0's auc: 0.959111\n",
      "[148]\tvalid_0's auc: 0.959137\n",
      "[149]\tvalid_0's auc: 0.959158\n",
      "[150]\tvalid_0's auc: 0.959172\n",
      "[151]\tvalid_0's auc: 0.959212\n",
      "[152]\tvalid_0's auc: 0.959268\n",
      "[153]\tvalid_0's auc: 0.95929\n",
      "[154]\tvalid_0's auc: 0.959318\n",
      "[155]\tvalid_0's auc: 0.959356\n",
      "[156]\tvalid_0's auc: 0.95939\n",
      "[157]\tvalid_0's auc: 0.959421\n",
      "[158]\tvalid_0's auc: 0.95945\n",
      "[159]\tvalid_0's auc: 0.959477\n",
      "[160]\tvalid_0's auc: 0.959497\n",
      "[161]\tvalid_0's auc: 0.959542\n",
      "[162]\tvalid_0's auc: 0.959568\n",
      "[163]\tvalid_0's auc: 0.95961\n",
      "[164]\tvalid_0's auc: 0.959646\n",
      "[165]\tvalid_0's auc: 0.95967\n",
      "[166]\tvalid_0's auc: 0.9597\n",
      "[167]\tvalid_0's auc: 0.959715\n",
      "[168]\tvalid_0's auc: 0.959745\n",
      "[169]\tvalid_0's auc: 0.959764\n",
      "[170]\tvalid_0's auc: 0.95979\n",
      "[171]\tvalid_0's auc: 0.959812\n",
      "[172]\tvalid_0's auc: 0.959828\n",
      "[173]\tvalid_0's auc: 0.959843\n",
      "[174]\tvalid_0's auc: 0.959874\n",
      "[175]\tvalid_0's auc: 0.95989\n",
      "[176]\tvalid_0's auc: 0.959912\n",
      "[177]\tvalid_0's auc: 0.959926\n",
      "[178]\tvalid_0's auc: 0.959944\n",
      "[179]\tvalid_0's auc: 0.959965\n",
      "[180]\tvalid_0's auc: 0.95998\n",
      "[181]\tvalid_0's auc: 0.959999\n",
      "[182]\tvalid_0's auc: 0.96003\n",
      "[183]\tvalid_0's auc: 0.960046\n",
      "[184]\tvalid_0's auc: 0.96006\n",
      "[185]\tvalid_0's auc: 0.960076\n",
      "[186]\tvalid_0's auc: 0.960096\n",
      "[187]\tvalid_0's auc: 0.96012\n",
      "[188]\tvalid_0's auc: 0.960137\n",
      "[189]\tvalid_0's auc: 0.960157\n",
      "[190]\tvalid_0's auc: 0.960172\n",
      "[191]\tvalid_0's auc: 0.960185\n",
      "[192]\tvalid_0's auc: 0.96021\n",
      "[193]\tvalid_0's auc: 0.960225\n",
      "[194]\tvalid_0's auc: 0.96024\n",
      "[195]\tvalid_0's auc: 0.960252\n",
      "[196]\tvalid_0's auc: 0.960274\n",
      "[197]\tvalid_0's auc: 0.960291\n",
      "[198]\tvalid_0's auc: 0.960303\n",
      "[199]\tvalid_0's auc: 0.960313\n",
      "[200]\tvalid_0's auc: 0.960312\n",
      "[201]\tvalid_0's auc: 0.960335\n",
      "[202]\tvalid_0's auc: 0.960363\n",
      "[203]\tvalid_0's auc: 0.960394\n",
      "[204]\tvalid_0's auc: 0.960398\n",
      "[205]\tvalid_0's auc: 0.960406\n",
      "[206]\tvalid_0's auc: 0.960419\n",
      "[207]\tvalid_0's auc: 0.96043\n",
      "[208]\tvalid_0's auc: 0.96045\n",
      "[209]\tvalid_0's auc: 0.960462\n",
      "[210]\tvalid_0's auc: 0.960476\n",
      "[211]\tvalid_0's auc: 0.960496\n",
      "[212]\tvalid_0's auc: 0.960519\n",
      "[213]\tvalid_0's auc: 0.960533\n",
      "[214]\tvalid_0's auc: 0.960547\n",
      "[215]\tvalid_0's auc: 0.960567\n",
      "[216]\tvalid_0's auc: 0.960573\n",
      "[217]\tvalid_0's auc: 0.960573\n",
      "[218]\tvalid_0's auc: 0.960575\n",
      "[219]\tvalid_0's auc: 0.960578\n",
      "[220]\tvalid_0's auc: 0.960593\n",
      "[221]\tvalid_0's auc: 0.960605\n",
      "[222]\tvalid_0's auc: 0.960616\n",
      "[223]\tvalid_0's auc: 0.960626\n",
      "[224]\tvalid_0's auc: 0.960647\n",
      "[225]\tvalid_0's auc: 0.960654\n",
      "[226]\tvalid_0's auc: 0.960656\n",
      "[227]\tvalid_0's auc: 0.960672\n",
      "[228]\tvalid_0's auc: 0.960679\n",
      "[229]\tvalid_0's auc: 0.960681\n",
      "[230]\tvalid_0's auc: 0.960697\n",
      "[231]\tvalid_0's auc: 0.960703\n",
      "[232]\tvalid_0's auc: 0.96071\n",
      "[233]\tvalid_0's auc: 0.960721\n",
      "[234]\tvalid_0's auc: 0.960723\n",
      "[235]\tvalid_0's auc: 0.960734\n",
      "[236]\tvalid_0's auc: 0.96074\n",
      "[237]\tvalid_0's auc: 0.960762\n",
      "[238]\tvalid_0's auc: 0.960763\n",
      "[239]\tvalid_0's auc: 0.960774\n",
      "[240]\tvalid_0's auc: 0.96078\n",
      "[241]\tvalid_0's auc: 0.960782\n",
      "[242]\tvalid_0's auc: 0.960787\n",
      "[243]\tvalid_0's auc: 0.960796\n",
      "[244]\tvalid_0's auc: 0.960801\n",
      "[245]\tvalid_0's auc: 0.960801\n",
      "[246]\tvalid_0's auc: 0.960802\n",
      "[247]\tvalid_0's auc: 0.960815\n",
      "[248]\tvalid_0's auc: 0.960828\n",
      "[249]\tvalid_0's auc: 0.96083\n",
      "[250]\tvalid_0's auc: 0.960841\n",
      "[251]\tvalid_0's auc: 0.96085\n",
      "[252]\tvalid_0's auc: 0.960852\n",
      "[253]\tvalid_0's auc: 0.960855\n",
      "[254]\tvalid_0's auc: 0.960858\n",
      "[255]\tvalid_0's auc: 0.960863\n",
      "[256]\tvalid_0's auc: 0.960871\n",
      "[257]\tvalid_0's auc: 0.960877\n",
      "[258]\tvalid_0's auc: 0.960886\n",
      "[259]\tvalid_0's auc: 0.960894\n",
      "[260]\tvalid_0's auc: 0.960898\n",
      "[261]\tvalid_0's auc: 0.960904\n",
      "[262]\tvalid_0's auc: 0.960901\n",
      "[263]\tvalid_0's auc: 0.960898\n",
      "[264]\tvalid_0's auc: 0.960902\n",
      "[265]\tvalid_0's auc: 0.960911\n",
      "[266]\tvalid_0's auc: 0.960918\n",
      "[267]\tvalid_0's auc: 0.960939\n",
      "[268]\tvalid_0's auc: 0.960946\n",
      "[269]\tvalid_0's auc: 0.960946\n",
      "[270]\tvalid_0's auc: 0.960951\n",
      "[271]\tvalid_0's auc: 0.96095\n",
      "[272]\tvalid_0's auc: 0.96095\n",
      "[273]\tvalid_0's auc: 0.960952\n",
      "[274]\tvalid_0's auc: 0.960952\n",
      "[275]\tvalid_0's auc: 0.960963\n",
      "[276]\tvalid_0's auc: 0.960961\n",
      "[277]\tvalid_0's auc: 0.960962\n",
      "[278]\tvalid_0's auc: 0.960964\n",
      "[279]\tvalid_0's auc: 0.960967\n",
      "[280]\tvalid_0's auc: 0.960973\n",
      "[281]\tvalid_0's auc: 0.960981\n",
      "[282]\tvalid_0's auc: 0.960983\n",
      "[283]\tvalid_0's auc: 0.960987\n",
      "[284]\tvalid_0's auc: 0.961001\n",
      "[285]\tvalid_0's auc: 0.961\n",
      "[286]\tvalid_0's auc: 0.961\n",
      "[287]\tvalid_0's auc: 0.961008\n",
      "[288]\tvalid_0's auc: 0.961011\n",
      "[289]\tvalid_0's auc: 0.961017\n",
      "[290]\tvalid_0's auc: 0.961019\n",
      "[291]\tvalid_0's auc: 0.961025\n",
      "[292]\tvalid_0's auc: 0.96103\n",
      "[293]\tvalid_0's auc: 0.961029\n",
      "[294]\tvalid_0's auc: 0.961028\n",
      "[295]\tvalid_0's auc: 0.961028\n",
      "[296]\tvalid_0's auc: 0.961027\n",
      "[297]\tvalid_0's auc: 0.961028\n",
      "[298]\tvalid_0's auc: 0.961028\n",
      "[299]\tvalid_0's auc: 0.961024\n",
      "[300]\tvalid_0's auc: 0.961021\n",
      "[301]\tvalid_0's auc: 0.961026\n",
      "[302]\tvalid_0's auc: 0.96103\n",
      "[303]\tvalid_0's auc: 0.961032\n",
      "[304]\tvalid_0's auc: 0.961034\n",
      "[305]\tvalid_0's auc: 0.961031\n",
      "[306]\tvalid_0's auc: 0.961028\n",
      "[307]\tvalid_0's auc: 0.961033\n",
      "[308]\tvalid_0's auc: 0.961031\n",
      "[309]\tvalid_0's auc: 0.961028\n",
      "[310]\tvalid_0's auc: 0.961025\n",
      "[311]\tvalid_0's auc: 0.961029\n",
      "[312]\tvalid_0's auc: 0.961028\n",
      "[313]\tvalid_0's auc: 0.961027\n",
      "[314]\tvalid_0's auc: 0.961037\n",
      "[315]\tvalid_0's auc: 0.961037\n",
      "[316]\tvalid_0's auc: 0.961035\n",
      "[317]\tvalid_0's auc: 0.961035\n",
      "[318]\tvalid_0's auc: 0.961034\n",
      "[319]\tvalid_0's auc: 0.961045\n",
      "[320]\tvalid_0's auc: 0.961062\n",
      "[321]\tvalid_0's auc: 0.961064\n",
      "[322]\tvalid_0's auc: 0.961066\n",
      "[323]\tvalid_0's auc: 0.96107\n",
      "[324]\tvalid_0's auc: 0.961083\n",
      "[325]\tvalid_0's auc: 0.961084\n",
      "[326]\tvalid_0's auc: 0.961088\n",
      "[327]\tvalid_0's auc: 0.961086\n",
      "[328]\tvalid_0's auc: 0.961098\n",
      "[329]\tvalid_0's auc: 0.961097\n",
      "[330]\tvalid_0's auc: 0.961093\n",
      "[331]\tvalid_0's auc: 0.961093\n",
      "[332]\tvalid_0's auc: 0.961092\n",
      "[333]\tvalid_0's auc: 0.96109\n",
      "[334]\tvalid_0's auc: 0.961096\n",
      "[335]\tvalid_0's auc: 0.961094\n",
      "[336]\tvalid_0's auc: 0.961096\n",
      "[337]\tvalid_0's auc: 0.961095\n",
      "[338]\tvalid_0's auc: 0.961106\n",
      "[339]\tvalid_0's auc: 0.961108\n",
      "[340]\tvalid_0's auc: 0.961112\n",
      "[341]\tvalid_0's auc: 0.96113\n",
      "[342]\tvalid_0's auc: 0.961134\n",
      "[343]\tvalid_0's auc: 0.961138\n",
      "[344]\tvalid_0's auc: 0.961144\n",
      "[345]\tvalid_0's auc: 0.961147\n",
      "[346]\tvalid_0's auc: 0.961154\n",
      "[347]\tvalid_0's auc: 0.96115\n",
      "[348]\tvalid_0's auc: 0.96115\n",
      "[349]\tvalid_0's auc: 0.961153\n",
      "[350]\tvalid_0's auc: 0.961153\n",
      "[351]\tvalid_0's auc: 0.96115\n",
      "[352]\tvalid_0's auc: 0.96115\n",
      "[353]\tvalid_0's auc: 0.96115\n",
      "[354]\tvalid_0's auc: 0.961149\n",
      "[355]\tvalid_0's auc: 0.961151\n",
      "[356]\tvalid_0's auc: 0.961146\n",
      "[357]\tvalid_0's auc: 0.961153\n",
      "[358]\tvalid_0's auc: 0.96116\n",
      "[359]\tvalid_0's auc: 0.961168\n",
      "[360]\tvalid_0's auc: 0.961172\n",
      "[361]\tvalid_0's auc: 0.961171\n",
      "[362]\tvalid_0's auc: 0.961177\n",
      "[363]\tvalid_0's auc: 0.961175\n",
      "[364]\tvalid_0's auc: 0.961168\n",
      "[365]\tvalid_0's auc: 0.961168\n",
      "[366]\tvalid_0's auc: 0.961164\n",
      "[367]\tvalid_0's auc: 0.961171\n",
      "[368]\tvalid_0's auc: 0.961177\n",
      "[369]\tvalid_0's auc: 0.961175\n",
      "[370]\tvalid_0's auc: 0.961176\n",
      "[371]\tvalid_0's auc: 0.961175\n",
      "[372]\tvalid_0's auc: 0.961174\n",
      "[373]\tvalid_0's auc: 0.961175\n",
      "[374]\tvalid_0's auc: 0.961177\n",
      "[375]\tvalid_0's auc: 0.961176\n",
      "[376]\tvalid_0's auc: 0.961177\n",
      "[377]\tvalid_0's auc: 0.961176\n",
      "[378]\tvalid_0's auc: 0.961174\n",
      "[379]\tvalid_0's auc: 0.96117\n",
      "[380]\tvalid_0's auc: 0.961171\n",
      "[381]\tvalid_0's auc: 0.961172\n",
      "[382]\tvalid_0's auc: 0.961178\n",
      "[383]\tvalid_0's auc: 0.96118\n",
      "[384]\tvalid_0's auc: 0.961183\n",
      "[385]\tvalid_0's auc: 0.961186\n",
      "[386]\tvalid_0's auc: 0.961182\n",
      "[387]\tvalid_0's auc: 0.961191\n",
      "[388]\tvalid_0's auc: 0.961193\n",
      "[389]\tvalid_0's auc: 0.961196\n",
      "[390]\tvalid_0's auc: 0.9612\n",
      "[391]\tvalid_0's auc: 0.961196\n",
      "[392]\tvalid_0's auc: 0.961194\n",
      "[393]\tvalid_0's auc: 0.961199\n",
      "[394]\tvalid_0's auc: 0.961205\n",
      "[395]\tvalid_0's auc: 0.96121\n",
      "[396]\tvalid_0's auc: 0.961213\n",
      "[397]\tvalid_0's auc: 0.961211\n",
      "[398]\tvalid_0's auc: 0.961211\n",
      "[399]\tvalid_0's auc: 0.961213\n",
      "[400]\tvalid_0's auc: 0.961221\n",
      "[401]\tvalid_0's auc: 0.961223\n",
      "[402]\tvalid_0's auc: 0.961227\n",
      "[403]\tvalid_0's auc: 0.961225\n",
      "[404]\tvalid_0's auc: 0.961228\n",
      "[405]\tvalid_0's auc: 0.961224\n",
      "[406]\tvalid_0's auc: 0.961223\n",
      "[407]\tvalid_0's auc: 0.961223\n",
      "[408]\tvalid_0's auc: 0.961227\n",
      "[409]\tvalid_0's auc: 0.961229\n",
      "[410]\tvalid_0's auc: 0.96123\n",
      "[411]\tvalid_0's auc: 0.961229\n",
      "[412]\tvalid_0's auc: 0.961227\n",
      "[413]\tvalid_0's auc: 0.961229\n",
      "[414]\tvalid_0's auc: 0.961234\n",
      "[415]\tvalid_0's auc: 0.961236\n",
      "[416]\tvalid_0's auc: 0.96124\n",
      "[417]\tvalid_0's auc: 0.961246\n",
      "[418]\tvalid_0's auc: 0.961245\n",
      "[419]\tvalid_0's auc: 0.961251\n",
      "[420]\tvalid_0's auc: 0.961256\n",
      "[421]\tvalid_0's auc: 0.961258\n",
      "[422]\tvalid_0's auc: 0.961263\n",
      "[423]\tvalid_0's auc: 0.961262\n",
      "[424]\tvalid_0's auc: 0.961258\n",
      "[425]\tvalid_0's auc: 0.961256\n",
      "[426]\tvalid_0's auc: 0.961262\n",
      "[427]\tvalid_0's auc: 0.96126\n",
      "[428]\tvalid_0's auc: 0.961258\n",
      "[429]\tvalid_0's auc: 0.961254\n",
      "[430]\tvalid_0's auc: 0.961252\n",
      "[431]\tvalid_0's auc: 0.961256\n",
      "[432]\tvalid_0's auc: 0.96126\n",
      "[433]\tvalid_0's auc: 0.961264\n",
      "[434]\tvalid_0's auc: 0.961267\n",
      "[435]\tvalid_0's auc: 0.961265\n",
      "[436]\tvalid_0's auc: 0.961268\n",
      "[437]\tvalid_0's auc: 0.961269\n",
      "[438]\tvalid_0's auc: 0.961267\n",
      "[439]\tvalid_0's auc: 0.961267\n",
      "[440]\tvalid_0's auc: 0.961272\n",
      "[441]\tvalid_0's auc: 0.961272\n",
      "[442]\tvalid_0's auc: 0.961281\n",
      "[443]\tvalid_0's auc: 0.96128\n",
      "[444]\tvalid_0's auc: 0.961281\n",
      "[445]\tvalid_0's auc: 0.961283\n",
      "[446]\tvalid_0's auc: 0.961286\n",
      "[447]\tvalid_0's auc: 0.961289\n",
      "[448]\tvalid_0's auc: 0.961291\n",
      "[449]\tvalid_0's auc: 0.961295\n",
      "[450]\tvalid_0's auc: 0.961298\n",
      "[451]\tvalid_0's auc: 0.96129\n",
      "[452]\tvalid_0's auc: 0.961285\n",
      "[453]\tvalid_0's auc: 0.961279\n",
      "[454]\tvalid_0's auc: 0.961275\n",
      "[455]\tvalid_0's auc: 0.961276\n",
      "[456]\tvalid_0's auc: 0.961277\n",
      "[457]\tvalid_0's auc: 0.961278\n",
      "[458]\tvalid_0's auc: 0.961279\n",
      "[459]\tvalid_0's auc: 0.961278\n",
      "[460]\tvalid_0's auc: 0.961274\n",
      "[461]\tvalid_0's auc: 0.961278\n",
      "[462]\tvalid_0's auc: 0.96128\n",
      "[463]\tvalid_0's auc: 0.961283\n",
      "[464]\tvalid_0's auc: 0.961291\n",
      "[465]\tvalid_0's auc: 0.961292\n",
      "[466]\tvalid_0's auc: 0.961291\n",
      "[467]\tvalid_0's auc: 0.961294\n",
      "[468]\tvalid_0's auc: 0.96129\n",
      "[469]\tvalid_0's auc: 0.961292\n",
      "[470]\tvalid_0's auc: 0.961292\n",
      "Early stopping, best iteration is:\n",
      "[450]\tvalid_0's auc: 0.961298\n"
     ]
    }
   ],
   "source": [
    "num_round = 1000\n",
    "model = lgb.train(params, train_data, num_round, valid_sets=[test_data], early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x2c5235743a0>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94891     0.0\n",
       "153423    0.0\n",
       "351509    1.0\n",
       "84657     1.0\n",
       "250466    1.0\n",
       "         ... \n",
       "301003    1.0\n",
       "271062    1.0\n",
       "124153    0.0\n",
       "257616    1.0\n",
       "123250    0.0\n",
       "Name: is_owner, Length: 74720, dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91     40796\n",
      "           1       0.86      0.94      0.90     33924\n",
      "\n",
      "    accuracy                           0.90     74720\n",
      "   macro avg       0.90      0.91      0.90     74720\n",
      "weighted avg       0.91      0.90      0.90     74720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = [1 if pred >= 0.5 else 0 for pred in y_pred]\n",
    "print(classification_report(y_pred_class, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_2/embedding_2/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2576\\198240323.py\", line 39, in <cell line: 39>\n      model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_2/embedding_2/embedding_lookup'\nindices[0,3] = 5777 is not in [0, 86)\n\t [[{{node model_2/embedding_2/embedding_lookup}}]] [Op:__inference_train_function_5568987]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [157]\u001b[0m, in \u001b[0;36m<cell line: 39>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Обучение модели\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model_2/embedding_2/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2576\\198240323.py\", line 39, in <cell line: 39>\n      model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_2/embedding_2/embedding_lookup'\nindices[0,3] = 5777 is not in [0, 86)\n\t [[{{node model_2/embedding_2/embedding_lookup}}]] [Op:__inference_train_function_5568987]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "X = fi.drop('is_owner', axis=1)\n",
    "Y = fi['is_owner']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train, y_train = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "embedding_dim = 10\n",
    "\n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "embedding_layer = Embedding(X_train.shape[1], embedding_dim)(input_layer)\n",
    "flatten_layer = Flatten()(embedding_layer)\n",
    "\n",
    "hidden_layer = Dense(128, activation='relu')(flatten_layer)\n",
    "\n",
    "output_layer = Dense(1, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Обучение модели\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 86)\n"
     ]
    }
   ],
   "source": [
    "print(input_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_3/embedding_89/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14328\\3608470904.py\", line 39, in <cell line: 39>\n      model.fit(X_train_resampled, y_train_resampled, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_3/embedding_89/embedding_lookup'\nindices[0,43] = -1 is not in [0, 416)\n\t [[{{node model_3/embedding_89/embedding_lookup}}]] [Op:__inference_train_function_21222]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 39>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39minput_layer, outputs\u001b[38;5;241m=\u001b[39moutput_layer)\n\u001b[0;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 39\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model_3/embedding_89/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14328\\3608470904.py\", line 39, in <cell line: 39>\n      model.fit(X_train_resampled, y_train_resampled, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_3/embedding_89/embedding_lookup'\nindices[0,43] = -1 is not in [0, 416)\n\t [[{{node model_3/embedding_89/embedding_lookup}}]] [Op:__inference_train_function_21222]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "X = fi.drop('is_owner', axis=1)\n",
    "Y = fi['is_owner']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train, y_train = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "input_layer = Input(shape=(X_train_resampled.shape[1],))\n",
    "\n",
    "\n",
    "embedding_layer = Embedding(int(X_train_resampled.max()+1), embedding_dim)(input_layer)\n",
    "flatten_layer = Flatten()(embedding_layer)\n",
    "\n",
    "\n",
    "hidden_layer1 = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(flatten_layer)\n",
    "hidden_layer2 = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer1)\n",
    "hidden_layer3 = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer2)\n",
    "\n",
    "output_layer = Dense(1, activation='sigmoid')(hidden_layer3)\n",
    "\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1023. MiB for an array with shape (1122, 119540) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [161]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_train_int, y_train, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Resample the data using SMOTE\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m X_train_resampled, y_train_resampled \u001b[38;5;241m=\u001b[39m \u001b[43mSMOTE\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Определение размерности векторных представлений\u001b[39;00m\n\u001b[0;32m     26\u001b[0m embedding_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\base.py:203\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\base.py:88\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     82\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[0;32m     86\u001b[0m )\n\u001b[1;32m---> 88\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     91\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     92\u001b[0m )\n\u001b[0;32m     94\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:355\u001b[0m, in \u001b[0;36mSMOTE._fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    352\u001b[0m X_class \u001b[38;5;241m=\u001b[39m _safe_indexing(X, target_class_indices)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_k_\u001b[38;5;241m.\u001b[39mfit(X_class)\n\u001b[1;32m--> 355\u001b[0m nns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn_k_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    356\u001b[0m X_new, y_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_samples(\n\u001b[0;32m    357\u001b[0m     X_class, y\u001b[38;5;241m.\u001b[39mdtype, class_sample, X_class, nns, n_samples, \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m    358\u001b[0m )\n\u001b[0;32m    359\u001b[0m X_resampled\u001b[38;5;241m.\u001b[39mappend(X_new)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_base.py:861\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m         kwds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_\n\u001b[1;32m--> 861\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mball_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkd_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1867\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1866\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[1;32m-> 1867\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[38;5;241m=\u001b[39mmetric, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1869\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   1871\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   1872\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   1873\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2039\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2037\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1579\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1576\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1581\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1582\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:328\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Y_norm_squared\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m1\u001b[39m, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimensions for Y of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    325\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY_norm_squared of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    326\u001b[0m         )\n\u001b[1;32m--> 328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:369\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[1;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[0;32m    366\u001b[0m     distances \u001b[38;5;241m=\u001b[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[1;32m--> 369\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    370\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m XX\n\u001b[0;32m    371\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m YY\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1023. MiB for an array with shape (1122, 119540) and data type float64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X = fi.drop('is_owner', axis=1)\n",
    "Y = fi['is_owner']\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "X_train_int = X_train_scaled.astype(int)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_int, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train_resampled, y_train_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "embedding_dim = 10\n",
    "\n",
    "input_layer = Input(shape=(X_train_resampled.shape[1],))\n",
    "\n",
    "\n",
    "embedding_layer = Embedding(X_train_resampled.max()+1, embedding_dim)(input_layer)\n",
    "flatten_layer = Flatten()(embedding_layer)\n",
    "hidden_layer = Dense(128, activation='relu')(flatten_layer)\n",
    "\n",
    "output_layer = Dense(1, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Dimension value must be integer or None or have an __index__ method, got value '2.0' with type '<class 'numpy.float64'>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [223]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m input_layer \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(X_train_resampled\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],))\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Создание встраивающего слоя\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m embedding_layer \u001b[38;5;241m=\u001b[39m \u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m flatten_layer \u001b[38;5;241m=\u001b[39m Flatten()(embedding_layer)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Создание скрытого слоя\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:214\u001b[0m, in \u001b[0;36mDimension.__init__\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    212\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(value\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__index__\u001b[39m())\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m--> 214\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    215\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimension value must be integer or None or have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    216\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man __index__ method, got value \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{1!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    217\u001b[0m           value, \u001b[38;5;28mtype\u001b[39m(value))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    219\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimension \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m must be >= 0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value)\n",
      "\u001b[1;31mTypeError\u001b[0m: Dimension value must be integer or None or have an __index__ method, got value '2.0' with type '<class 'numpy.float64'>'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "X = fi.drop('is_owner', axis=1)\n",
    "Y = fi['is_owner']\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train).astype(np.float32)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train_resampled, y_train_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "embedding_dim = 10\n",
    "\n",
    "\n",
    "input_layer = Input(shape=(X_train_resampled.shape[1],))\n",
    "\n",
    "\n",
    "embedding_layer = Embedding(X_train_resampled.max()+1, embedding_dim)(input_layer)\n",
    "flatten_layer = Flatten()(embedding_layer)\n",
    "\n",
    "\n",
    "hidden_layer = Dense(64, activation='relu')(flatten_layer)\n",
    "\n",
    "output_layer = Dense(1, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3605/7662 [=============>................] - ETA: 36s - loss: 0.7272 - accuracy: 0.5029"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X = fi.drop('is_owner', axis=1)\n",
    "Y = fi['is_owner']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train).astype(np.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "embedding_dim = 10\n",
    "\n",
    "input_layer = Input(shape=(X_train_resampled.shape[1],))\n",
    "\n",
    "embedding_layer = Embedding(int(X_train_resampled.max()+1), embedding_dim)(input_layer)\n",
    "flatten_layer = Flatten()(embedding_layer)\n",
    "\n",
    "hidden_layer1 = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(flatten_layer)\n",
    "hidden_layer2 = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer1)\n",
    "hidden_layer3 = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer2)\n",
    "\n",
    "output_layer = Dense(1, activation='sigmoid')(hidden_layer3)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6127/6127 [==============================] - 57s 9ms/step - loss: 0.4791 - accuracy: 0.8380 - val_loss: 0.3815 - val_accuracy: 0.8543\n",
      "Epoch 2/10\n",
      "6127/6127 [==============================] - 50s 8ms/step - loss: 0.3964 - accuracy: 0.8455 - val_loss: 0.3681 - val_accuracy: 0.8612\n",
      "Epoch 3/10\n",
      "6127/6127 [==============================] - 51s 8ms/step - loss: 0.3842 - accuracy: 0.8483 - val_loss: 0.3848 - val_accuracy: 0.8527\n",
      "Epoch 4/10\n",
      "6127/6127 [==============================] - 52s 8ms/step - loss: 0.3795 - accuracy: 0.8492 - val_loss: 0.3550 - val_accuracy: 0.8627\n",
      "Epoch 5/10\n",
      "6127/6127 [==============================] - 51s 8ms/step - loss: 0.3779 - accuracy: 0.8490 - val_loss: 0.3521 - val_accuracy: 0.8622\n",
      "Epoch 6/10\n",
      "6127/6127 [==============================] - 50s 8ms/step - loss: 0.3769 - accuracy: 0.8494 - val_loss: 0.3559 - val_accuracy: 0.8607\n",
      "Epoch 7/10\n",
      "6127/6127 [==============================] - 53s 9ms/step - loss: 0.3768 - accuracy: 0.8485 - val_loss: 0.3527 - val_accuracy: 0.8539\n",
      "Epoch 8/10\n",
      "6127/6127 [==============================] - 51s 8ms/step - loss: 0.3755 - accuracy: 0.8492 - val_loss: 0.3482 - val_accuracy: 0.8640\n",
      "Epoch 9/10\n",
      "6127/6127 [==============================] - 51s 8ms/step - loss: 0.3740 - accuracy: 0.8486 - val_loss: 0.3470 - val_accuracy: 0.8619\n",
      "Epoch 10/10\n",
      "6127/6127 [==============================] - 52s 8ms/step - loss: 0.3721 - accuracy: 0.8489 - val_loss: 0.3468 - val_accuracy: 0.8621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c5237b2530>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "hidden_layer1 = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(flatten_layer)\n",
    "dropout1 = Dropout(0.5)(hidden_layer1)\n",
    "hidden_layer2 = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(dropout1)\n",
    "dropout2 = Dropout(0.5)(hidden_layer2)\n",
    "hidden_layer3 = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(dropout2)\n",
    "\n",
    "output_layer = Dense(1, activation='sigmoid')(hidden_layer3)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled, epochs=10, batch_size=16, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18682/18682 [==============================] - 186s 10ms/step - loss: 0.6089 - accuracy: 0.7042 - val_loss: 0.6151 - val_accuracy: 0.5776\n",
      "Epoch 2/10\n",
      " 1293/18682 [=>............................] - ETA: 2:44 - loss: 0.5921 - accuracy: 0.7098"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "input_layer = Input(shape=(X_train_resampled.shape[1],))\n",
    "\n",
    "\n",
    "embedding_layer = Embedding(int(X_train_resampled.max()+1), embedding_dim)(input_layer)\n",
    "flatten_layer = Flatten()(embedding_layer)\n",
    "\n",
    "\n",
    "hidden_layer1 = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(flatten_layer)\n",
    "hidden_layer2 = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer1)\n",
    "hidden_layer3 = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer2)\n",
    "\n",
    "output_layer = Dense(1, activation='sigmoid')(hidden_layer3)\n",
    "\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766/766 [==============================] - 4s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      1.00      0.88     12347\n",
      "         1.0       0.99      0.73      0.84     12139\n",
      "\n",
      "    accuracy                           0.86     24486\n",
      "   macro avg       0.89      0.86      0.86     24486\n",
      "weighted avg       0.89      0.86      0.86     24486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = (y_pred > 50/100).astype(int) # преобразование вероятностей в метки классов (0 или 1)\n",
    "print(i)\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array 2 cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [168]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m y_pred_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m y_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_test)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2310\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassification_report\u001b[39m(\n\u001b[0;32m   2196\u001b[0m     y_true,\n\u001b[0;32m   2197\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2204\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2205\u001b[0m ):\n\u001b[0;32m   2206\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[0;32m   2207\u001b[0m \n\u001b[0;32m   2208\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2307\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[0;32m   2308\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2310\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2313\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:394\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_consistent_length\u001b[39m(\u001b[38;5;241m*\u001b[39marrays):\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m        Objects that will be checked for consistent length.\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 394\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m    395\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:394\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_consistent_length\u001b[39m(\u001b[38;5;241m*\u001b[39marrays):\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m        Objects that will be checked for consistent length.\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 394\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m [\u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m    395\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:335\u001b[0m, in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 335\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    336\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingleton array \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m cannot be considered a valid collection.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m x\n\u001b[0;32m    337\u001b[0m         )\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;66;03m# Check that shape is returning an integer or default to len\u001b[39;00m\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;66;03m# Dask dataframes may not return numeric shape[0] value\u001b[39;00m\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array 2 cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test)\n",
    "print(classification_report(y_pred_classes, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [97942, 78353]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [199]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m Y \u001b[38;5;241m=\u001b[39m fi[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_owner\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m----> 9\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m X_train_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     13\u001b[0m X_train_resampled, y_train_resampled \u001b[38;5;241m=\u001b[39m SMOTE()\u001b[38;5;241m.\u001b[39mfit_resample(X_train_scaled, y_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2559\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2559\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2561\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2562\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2564\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \n\u001b[0;32m    426\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 443\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [97942, 78353]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = fi.drop('is_owner', axis=1)\n",
    "Y = fi['is_owner']\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train).astype(np.float32)\n",
    "\n",
    "X_train_resampled, y_train_resampled = SMOTE().fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "embedding_dim = 10\n",
    "\n",
    "k = 5 \n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in skf.split(X_train_scaled, y_train):\n",
    "    X_train_cv, X_test_cv = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "    y_train_cv, y_test_cv = y_train[train_index], y_train[test_index]\n",
    "\n",
    "    X_train_resampled_cv, y_train_resampled_cv = SMOTE().fit_resample(X_train_cv, y_train_cv)\n",
    "\n",
    "    input_layer = Input(shape=(X_train_resampled_cv.shape[1],))\n",
    "\n",
    "    embedding_layer = Embedding(int(X_train_resampled_cv.max()+1), embedding_dim)(input_layer)\n",
    "    flatten_layer = Flatten()(embedding_layer)\n",
    "\n",
    "    hidden_layer1 = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(flatten_layer)\n",
    "    hidden_layer2 = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer1)\n",
    "    hidden_layer3 = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer2)\n",
    "\n",
    "    output_layer = Dense(1, activation='sigmoid')(hidden_layer3)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train_resampled_cv, y_train_resampled_cv, epochs=10, batch_size=16, validation_data=(X_test_cv, y_test_cv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3918/3918 [==============================] - 27s 6ms/step - loss: 0.4670 - accuracy: 0.8355 - val_loss: 0.3779 - val_accuracy: 0.8587\n",
      "Epoch 2/10\n",
      "3918/3918 [==============================] - 25s 6ms/step - loss: 0.3764 - accuracy: 0.8519 - val_loss: 0.3599 - val_accuracy: 0.8571\n",
      "Epoch 3/10\n",
      "3918/3918 [==============================] - 27s 7ms/step - loss: 0.3631 - accuracy: 0.8530 - val_loss: 0.3985 - val_accuracy: 0.8460\n",
      "Epoch 4/10\n",
      "3918/3918 [==============================] - 28s 7ms/step - loss: 0.3549 - accuracy: 0.8551 - val_loss: 0.3503 - val_accuracy: 0.8575\n",
      "Epoch 5/10\n",
      "3918/3918 [==============================] - 31s 8ms/step - loss: 0.3502 - accuracy: 0.8563 - val_loss: 0.3500 - val_accuracy: 0.8590\n",
      "Epoch 6/10\n",
      "3918/3918 [==============================] - 32s 8ms/step - loss: 0.3472 - accuracy: 0.8568 - val_loss: 0.3431 - val_accuracy: 0.8595\n",
      "Epoch 7/10\n",
      "3918/3918 [==============================] - 31s 8ms/step - loss: 0.3453 - accuracy: 0.8573 - val_loss: 0.3427 - val_accuracy: 0.8588\n",
      "Epoch 8/10\n",
      "3918/3918 [==============================] - 30s 8ms/step - loss: 0.3421 - accuracy: 0.8581 - val_loss: 0.3457 - val_accuracy: 0.8502\n",
      "Epoch 9/10\n",
      "3918/3918 [==============================] - 30s 8ms/step - loss: 0.3419 - accuracy: 0.8579 - val_loss: 0.3398 - val_accuracy: 0.8591\n",
      "Epoch 10/10\n",
      "3918/3918 [==============================] - 30s 8ms/step - loss: 0.3413 - accuracy: 0.8581 - val_loss: 0.3607 - val_accuracy: 0.8236\n",
      "Epoch 1/10\n",
      "3918/3918 [==============================] - 34s 8ms/step - loss: 0.4694 - accuracy: 0.8327 - val_loss: 0.3846 - val_accuracy: 0.8610\n",
      "Epoch 2/10\n",
      "3918/3918 [==============================] - 38s 10ms/step - loss: 0.3776 - accuracy: 0.8504 - val_loss: 0.4082 - val_accuracy: 0.7792\n",
      "Epoch 3/10\n",
      "3918/3918 [==============================] - 47s 12ms/step - loss: 0.3657 - accuracy: 0.8529 - val_loss: 0.3458 - val_accuracy: 0.8667\n",
      "Epoch 4/10\n",
      "3918/3918 [==============================] - 38s 10ms/step - loss: 0.3592 - accuracy: 0.8522 - val_loss: 0.3436 - val_accuracy: 0.8587\n",
      "Epoch 5/10\n",
      "3918/3918 [==============================] - 38s 10ms/step - loss: 0.3549 - accuracy: 0.8545 - val_loss: 0.3364 - val_accuracy: 0.8673\n",
      "Epoch 6/10\n",
      "3918/3918 [==============================] - 39s 10ms/step - loss: 0.3526 - accuracy: 0.8544 - val_loss: 0.3363 - val_accuracy: 0.8664\n",
      "Epoch 7/10\n",
      "3918/3918 [==============================] - 40s 10ms/step - loss: 0.3510 - accuracy: 0.8549 - val_loss: 0.3388 - val_accuracy: 0.8572\n",
      "Epoch 8/10\n",
      "2799/3918 [====================>.........] - ETA: 9s - loss: 0.3515 - accuracy: 0.8539"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train).astype(np.float32)\n",
    "X_train_resampled, y_train_resampled = SMOTE().fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in skf.split(X_train_resampled, y_train_resampled):\n",
    "    X_train_fold, X_test_fold = X_train_resampled[train_index], X_train_resampled[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_resampled[train_index], y_train_resampled[test_index]\n",
    "\n",
    "    input_layer = Input(shape=(X_train_fold.shape[1],))\n",
    "\n",
    "    embedding_layer = Embedding(int(X_train_fold.max()+1), embedding_dim)(input_layer)\n",
    "    flatten_layer = Flatten()(embedding_layer)\n",
    "\n",
    "    hidden_layer1 = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(flatten_layer)\n",
    "    hidden_layer2 = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer1)\n",
    "    hidden_layer3 = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer2)\n",
    "\n",
    "    output_layer = Dense(1, activation='sigmoid')(hidden_layer3)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=16, validation_data=(X_test_fold, y_test_fold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '<keras.engine.functional.Functional object at 0x000002C523720FD0>' (type <class 'keras.engine.functional.Functional'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:862\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 862\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ready_batches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m queue\u001b[38;5;241m.\u001b[39mEmpty:\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;66;03m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;66;03m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[38;5;66;03m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# workers.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\queue.py:168\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[1;32m--> 168\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [205]\u001b[0m, in \u001b[0;36m<cell line: 46>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Кросс-валидация с использованием функции cross_val_score()\u001b[39;00m\n\u001b[0;32m     40\u001b[0m scoring \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m: make_scorer(precision_score),\n\u001b[0;32m     41\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m: make_scorer(recall_score),\n\u001b[0;32m     42\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     43\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m: make_scorer(f1_score),\n\u001b[0;32m     44\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m: make_scorer(roc_auc_score)}\n\u001b[1;32m---> 46\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision:\u001b[39m\u001b[38;5;124m'\u001b[39m, scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_precision\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecall:\u001b[39m\u001b[38;5;124m'\u001b[39m, scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_recall\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:873\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    870\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_effective_n_jobs\n\u001b[0;32m    871\u001b[0m big_batch_size \u001b[38;5;241m=\u001b[39m batch_size \u001b[38;5;241m*\u001b[39m n_jobs\n\u001b[1;32m--> 873\u001b[0m islice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbig_batch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(islice) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:59\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Capture the thread-local scikit-learn configuration at the time\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Parallel.__call__ is issued since the tasks can be dispatched\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# in a different thread depending on the backend and on the value of\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# pre_dispatch and n_jobs.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m---> 59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:268\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m--> 268\u001b[0m         \u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:79\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     74\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot clone object. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     75\u001b[0m                 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should provide an instance of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m                 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscikit-learn estimator instead of a class.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 79\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     80\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot clone object \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     81\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit does not seem to be a scikit-learn \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator as it does not implement a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mrepr\u001b[39m(estimator), \u001b[38;5;28mtype\u001b[39m(estimator))\n\u001b[0;32m     84\u001b[0m             )\n\u001b[0;32m     86\u001b[0m klass \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\n\u001b[0;32m     87\u001b[0m new_object_params \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mget_params(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot clone object '<keras.engine.functional.Functional object at 0x000002C523720FD0>' (type <class 'keras.engine.functional.Functional'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "X = fi.drop('is_owner', axis=1)\n",
    "Y = fi['is_owner']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X).astype(np.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "embedding_dim = 10\n",
    "input_layer = Input(shape=(X_train_resampled.shape[1],))\n",
    "embedding_layer = Embedding(int(X_train_resampled.max()+1), embedding_dim)(input_layer)\n",
    "flatten_layer = Flatten()(embedding_layer)\n",
    "hidden_layer1 = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(flatten_layer)\n",
    "hidden_layer2 = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer1)\n",
    "hidden_layer3 = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer2)\n",
    "output_layer = Dense(1, activation='sigmoid')(hidden_layer3)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "scoring = {'precision': make_scorer(precision_score),\n",
    "           'recall': make_scorer(recall_score),\n",
    "           'accuracy': 'accuracy',\n",
    "           'f1': make_scorer(f1_score),\n",
    "           'roc_auc': make_scorer(roc_auc_score)}\n",
    "\n",
    "scores = cross_validate(model, X_train_resampled, y_train_resampled, scoring=scoring, cv=5)\n",
    "\n",
    "print('Precision:', scores['test_precision'].mean())\n",
    "print('Recall:', scores['test_recall'].mean())\n",
    "print('Accuracy:', scores['test_accuracy'].mean())\n",
    "print('F1:', scores['test_f1'].mean())\n",
    "print('ROC AUC:', scores['test_roc_auc'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X_train_scaled, y_train):\n",
    "    X_train, X_test = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "    y_train, y_test = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "    X_train_resampled, y_train_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "    input_layer = Input(shape=(X_train_fold.shape[1],))\n",
    "\n",
    "    embedding_layer = Embedding(int(X_train_fold.max()+1), embedding_dim)(input_layer)\n",
    "    flatten_layer = Flatten()(embedding_layer)\n",
    "\n",
    "    hidden_layer1 = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(flatten_layer)\n",
    "    hidden_layer2 = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer1)\n",
    "    hidden_layer3 = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer2)\n",
    "\n",
    "    output_layer = Dense(1, activation='sigmoid')(hidden_layer3)\n",
    "\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=16, validation_data=(X_test_fold, y_test_fold))\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "print(\"F1-score: {:.2f} (+/- {:.2f})\".format(np.mean(f1_scores), np.std(f1_scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.8.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.22.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2576\\2431171484.py:41: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_model = KerasClassifier(model, epochs=10, batch_size=32, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\embedding\n",
      "......vars\n",
      ".........0\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-02 15:50:25         3501\n",
      "metadata.json                                  2023-04-02 15:50:25           64\n",
      "variables.h5                                   2023-04-02 15:50:25       504160\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-02 15:50:24         3501\n",
      "metadata.json                                  2023-04-02 15:50:24           64\n",
      "variables.h5                                   2023-04-02 15:50:24       504160\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\embedding\n",
      "......vars\n",
      ".........0\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\embedding\n",
      "......vars\n",
      ".........0\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-02 15:50:26         3501\n",
      "metadata.json                                  2023-04-02 15:50:26           64\n",
      "variables.h5                                   2023-04-02 15:50:26       504160\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-02 15:50:26         3501\n",
      "metadata.json                                  2023-04-02 15:50:26           64\n",
      "variables.h5                                   2023-04-02 15:50:26       504160\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\embedding\n",
      "......vars\n",
      ".........0\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\embedding\n",
      "......vars\n",
      ".........0\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-02 15:50:27         3501\n",
      "metadata.json                                  2023-04-02 15:50:27           64\n",
      "variables.h5                                   2023-04-02 15:50:27       504160\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-02 15:50:26         3501\n",
      "metadata.json                                  2023-04-02 15:50:26           64\n",
      "variables.h5                                   2023-04-02 15:50:26       504160\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\embedding\n",
      "......vars\n",
      ".........0\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\embedding\n",
      "......vars\n",
      ".........0\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-02 15:50:28         3501\n",
      "metadata.json                                  2023-04-02 15:50:28           64\n",
      "variables.h5                                   2023-04-02 15:50:28       504160\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-02 15:50:28         3501\n",
      "metadata.json                                  2023-04-02 15:50:28           64\n",
      "variables.h5                                   2023-04-02 15:50:28       504160\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\embedding\n",
      "......vars\n",
      ".........0\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\embedding\n",
      "......vars\n",
      ".........0\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-02 15:50:28         3501\n",
      "metadata.json                                  2023-04-02 15:50:28           64\n",
      "variables.h5                                   2023-04-02 15:50:29       504160\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-02 15:50:28         3501\n",
      "metadata.json                                  2023-04-02 15:50:28           64\n",
      "variables.h5                                   2023-04-02 15:50:28       504160\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\embedding\n",
      "......vars\n",
      ".........0\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 160, in fit\n    self.model = self.build_fn(\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\layer_utils.py\", line 809, in split_out_first_arg\n    raise ValueError(\nValueError: The first argument to `Layer.call` must always be passed.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [213]\u001b[0m, in \u001b[0;36m<cell line: 50>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Кросс-валидация с использованием функции cross_val_score()\u001b[39;00m\n\u001b[0;32m     44\u001b[0m scoring \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m: make_scorer(precision_score),\n\u001b[0;32m     45\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m: make_scorer(recall_score),\n\u001b[0;32m     46\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     47\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m: make_scorer(f1_score),\n\u001b[0;32m     48\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m: make_scorer(roc_auc_score)}\n\u001b[1;32m---> 50\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeras_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision:\u001b[39m\u001b[38;5;124m'\u001b[39m, scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_precision\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecall:\u001b[39m\u001b[38;5;124m'\u001b[39m, scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_recall\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(scoring):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 160, in fit\n    self.model = self.build_fn(\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\layer_utils.py\", line 809, in split_out_first_arg\n    raise ValueError(\nValueError: The first argument to `Layer.call` must always be passed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.utils import all_estimators\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "X = fi.drop('is_owner', axis=1)\n",
    "Y = fi['is_owner']\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X).astype(np.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "embedding_dim = 10\n",
    "input_layer = Input(shape=(X_train_resampled.shape[1],))\n",
    "embedding_layer = Embedding(int(X_train_resampled.max()+1), embedding_dim)(input_layer)\n",
    "flatten_layer = Flatten()(embedding_layer)\n",
    "hidden_layer1 = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(flatten_layer)\n",
    "hidden_layer2 = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer1)\n",
    "hidden_layer3 = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer2)\n",
    "output_layer = Dense(1, activation='sigmoid')(hidden_layer3)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "keras_model = KerasClassifier(model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "\n",
    "scoring = {'precision': make_scorer(precision_score),\n",
    "           'recall': make_scorer(recall_score),\n",
    "           'accuracy': 'accuracy',\n",
    "           'f1': make_scorer(f1_score),\n",
    "           'roc_auc': make_scorer(roc_auc_score)}\n",
    "\n",
    "scores = cross_validate(keras_model, X_train_resampled, y_train_resampled, scoring=scoring, cv=5)\n",
    "\n",
    "print('Precision:', scores['test_precision'].mean())\n",
    "print('Recall:', scores['test_recall'].mean())\n",
    "print('Accuracy:', scores['test_accuracy'].mean())\n",
    "print('F1:', scores['test_f1'].mean())\n",
    "print('ROC AUC:', scores['test_roc_auc'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\embedding\n",
      "......vars\n",
      ".........0\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-02 16:02:30         3501\n",
      "metadata.json                                  2023-04-02 16:02:30           64\n",
      "variables.h5                                   2023-04-02 16:02:30       504160\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-02 16:02:30         3501\n",
      "metadata.json                                  2023-04-02 16:02:30           64\n",
      "variables.h5                                   2023-04-02 16:02:30       504160\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_3\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\embedding\n",
      "......vars\n",
      ".........0\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The first argument to `Layer.call` must always be passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [217]\u001b[0m, in \u001b[0;36m<cell line: 48>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m keras_model \u001b[38;5;241m=\u001b[39m KerasClassifier(model, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     42\u001b[0m scoring \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m: make_scorer(precision_score),\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m: make_scorer(recall_score),\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m: make_scorer(f1_score),\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m: make_scorer(roc_auc_score)}\n\u001b[1;32m---> 48\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeras_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mraise\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision:\u001b[39m\u001b[38;5;124m'\u001b[39m, scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_precision\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecall:\u001b[39m\u001b[38;5;124m'\u001b[39m, scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_recall\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py:248\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape for y: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[1;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(x, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py:160\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_sk_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m))\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_fn, types\u001b[38;5;241m.\u001b[39mFunctionType\n\u001b[0;32m    159\u001b[0m ) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_fn, types\u001b[38;5;241m.\u001b[39mMethodType):\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_fn(\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_sk_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m)\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_fn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_sk_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_fn))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\layer_utils.py:809\u001b[0m, in \u001b[0;36mCallFunctionSpec.split_out_first_arg\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    807\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arg_names[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    810\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe first argument to `Layer.call` must always be passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    811\u001b[0m     )\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs, args, kwargs\n",
      "\u001b[1;31mValueError\u001b[0m: The first argument to `Layer.call` must always be passed."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "X = fi.drop('is_owner', axis=1)\n",
    "Y = fi['is_owner']\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X).astype(np.float32)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "embedding_dim = 10\n",
    "input_layer = Input(shape=(X_train_resampled.shape[1],))\n",
    "embedding_layer = Embedding(int(X_train_resampled.max()+1), embedding_dim)(input_layer)\n",
    "flatten_layer = Flatten()(embedding_layer)\n",
    "hidden_layer1 = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(flatten_layer)\n",
    "hidden_layer2 = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer1)\n",
    "hidden_layer3 = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer2)\n",
    "output_layer = Dense(1, activation='sigmoid')(hidden_layer3)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "keras_model = KerasClassifier(model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "scoring = {'precision': make_scorer(precision_score),\n",
    "'recall': make_scorer(recall_score),\n",
    "'accuracy': 'accuracy',\n",
    "'f1': make_scorer(f1_score),\n",
    "'roc_auc': make_scorer(roc_auc_score)}\n",
    "\n",
    "scores = cross_validate(keras_model, X_train_resampled, y_train_resampled, scoring=scoring, cv=5, error_score='raise')\n",
    "\n",
    "print('Precision:', scores['test_precision'].mean())\n",
    "print('Recall:', scores['test_recall'].mean())\n",
    "print('Accuracy:', scores['test_accuracy'].mean())\n",
    "print('F1:', scores['test_f1'].mean())\n",
    "print('ROC AUC:', scores['test_roc_auc'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'KerasClassifierWrapper' from 'tensorflow.keras.wrappers.scikit_learn' (C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\api\\_v2\\keras\\wrappers\\scikit_learn\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [216]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_validate\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_scorer, precision_score, recall_score, f1_score, roc_auc_score\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasClassifierWrapper\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m     13\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'KerasClassifierWrapper' from 'tensorflow.keras.wrappers.scikit_learn' (C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\api\\_v2\\keras\\wrappers\\scikit_learn\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifierWrapper\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "X = fi.drop('is_owner', axis=1)\n",
    "Y = fi['is_owner']\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X).astype(np.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "embedding_dim = 10\n",
    "input_layer = Input(shape=(X_train_resampled.shape[1],))\n",
    "embedding_layer = Embedding(int(X_train_resampled.max()+1), embedding_dim)(input_layer)\n",
    "flatten_layer = Flatten()(embedding_layer)\n",
    "hidden_layer1 = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(flatten_layer)\n",
    "hidden_layer2 = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer1)\n",
    "hidden_layer3 = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer2)\n",
    "output_layer = Dense(1, activation='sigmoid')(hidden_layer3)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "keras_model = KerasClassifierWrapper(build_fn=model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "scoring = {'precision': make_scorer(precision_score),\n",
    "'recall': make_scorer(recall_score),\n",
    "'accuracy': 'accuracy',\n",
    "'f1': make_scorer(f1_score),\n",
    "'roc_auc': make_scorer(roc_auc_score)}\n",
    "\n",
    "scores = cross_validate(keras_model, X_train_resampled, y_train_resampled, scoring=scoring, cv=5, error_score='raise', n_jobs=-1)\n",
    "\n",
    "print('Precision:', scores['test_precision'].mean())\n",
    "print('Recall:', scores['test_recall'].mean())\n",
    "print('Accuracy:', scores['test_accuracy'].mean())\n",
    "print('F1:', scores['test_f1'].mean())\n",
    "print('ROC AUC:', scores['test_roc_auc'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5705509464017341\n",
      "Recall: 0.8790823711026183\n",
      "Accuracy: 0.6893905417873263\n",
      "F1: 0.6316051959503725\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "X = fi.drop('is_owner', axis=1)\n",
    "Y = fi['is_owner']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X).astype(np.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train_resampled, y_train_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "def create_model():\n",
    "    embedding_dim = 10\n",
    "    input_layer = Input(shape=(X_train_resampled.shape[1],))\n",
    "    embedding_layer = Embedding(int(X_train_resampled.max()+1), embedding_dim)(input_layer)\n",
    "    flatten_layer = Flatten()(embedding_layer)\n",
    "    hidden_layer1 = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(flatten_layer)\n",
    "    hidden_layer2 = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer1)\n",
    "    hidden_layer3 = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(hidden_layer2)\n",
    "    output_layer = Dense(1, activation='sigmoid')(hidden_layer3)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "keras_model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "scoring = {'precision': make_scorer(precision_score),\n",
    "'recall': make_scorer(recall_score),\n",
    "'accuracy': 'accuracy',\n",
    "'f1': make_scorer(f1_score)}\n",
    "\n",
    "scores = cross_validate(keras_model, X_train_resampled, y_train_resampled, scoring=scoring, cv=5, error_score='raise', n_jobs=-1)\n",
    "\n",
    "print('Precision:', scores['test_precision'].mean())\n",
    "print('Recall:', scores['test_recall'].mean())\n",
    "print('Accuracy:', scores['test_accuracy'].mean())\n",
    "print('F1:', scores['test_f1'].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
